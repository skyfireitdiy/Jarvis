import json
import yaml
from typing import Dict, Any, Optional
from datetime import datetime
from colorama import Fore, Style

from .base import BaseAgent
from utils import extract_yaml_from_response
from utils.logger import Logger
from llm import BaseLLM
from utils.yaml_utils import extract_yaml_from_response

class LlamaAgent(BaseAgent):
    """Main agent class that implements the core task loop"""
    
    def __init__(self, llm: BaseLLM, tool_registry=None, verbose: bool = False):
        super().__init__(llm=llm, verbose=verbose)
        self.logger = Logger()
        self.tool_registry = tool_registry
        self.task_context = {}
        self.current_task = None
    
    def process_input(self, task: str):
        """å¤„ç†ç”¨æˆ·è¾“å…¥ä½¿ç”¨ä»»åŠ¡å¾ªç¯æ¨¡å¼"""
        # å¤„ç†å¤šè¡Œè¾“å…¥ï¼Œå°†è¿ç»­çš„æ¢è¡Œæ›¿æ¢ä¸ºå•ä¸ªæ¢è¡Œ
        task = "\n".join(line.strip() for line in task.splitlines() if line.strip())
        
        self.current_task = task
        self.task_context = {
            "task_plan": None,
            "execution_history": [],
            "current_state": "Starting task analysis",
            "user_inputs": []  # å­˜å‚¨ç”¨æˆ·è¾“å…¥å†å²
        }
        
        self.logger.info(f"\n{Fore.CYAN}ğŸ¯ Task:{Style.RESET_ALL}")
        for line in task.splitlines():
            self.logger.info(f"{Fore.CYAN}  {line}{Style.RESET_ALL}")
        
        consecutive_failures = []
        reflection_summary = ""
        first_iteration = True
        
        while True:
            # åªåœ¨éç¬¬ä¸€è½®è¿­ä»£æ—¶æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ
            if not first_iteration:
                self.logger.info(f"\n{Fore.BLUE}ğŸ” Checking task completion...{Style.RESET_ALL}")
                completion_status = self._check_task_completion()
                
                # æ‰“å°å®ŒæˆçŠ¶æ€çš„å…³é”®ä¿¡æ¯
                if completion_status.get("evidence"):
                    self.logger.info(f"{Fore.CYAN}ğŸ“‹ Evidence:{Style.RESET_ALL}")
                    for evidence in completion_status.get("evidence", []):
                        self.logger.info(f"{Fore.CYAN}  â€¢ {evidence}{Style.RESET_ALL}")
                
                if completion_status.get("is_complete", False):
                    conclusion = completion_status.get("conclusion", "")
                    reason = completion_status.get("reason", "")
                    self.task_context["conclusion"] = conclusion
                    self.logger.info(f"\n{Fore.GREEN}âœ¨ Task Complete!{Style.RESET_ALL}")
                    self.logger.info(f"{Fore.GREEN}ğŸ“ Reason: {reason}{Style.RESET_ALL}")
                    self.logger.info(f"{Fore.GREEN}ğŸ“ Conclusion: {conclusion}{Style.RESET_ALL}")
                    break
                else:
                    reason = completion_status.get("reason", "Unknown reason")
                    self.logger.info(f"\n{Fore.YELLOW}â³ Task Incomplete:{Style.RESET_ALL}")
                    self.logger.info(f"{Fore.YELLOW}ğŸ“ Reason: {reason}{Style.RESET_ALL}")
            
            # 1. ä»»åŠ¡åˆ†æ
            self.logger.info(f"\n{Fore.BLUE}ğŸ¤” Analyzing task...{Style.RESET_ALL}")
            
            # å¦‚æœæœ‰åæ€æ€»ç»“ï¼Œæ·»åŠ åˆ°æç¤ºä¸­
            if reflection_summary:
                self.task_context["reflection"] = reflection_summary
            
            guidance = self._get_step_guidance()
            
            # æ‰“å°ä»»åŠ¡è®¡åˆ’
            if guidance.get("task_plan"):
                plan = guidance["task_plan"]
                self.logger.info(f"\n{Fore.YELLOW}ğŸ“‹ Task Plan:{Style.RESET_ALL}")
                self.logger.info(f"{Fore.YELLOW}  â€¢ Goal: {plan.get('overall_goal')}{Style.RESET_ALL}")
                self.logger.info(f"{Fore.YELLOW}  â€¢ Next Focus: {plan.get('next_focus')}{Style.RESET_ALL}")
            
            # æ‰“å°æå–çš„ä¿¡æ¯
            if guidance.get("information_extracted"):
                info = guidance["information_extracted"]
                self.logger.info(f"\n{Fore.MAGENTA}â„¹ï¸ Extracted Information:{Style.RESET_ALL}")
                if info.get("available_info"):
                    self.logger.info(f"{Fore.MAGENTA}  Available Info:{Style.RESET_ALL}")
                    for item in info["available_info"]:
                        self.logger.info(f"{Fore.MAGENTA}    â€¢ {item}{Style.RESET_ALL}")
                if info.get("missing_info"):
                    self.logger.info(f"{Fore.YELLOW}  Missing Info:{Style.RESET_ALL}")
                    for item in info["missing_info"]:
                        self.logger.info(f"{Fore.YELLOW}    â€¢ {item}{Style.RESET_ALL}")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”¨æˆ·è¡¥å……ä¿¡æ¯
            if guidance.get("need_user_input", False):
                reason = guidance.get("user_input_reason", "Please provide more information")
                self.logger.info(f"\n{Fore.YELLOW}â“ {reason}{Style.RESET_ALL}")
                
                # è·å–ç”¨æˆ·è¾“å…¥
                self.logger.info(f"\n{Fore.YELLOW}ğŸ’¬ Your response (type 'done' on a new line when finished):{Style.RESET_ALL}")
                user_input = []
                while True:
                    line = input().strip()
                    if line.lower() == 'done':
                        break
                    user_input.append(line)
                
                # å­˜å‚¨ç”¨æˆ·è¾“å…¥
                if user_input:
                    input_entry = {
                        'timestamp': datetime.now().isoformat(),
                        'reason': reason,
                        'input': '\n'.join(user_input)
                    }
                    self.task_context['user_inputs'].append(input_entry)
                    self.logger.info(f"{Fore.GREEN}âœ… Input received and stored{Style.RESET_ALL}")
                else:
                    self.logger.info(f"{Fore.YELLOW}âš ï¸ No input provided{Style.RESET_ALL}")
                break
            
            # 2. æ‰§è¡Œå·¥å…·
            next_steps = guidance.get("next_steps", [])
            if not next_steps:
                self.logger.info(f"\n{Fore.YELLOW}âš ï¸ No next steps available{Style.RESET_ALL}")
                break
            
            step_success = False
            for step in next_steps:
                # æ˜¾ç¤ºå½“å‰æ­¥éª¤
                self.logger.info(f"\n{Fore.BLUE}ğŸ”„ Executing step: {step.get('description', 'Unknown step')}{Style.RESET_ALL}")
                self.logger.info(f"{Fore.CYAN}âš™ï¸ Using tool: {step.get('tool', '')}{Style.RESET_ALL}")
                self.logger.info(f"{Fore.CYAN}ğŸ“‹ Parameters: {json.dumps(step.get('parameters', {}), indent=2)}{Style.RESET_ALL}")
                
                # æ‰§è¡Œå·¥å…·
                result = self.execute_step(step)
                
                # æ˜¾ç¤ºæ‰§è¡Œç»“æœçŠ¶æ€
                if result.get("success", False):
                    self.logger.info(f"{Fore.GREEN}âœ… Execution successful{Style.RESET_ALL}")
                    step_success = True
                    consecutive_failures = []  # é‡ç½®è¿ç»­å¤±è´¥è®¡æ•°
                    
                    # æ˜¾ç¤ºè¾“å‡ºç»“æœ
                    stdout = result.get("result", {}).get("result", {}).get("stdout", "").strip()
                    stderr = result.get("result", {}).get("result", {}).get("stderr", "").strip()
                    returncode = result.get("result", {}).get("result", {}).get("returncode", "")
                    
                    if stdout:
                        self.logger.info(f"{Fore.WHITE}ğŸ“¤ Output:\n{stdout}{Style.RESET_ALL}")
                    if stderr:
                        self.logger.info(f"{Fore.RED}âš ï¸ Error output:\n{stderr}{Style.RESET_ALL}")
                    if returncode is not None:
                        self.logger.info(f"{Fore.CYAN}ğŸ“Š Return Code: {returncode}{Style.RESET_ALL}")
                else:
                    error = result.get('error', 'Unknown error')
                    self.logger.error(f"{Fore.RED}âŒ Execution failed: {error}{Style.RESET_ALL}")
                    
                    # è®°å½•å¤±è´¥ä¿¡æ¯
                    consecutive_failures.append({
                        'step': step,
                        'result': result,
                        'analysis': None  # å°†åœ¨åˆ†æåæ›´æ–°
                    })
                
                # 3. ç»“æœåˆ†æï¼šæ ¹æ®æ‰§è¡Œç»“æœï¼Œç»“åˆä»»åŠ¡æè¿°ã€è®¡åˆ’ã€ç°æœ‰ä¿¡æ¯ã€å†å²æ‰§è¡Œç»“æœï¼Œåˆ†æå‡ºå¯¹ä»»åŠ¡æœ‰ç”¨çš„ä¿¡æ¯
                self.logger.info(f"\n{Fore.BLUE}ğŸ“Š Analyzing results...{Style.RESET_ALL}")
                analysis = self.analyze_tool_result(step, result)
                self.logger.info(f"{Fore.MAGENTA}ğŸ’¡ Analysis: {analysis}{Style.RESET_ALL}")
                
                # æ›´æ–°æœ€åä¸€æ¬¡å¤±è´¥çš„åˆ†æç»“æœ
                if consecutive_failures:
                    consecutive_failures[-1]['analysis'] = analysis
                
                # æ›´æ–°ä»»åŠ¡ä¸Šä¸‹æ–‡
                self._update_task_context(step, result, analysis)
            
            # å¦‚æœæ‰€æœ‰æ­¥éª¤éƒ½å¤±è´¥äº†ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦åæ€
            if not step_success and len(consecutive_failures) >= 3:
                reflection_summary = self._reflect_on_failures(consecutive_failures[-3:])
                consecutive_failures = []  # é‡ç½®å¤±è´¥è®¡æ•°
            
            first_iteration = False
    
    def _check_task_completion(self) -> Dict[str, Any]:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å®Œæˆï¼Œå¦‚æœå®Œæˆåˆ™ç»™å‡ºæ€»ç»“"""
        prompt_parts = [
            "# ä»»åŠ¡å®Œæˆæ£€æŸ¥",
            "",
            "## ä»»åŠ¡",
            self.current_task,
            "",
            "## å½“å‰ä¿¡æ¯",
            "",
            "### æ‰§è¡Œå†å²",
            *[
                f"#### æ­¥éª¤ {i+1}: {execution['step'].get('description', 'æœªçŸ¥æ­¥éª¤')}\n"
                f"å·¥å…·: {execution['step'].get('tool', 'æœªçŸ¥å·¥å…·')}\n"
                f"å‚æ•°: {json.dumps(execution['step'].get('parameters', {}), indent=2)}\n"
                f"æˆåŠŸ: {execution['result'].get('success', False)}\n"
                f"åˆ†æç»“æœ: {execution.get('analysis', '(æ— åˆ†æ)')}\n"
                for i, execution in enumerate(self.task_context.get('execution_history', []))
            ],
            "",
            "## åˆ†æè¦æ±‚",
            "ä»…åŸºäºä¸Šè¿°æ‰§è¡Œå†å²ï¼š",
            "",
            "1. æˆ‘ä»¬æ˜¯å¦æœ‰è¶³å¤Ÿçš„å®é™…ç»“æœæ¥å›ç­”ä»»åŠ¡é—®é¢˜ï¼Ÿ",
            "2. å¦‚æœæœ‰ï¼ŒåŸºäºè¿™äº›ç»“æœçš„å…·ä½“ç»“è®ºæ˜¯ä»€ä¹ˆï¼Ÿ",
            "",
            "å…³é”®è§„åˆ™ï¼š",
            "1. ç¦æ­¢åšå‡è®¾æˆ–çŒœæµ‹ç»“æœ",
            "2. åªä½¿ç”¨å®é™…æ‰§è¡Œç»“æœä¸­çš„ä¿¡æ¯",
            "3. å¦‚æœæ²¡æœ‰æ‰§è¡Œå†å²ï¼Œä»»åŠ¡ä¸èƒ½å®Œæˆ",
            "4. å¦‚æœç»“æœä¸å®Œæ•´ï¼Œä»»åŠ¡ä¸èƒ½å®Œæˆ",
            "5. ç»“è®ºå¿…é¡»åŒ…å«æ¥è‡ªç»“æœçš„å®é™…è¯æ®",
            "6. å¯¹äº ping ç»“æœï¼š",
            "   - æˆåŠŸï¼šå¿…é¡»çœ‹åˆ°æ¥è‡ª IP çš„å®é™…å“åº”",
            "   - å¤±è´¥ï¼šè¶…æ—¶æˆ–ä¸å¯è¾¾æ¶ˆæ¯ä¹Ÿæ˜¯æœ‰æ•ˆç»“æœ",
            "   - æˆåŠŸå’Œå¤±è´¥éƒ½æ˜¯ç¡®å®šæ€§ç»“æœ",
            "",
            "## å“åº”æ ¼å¼",
            "ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ YAML æ ¼å¼è¿”å›å“åº”ï¼š",
            "",
            "is_complete: true/false",
            "reason: ä»»åŠ¡å®Œæˆ/æœªå®Œæˆçš„åŸå› ",
            "evidence:",
            "  - æ¥è‡ªç»“æœçš„å®é™…è¯æ®1",
            "  - æ¥è‡ªç»“æœçš„å®é™…è¯æ®2",
            "conclusion: å¦‚æœå®Œæˆåˆ™ç»™å‡ºå¸¦è¯æ®çš„æœ€ç»ˆç­”æ¡ˆï¼Œå¦åˆ™ä¸ºç©º",
            "",
            "ç¤ºä¾‹å“åº”ï¼š",
            "is_complete: true",
            'reason: æˆåŠŸè·å–äº†æ‰€éœ€çš„æ‰€æœ‰ä¿¡æ¯',
            "evidence:",
            "  - ç¬¬ä¸€æ­¥æ‰§è¡ŒæˆåŠŸï¼Œè·å–äº†Aä¿¡æ¯",
            "  - ç¬¬äºŒæ­¥æ‰§è¡ŒæˆåŠŸï¼Œè·å–äº†Bä¿¡æ¯",
            'conclusion: æ ¹æ®è·å–çš„ä¿¡æ¯ï¼Œå¯ä»¥å¾—å‡ºæœ€ç»ˆç»“è®º...'
        ]
        
        prompt = "\n".join(prompt_parts)
        completion_status = self._get_llm_yaml_response_with_retry(prompt)
        
        if completion_status is None:
            return {
                "is_complete": False,
                "reason": "Failed to check completion status",
                "evidence": [],
                "conclusion": ""
            }
            
        # å¦‚æœæ²¡æœ‰æ‰§è¡Œå†å²ï¼Œå¼ºåˆ¶è®¾ç½®ä¸ºæœªå®Œæˆ
        if not self.task_context.get('execution_history'):
            completion_status["is_complete"] = False
            completion_status["reason"] = "No execution history available"
            completion_status["evidence"] = []
            completion_status["conclusion"] = ""
            
        return completion_status
    
    def _get_llm_json_response_with_retry(self, prompt: str, max_retries: int = 3) -> Optional[Dict[str, Any]]:
        """è·å–LLMå“åº”å¹¶è§£æä¸ºJSONï¼Œæ”¯æŒé‡è¯•"""
        last_response = None
        
        for attempt in range(max_retries):
            if attempt > 0:
                # å¦‚æœæ˜¯é‡è¯•ï¼Œæ·»åŠ æ›´æ˜ç¡®çš„JSONæ ¼å¼è¦æ±‚
                retry_prompt = f"""
ä½ çš„ä¸Šä¸€ä¸ªå“åº”åŒ…å«æ— æ•ˆçš„JSONæ ¼å¼ã€‚è¯·ä»”ç»†æ£€æŸ¥å¹¶é‡è¯•ã€‚

å¸¸è§é”™è¯¯ï¼š
1. JSONå­—ç¬¦ä¸²ä¸­ä½¿ç”¨äº†å•å¼•å·è€Œä¸æ˜¯åŒå¼•å·
2. å­—æ®µåæ²¡æœ‰ä½¿ç”¨åŒå¼•å·
3. å¤šè¡Œå­—ç¬¦ä¸²æ ¼å¼ä¸æ­£ç¡®
4. æ‹¬å·æˆ–é€—å·ä¸åŒ¹é…
5. åŒ…å«äº†é¢å¤–çš„æ–‡æœ¬æˆ–æ³¨é‡Š

è¯·ç¡®ä¿ï¼š
1. ä½¿ç”¨æ­£ç¡®çš„JSONè¯­æ³•
2. æ‰€æœ‰å­—ç¬¦ä¸²ä½¿ç”¨åŒå¼•å·
3. æ‰€æœ‰å­—æ®µåä½¿ç”¨åŒå¼•å·
4. ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡æœ¬
5. ä¸è¦ä½¿ç”¨æ³¨é‡Š
6. ç¡®ä¿æ‰€æœ‰æ‹¬å·å’Œé€—å·æ­£ç¡®åŒ¹é…
7. å¤šè¡Œå­—ç¬¦ä¸²ä½¿ç”¨é€‚å½“çš„è½¬ä¹‰

åŸå§‹æç¤ºï¼š
{prompt}

ä¹‹å‰çš„å“åº”ï¼š
{last_response}

è¯·æä¾›ä¸€ä¸ªæœ‰æ•ˆçš„JSONå“åº”ï¼š
"""
                response = self._get_llm_response(retry_prompt)
            else:
                response = self._get_llm_response(prompt)
            
            # è®°å½•åŸå§‹å“åº”
            last_response = response
            
            # å°è¯•æå–å’Œè§£æJSON
            json_response = extract_yaml_from_response(response)
            if json_response is not None:
                return json_response
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œè®°å½•é”™è¯¯ä¿¡æ¯
            if self.verbose:
                self.logger.error(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•è§£æJSONå¤±è´¥")
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥åè¿”å›None
        if self.verbose:
            self.logger.error("æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œæ— æ³•è·å–æœ‰æ•ˆçš„JSONå“åº”")
        return None
    
    def _get_llm_yaml_response_with_retry(self, prompt: str, max_retries: int = 3) -> Optional[Dict[str, Any]]:
        """è·å–LLMå“åº”å¹¶è§£æä¸ºYAMLï¼Œæ”¯æŒé‡è¯•"""
        last_response = None
        
        for attempt in range(max_retries):
            if attempt > 0:
                retry_prompt = f"""
ä½ çš„ä¸Šä¸€ä¸ªå“åº”åŒ…å«æ— æ•ˆçš„YAMLæ ¼å¼ã€‚è¯·ä»”ç»†æ£€æŸ¥å¹¶é‡è¯•ã€‚

å¸¸è§é”™è¯¯ï¼š
1. ç¼©è¿›ä¸ä¸€è‡´
2. åˆ—è¡¨é¡¹æ ¼å¼ä¸æ­£ç¡®
3. å¤šè¡Œå­—ç¬¦ä¸²æ ¼å¼ä¸æ­£ç¡®
4. é”®å€¼å¯¹æ ¼å¼ä¸æ­£ç¡®
5. åŒ…å«äº†é¢å¤–çš„æ–‡æœ¬æˆ–æ³¨é‡Š

è¯·ç¡®ä¿ï¼š
1. ä½¿ç”¨æ­£ç¡®çš„YAMLè¯­æ³•
2. ä¿æŒä¸€è‡´çš„ç¼©è¿›ï¼ˆå»ºè®®ä½¿ç”¨2ç©ºæ ¼ï¼‰
3. åˆ—è¡¨é¡¹ä½¿ç”¨ "- " å¼€å¤´
4. å¤šè¡Œå­—ç¬¦ä¸²ä½¿ç”¨ | æˆ– >
5. ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡æœ¬
6. ä¸è¦ä½¿ç”¨æ³¨é‡Š

åŸå§‹æç¤ºï¼š
{prompt}

ä¹‹å‰çš„å“åº”ï¼š
{last_response}

è¯·æä¾›ä¸€ä¸ªæœ‰æ•ˆçš„YAMLå“åº”ï¼š
"""
                response = self._get_llm_response(retry_prompt)
            else:
                response = self._get_llm_response(prompt)
            
            last_response = response
            
            # å°è¯•æå–å’Œè§£æYAML
            yaml_response = extract_yaml_from_response(response)
            if yaml_response is not None:
                return yaml_response
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œè®°å½•é”™è¯¯ä¿¡æ¯
            if self.verbose:
                self.logger.error(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•è§£æYAMLå¤±è´¥")
        
        if self.verbose:
            self.logger.error("æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œæ— æ³•è·å–æœ‰æ•ˆçš„YAMLå“åº”")
        return None
    
    def _get_step_guidance(self) -> Dict[str, Any]:
        """ä»»åŠ¡åˆ†æï¼šæ ¹æ®ä¸Šä¸‹æ–‡ç»™å‡ºä¸‹ä¸€æ­¥æŒ‡å¯¼"""
        prompt_parts = [
            "# ä»»åŠ¡åˆ†æ",
            "",
            "## å½“å‰ä»»åŠ¡",
            self.current_task,
            "",
            "## ä¿¡æ¯æå–",
            "ä»ä»»åŠ¡æè¿°ä¸­æå–ï¼š",
            "",
            "* æ‰€éœ€çš„å€¼å’Œå‚æ•°",
            "* éšå«çš„çº¦æŸæ¡ä»¶",
            "* ç›¸å…³ä¸Šä¸‹æ–‡",
            "",
            "## å·¥å…·é€‰æ‹©",
            "åŸºäºæå–çš„ä¿¡æ¯ï¼š",
            "",
            "* é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·",
            "* å¿…é¡»æä¾›å·¥å…·æ‰€éœ€çš„æ‰€æœ‰å‚æ•°",
            "* å¯¹äº shell å·¥å…·ï¼Œå¿…é¡»åŒ…å« 'command' å‚æ•°",
            "* ä»…åœ¨ç»å¯¹å¿…è¦æ—¶æ‰è¯·æ±‚ç”¨æˆ·è¾“å…¥",
            "",
            "## å¯ç”¨å·¥å…·",
            self.tool_registry.get_tools_description(),
            "",
            "## å½“å‰ä¸Šä¸‹æ–‡",
            "",
            "### çŠ¶æ€",
            f"`{self.task_context['current_state']}`",
            "",
            "### ä»»åŠ¡è®¡åˆ’",
            "```json",
            json.dumps(self.task_context.get('task_plan', {}), indent=2),
            "```",
            "",
            "### ä¹‹å‰çš„æ‰§è¡Œ",
            *[
                f"#### æ­¥éª¤ï¼š{execution['step'].get('description', 'æœªçŸ¥æ­¥éª¤')}\n"
                f"åˆ†æï¼š{execution.get('analysis', '(æ— åˆ†æ)')}\n"
                for execution in self.task_context.get('execution_history', [])
            ],
            "",
            # æ·»åŠ ç”¨æˆ·è¾“å…¥å†å²åˆ°æç¤ºä¸­
            *(
                [
                    "### ç”¨æˆ·è¾“å…¥",
                    *sum([[
                        f"#### è¾“å…¥ {i+1}ï¼š",
                        f"åŸå› ï¼š{input_entry['reason']}",
                        f"å›åº”ï¼š\n{input_entry['input']}\n"
                    ] for i, input_entry in enumerate(self.task_context.get('user_inputs', []))], []),
                    ""
                ] if self.task_context.get('user_inputs') else []
            ),
            # æ·»åŠ åæ€ç»“æœåˆ°æç¤ºä¸­
            *(
                [
                    "### æœ€è¿‘çš„åæ€",
                    "åŸºäºå‰çš„å¤±è´¥ï¼Œè€ƒè™‘ä»¥ä¸‹è§è§£ï¼š",
                    self.task_context.get('reflection', '(æ— åæ€å¯ç”¨)'),
                    ""
                ] if self.task_context.get('reflection') else []
            ),
            "",
            "## å“åº”æ ¼å¼",
            "ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ YAML æ ¼å¼è¿”å›å“åº”ã€‚",
            "æ ¼å¼é”™è¯¯å°†å¯¼è‡´å·¥å…·æ‰§è¡Œå¤±è´¥ã€‚",
            "",
            "æ ¼å¼æ¨¡æ¿ï¼š",
            "information_extracted:",
            "  available_info:",
            "    - ä»ä»»åŠ¡ä¸­æå–çš„ä¿¡æ¯1",
            "    - ä»ä»»åŠ¡ä¸­æå–çš„ä¿¡æ¯2",
            "  implicit_info:",
            "    - ä»»ä½•éšå«çš„ä¿¡æ¯1",
            "    - ä»»ä½•éšå«çš„ä¿¡æ¯2",
            "  is_sufficient: true",
            "  missing_info: []",
            "",
            "need_user_input: false",
            "user_input_reason: ä»…å½“ need_user_input ä¸º true æ—¶å‡ºç°",
            "",
            "next_steps:",
            "  - tool: å·¥å…·åç§°",
            "    parameters:",
            "      param1: value1",
            "    description: è¿™ä¸€æ­¥å°†åšä»€ä¹ˆ",
            "",
            "task_plan:",
            "  overall_goal: ä¸»è¦ç›®æ ‡",
            "  next_focus: å½“å‰æ­¥éª¤é‡ç‚¹",
            "",
            "ç¤ºä¾‹å“åº”ï¼š",
            "information_extracted:",
            "  available_info:",
            "    - ä»»åŠ¡æ‰€éœ€çš„å€¼A",
            "    - ä»»åŠ¡éœ€çš„å€¼B",
            "  implicit_info:",
            "    - éœ€è¦è¿›è¡Œçš„æ“ä½œç±»å‹",
            "  is_sufficient: true",
            "  missing_info: []",
            "",
            "need_user_input: false",
            "",
            "next_steps:",
            "  - tool: python",
            "    parameters:",
            "      code: |",
            "        print('Hello, World!')",
            "        for i in range(5):",
            "            print(i)",
            "    description: æ‰§è¡ŒPythonä»£ç ç¤ºä¾‹",
            "",
            "task_plan:",
            "  overall_goal: å®Œæˆä¸»è¦ä»»åŠ¡ç›®æ ‡",
            "  next_focus: æ‰§è¡Œå½“å‰æ­¥éª¤"
        ]
        
        prompt = "\n".join(prompt_parts)
        guidance = self._get_llm_yaml_response_with_retry(prompt, max_retries=3)
        
        # ç„¶åå†æ£€æŸ¥ç»“æœ
        if guidance is None:
            return {
                "information_extracted": {
                    "available_info": [],
                    "implicit_info": [],
                    "is_sufficient": False,
                    "missing_info": ["æ— æ³•è§£æå“åº”ï¼ŒJSONæ ¼å¼æ— æ•ˆ"]
                },
                "need_user_input": True,
                "user_input_reason": "ä»»åŠ¡åˆ†æå¤±è´¥ã€‚è¯·è¯•é‡æ–°æè¿°æ‚¨çš„è¯·æ±‚ã€‚",
                "next_steps": [],
                "task_plan": {
                    "overall_goal": "é‡æ–°å°è¯•ä»»åŠ¡åˆ†æ",
                    "next_focus": "ç†è§£ä»»åŠ¡éœ€æ±‚"
                }
            }
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ï¼ŒåŒ…å«æå–çš„ä¿¡æ¯
        if guidance.get('information_extracted'):
            self.task_context['extracted_info'] = guidance['information_extracted']
            
        return guidance
    
    def execute_step(self, step: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªå·¥å…·æ­¥éª¤"""
        # 1. åŸºæœ¬å‚æ•°æ ¡éªŒ
        if not isinstance(step, dict):
            return {
                "success": False,
                "error": "æ­¥éª¤æ ¼å¼æ— æ•ˆï¼Œå¿…é¡»æ˜¯å­—å…¸",
                "result": None
            }
        
        tool_name = step.get("tool", "")
        if not tool_name:
            return {
                "success": False,
                "error": "æœªæä¾›å·¥å…·åç§°",
                "result": None
            }
            
        # è·å–å‚æ•°ï¼ŒåŒæ”¯æŒ parameters å’Œ arguments
        parameters = step.get("parameters", step.get("arguments", {}))
        if not isinstance(parameters, dict):
            return {
                "success": False,
                "error": "å‚æ•°å¿…é¡»æ˜¯å­—å…¸æ ¼å¼",
                "result": None
            }
        
        # 2. è·å–å·¥å…·
        tool_id = tool_name.split("(")[-1].strip(")") if "(" in tool_name else tool_name.lower()
        tool = self.tool_registry.get_tool(tool_id)
        if not tool:
            error = f"æœªæ‰¾åˆ°å·¥å…·ï¼š{tool_name}"
            if self.verbose:
                self.logger.error(error)
            return {
                "success": False,
                "error": error,
                "result": None
            }
        
        # 3. æ‰§è¡Œå·¥å…·
        try:
            result = tool.execute(**parameters)
            return {
                "success": True,
                "result": result
            }
        except Exception as e:
            error_msg = str(e)
            if self.verbose:
                self.logger.error(f"æ‰§è¡Œ {tool_name} æ—¶å‡ºé”™ï¼š{error_msg}")
            else:
                self.logger.error(error_msg)
            return {
                "success": False,
                "error": error_msg,
                "result": None
            }
    
    def analyze_tool_result(self, step: Dict[str, Any], result: Dict[str, Any]) -> str:
        """åˆ†æå·¥å…·æ‰§è¡Œç»“æœï¼Œæå–å¯¹ä»»åŠ¡æœ‰ç”¨çš„ä¿¡æ¯"""
        # è·å–å®é™…è¾“å‡ºå†…å®¹
        result_dict = result.get("result", {}).get("result", {})
        if isinstance(result_dict, dict):
            stdout = result_dict.get("stdout", "").strip()
            stderr = result_dict.get("stderr", "").strip()
            returncode = result_dict.get("returncode", "")
        else:
            stdout = str(result_dict)
            stderr = ""
            returncode = ""
        
        prompt_parts = [
            "# ç»“æœåˆ†æ",
            "",
            "## ä»»åŠ¡",
            self.current_task,
            "",
            "## å½“å‰ä¸Šä¸‹æ–‡",
            "",
            "### çŠ¶æ€",
            f"`{self.task_context['current_state']}`",
            "",
            "### ä»»åŠ¡è®¡åˆ’",
            "```json",
            json.dumps(self.task_context.get('task_plan', {}), indent=2),
            "```",
            "",
            "### ä¹‹å‰çš„æ‰§è¡Œ",
            *[
                f"#### æ­¥éª¤ï¼š{execution['step'].get('description', 'æœªçŸ¥æ­¥éª¤')}\n"
                f"å·¥å…·ï¼š{execution['step'].get('tool', 'æœªçŸ¥å·¥å…·')}\n"
                f"å‚æ•°ï¼š{json.dumps(execution['step'].get('parameters', {}), indent=2)}\n"
                f"æˆåŠŸï¼š{execution['result'].get('success', False)}\n"
                f"åˆ†æç»“æœï¼š{execution.get('analysis', '(æ— åˆ†æ)')}\n"
                for execution in self.task_context.get('execution_history', [])
            ],
            "",
            "## å½“å‰æ­¥éª¤",
            f"* å·¥å…·ï¼š`{step.get('tool', 'æœªçŸ¥')}`",
            f"* æè¿°ï¼š{step.get('description', 'æ— æè¿°')}",
            f"* å‚æ•°ï¼š{json.dumps(step.get('parameters', {}), indent=2)}",
            "",
            "## æ‰§è¡Œç»“æœ",
            "",
            "### æ ‡å‡†è¾“å‡º",
            "```",
            stdout if stdout else "(ç©º)",
            "```",
            "",
            "### æ ‡å‡†é”™è¯¯",
            "```",
            stderr if stderr else "(ç©º)",
            "```",
            "",
            f"### è¿”å›ç ï¼š`{returncode}`",
            "",
            "## åˆ†æè¦æ±‚",
            "åŸºäºä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯ï¼Œåˆ†ææ­¤æ­¥éª¤æ˜¯å¦å¸®åŠ©å®Œæˆä»»åŠ¡ã€‚",
            "",
            "å…³é”®è§„åˆ™ï¼š",
            "1. å…³æ³¨ä»»åŠ¡å®Œæˆæƒ…å†µï¼Œè€Œä¸æ˜¯å‘½ä»¤æˆåŠŸä¸å¦",
            "2. åªåŒ…å«æœ‰æ„ä¹‰çš„å†…å®¹éƒ¨åˆ†",
            "3. å¦‚æœæ²¡æœ‰é‡è¦å†…å®¹åˆ™è·³è¿‡ç›¸åº”éƒ¨åˆ†",
            "4. ä¿æŒç®€æ´å…·ä½“",
            "5. ç¦æ­¢æé€ æˆ–å‡è®¾æ•°æ® - åªä½¿ç”¨å·¥å…·çš„å®é™…è¾“å‡º",
            "6. æ‰€æœ‰å­—å’Œç»“è®ºå¿…é¡»æ¥è‡ªå·¥å…·æ‰§è¡Œç»“æœ",
            "7. å¦‚æœå·¥å…·æ²¡æœ‰è¾“å‡ºç‰¹å®šæ•°æ®ï¼Œä¸è¦åœ¨åˆ†æä¸­åŒ…å«å®ƒ",
            "8. å¦‚æœä¹‹å‰çš„åˆ†æç»™å‡ºäº†å…·ä½“å»ºè®®ï¼Œå¿…é¡»å…ˆæ‰§è¡Œè¿™äº›å»ºè®®",
            "9. åœ¨é‡åˆ°é”™è¯¯æ—¶ï¼Œä¼˜å…ˆé‡‡ç”¨é”™è¯¯ä¿¡æ¯ä¸­æä¾›çš„è§£å†³æ–¹æ¡ˆ",
            "",
            "ä½¿ç”¨ä»¥ä¸‹ç›¸å…³éƒ¨åˆ†æ ¼å¼åŒ–æ‚¨çš„å“åº”ï¼š",
            "",
            "ä»»åŠ¡è¿›å±•ï¼šï¼ˆå¿…éœ€ï¼‰",
            "- æœç›®æ ‡å–å¾—äº†ä»€ä¹ˆå…·ä½“è¿›å±•",
            "- æ»¡è¶³äº†å“ªäº›ä»»åŠ¡è¦æ±‚",
            "",
            "æœ‰ç”¨å‘ç°ï¼šï¼ˆä»…å½“æ‰¾åˆ°å®é™…æ•°æ®/äº‹å®æ—¶ï¼‰",
            "- å¯ä»¥ä½¿ç”¨çš„å…·ä½“äº‹å®/æ•°æ®",
            "- ä»äº‹å®/æ•°æ®å¾—å‡ºçš„å…·ä½“ç»“è®º",
            "",
            "é—®é¢˜ï¼šï¼ˆä»…å½“é‡åˆ°é—®é¢˜æ—¶ï¼‰",
            "- é˜»ç¢è¿›å±•çš„å…·ä½“é—®é¢˜",
            "- ç¼ºå¤±æˆ–æ— æ•ˆçš„ä¿¡æ¯",
            "",
            "ä¸‹ä¸€æ­¥ï¼šï¼ˆä»…å½“éœ€è¦æ”¹å˜æ—¶ï¼‰",
            "- å¿…é¡»å…ˆæ‰§è¡Œä¹‹å‰æœªå®Œæˆçš„å»ºè®®",
            "- å¦‚æœé”™è¯¯ä¿¡æ¯æä¾›äº†è§£å†³æ–¹æ¡ˆï¼Œä¼˜å…ˆä½¿ç”¨è¯¥æ–¹æ¡ˆ",
            "- å…¶ä»–å¯èƒ½çš„è°ƒæ•´å»ºè®®",
            "- è¦è€ƒè™‘çš„æ›¿ä»£æ–¹æ³•"
        ]
        
        prompt = "\n".join(prompt_parts)
        return self._get_llm_response(prompt)
    
    def _update_task_context(self, step: Dict[str, Any], result: Dict[str, Any], analysis: str):
        """æ›´æ–°ä»»åŠ¡ä¸Šä¸‹æ–‡"""
        history_entry = {
            'step': step,
            'result': result,
            'analysis': analysis,
            'timestamp': datetime.now().isoformat()
        }
        self.task_context['execution_history'].append(history_entry)
    
    def _reflect_on_failures(self, failed_steps: list) -> str:
        """æ ¹æ®è¿ç»­å¤±è´¥çš„æ­¥éª¤è¿›è¡Œåæ€ï¼Œç»™å‡ºæ–°çš„å»ºè®®"""
        # æ„å»ºå¤±è´¥å°è¯•çš„æè¿°
        failed_attempts = []
        for i, step in enumerate(failed_steps):
            failed_attempts.extend([
                f"### å°è¯• {i+1}:",
                f"å·¥å…·: {step['step'].get('tool')}",
                f"å‚æ•°: {json.dumps(step['step'].get('parameters', {}), indent=2)}",
                f"é”™è¯¯: {step['result'].get('error', 'æœªçŸ¥é”™è¯¯')}",
                f"è¾“å‡º: {json.dumps(step['result'].get('result', {}), indent=2)}",
                f"åˆ†æ: {step.get('analysis', '(æ— åˆ†æ)')}"
            ])
        
        prompt_parts = [
            "# å¤±è´¥å°è¯•åæ€",
            "",
            "## ä»»åŠ¡",
            self.current_task,
            "",
            "## å¤±è´¥å°è¯•",
            *failed_attempts,
            "",
            "## å½“å‰ä¸Šä¸‹æ–‡",
            f"ä»»åŠ¡è®¡åˆ’: {json.dumps(self.task_context.get('task_plan', {}), indent=2)}",
            "",
            "## åæ€è¦æ±‚",
            "åŸºäºä¸Šè¿°å¤±è´¥å°è¯•ï¼Œæä¾›å…¨é¢åˆ†æåŒ…æ‹¬",
            "",
            "1. è¿™äº›å¤±è´¥çš„å…±åŒæ¨¡å¼",
            "2. åšå‡ºçš„é”™è¯¯å‡è®¾",
            "3. å¯èƒ½æ›´å¥½çš„æ›¿ä»£æ–¹æ³•æˆ–å·¥å…·",
            "4. å¯èƒ½æœ‰å¸®åŠ©çš„å…·ä½“å‚æ•°è°ƒæ•´",
            "",
            "è¯·ä»¥æ¸…æ™°ã€ç»“æ„åŒ–çš„åˆ†æå½¢å¼å›åº”ï¼Œç»™å‡ºå…·ä½“å»ºè®®ã€‚",
            "é‡ç‚¹å…³æ³¨å¯ä»¥æŒ‡å¯¼ä¸‹ä¸€æ¬¡å°è¯•çš„å¯æ“ä½œè§è§£ã€‚",
            "",
            "æ ¼å¼ç¤ºä¾‹ï¼š",
            "å¤±è´¥æ¨¡å¼ï¼š",
            "- æ¨¡å¼1æè¿°",
            "- æ¨¡å¼2æè¿°",
            "",
            "é”™è¯¯å‡è®¾ï¼š",
            "- å‡è®¾1åŠå…¶é”™è¯¯åŸå› ",
            "- å‡è®¾2åŠå…¶é”™è¯¯åŸå› ",
            "",
            "æ›¿ä»£æ–¹æ³•ï¼š",
            "- æ–¹æ³•1ï¼šæè¿°åŠå¯èƒ½æœ‰æ•ˆçš„åŸå› ",
            "- æ–¹æ³•2ï¼šæè¿°åŠå¯èƒ½æœ‰æ•ˆçš„åŸå› ",
            "",
            "å‚æ•°è°ƒæ•´ï¼š",
            "- å‚æ•°1ï¼šå»ºè®®çš„æ”¹å˜åŠç†ç”±",
            "- å‚æ•°2ï¼šå»ºè®®çš„æ”¹å˜åŠç†ç”±",
            "",
            "å»ºè®®ï¼š",
            "æ˜ç¡®çš„ã€å¯æ‰§è¡Œçš„ä¸‹ä¸€æ­¥å°è¯•"
        ]
        
        prompt = "\n".join(prompt_parts)
        reflection = self._get_llm_response(prompt)
        
        # æ‰“å°åæ€ç»“æœ
        if reflection:
            self.logger.info(f"\n{Fore.YELLOW}ğŸ¤” Reflection after failures:{Style.RESET_ALL}")
            # æŒ‰è¡Œæ‰“å°ï¼Œä¿æŒæ ¼å¼
            for line in reflection.splitlines():
                if line.endswith(':'):  # æ ‡é¢˜
                    self.logger.info(f"\n{Fore.YELLOW}{line}{Style.RESET_ALL}")
                elif line.startswith('-'):  # åˆ—è¡¨é¡¹
                    self.logger.info(f"{Fore.CYAN}  {line}{Style.RESET_ALL}")
                else:  # æ™®é€šæ–‡æœ¬
                    self.logger.info(f"{Fore.WHITE}{line}{Style.RESET_ALL}")
        
        return reflection