"""ç½‘ç»œæœç´¢å·¥å…·ã€‚"""

from typing import Any
from typing import Dict
from typing import Optional
from jarvis.jarvis_utils.output import PrettyOutput

# -*- coding: utf-8 -*-

import json
import subprocess
import requests  # å¯¼å…¥ç¬¬ä¸‰æ–¹åº“requests

# pylint: disable=import-error,missing-module-docstring
# fmt: off
from markdownify import markdownify as md

from jarvis.jarvis_agent import Agent
from jarvis.jarvis_platform.registry import PlatformRegistry
from jarvis.jarvis_utils.config import calculate_content_token_limit
from jarvis.jarvis_utils.config import get_llm_config
from jarvis.jarvis_utils.config import get_normal_model_name
from jarvis.jarvis_utils.config import get_normal_platform_name
from jarvis.jarvis_utils.embedding import get_context_token_count
from jarvis.jarvis_utils.http import get as http_get

# fmt: on


class SearchWebTool:
    """å¤„ç†ç½‘ç»œæœç´¢çš„ç±»ã€‚"""

    name = "search_web"
    description = "æœç´¢äº’è”ç½‘ä¸Šçš„ä¿¡æ¯"
    parameters = {
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "æœç´¢å…³é”®è¯æˆ–é—®é¢˜",
            },
            "site": {
                "type": "string",
                "description": "åœ¨ç‰¹å®šç½‘ç«™å†…æœç´¢ï¼Œå¦‚ 'wikipedia.org', 'github.com'",
            },
        },
        "required": ["query"],
    }

    def _search_with_ddgr(
        self,
        query: str,
        agent: Agent,
        site: Optional[str] = None,
    ) -> Dict[str, Any]:
        # pylint: disable=too-many-locals, broad-except
        """ä½¿ç”¨ddgrå‘½ä»¤æ‰§è¡Œç½‘ç»œæœç´¢ã€æŠ“å–å†…å®¹å¹¶æ€»ç»“ç»“æœã€‚"""
        try:
            # æ„å»ºddgrå‘½ä»¤
            cmd = [
                "ddgr",
                "--json",
                "--np",
                "-x",
            ]  # --np è¡¨ç¤ºä¸æç¤ºï¼Œç›´æ¥æ‰§è¡Œï¼›-x æ˜¾ç¤ºå®Œæ•´URL

            # æ·»åŠ ç½‘ç«™ç‰¹å®šæœç´¢å‚æ•°
            if site:
                cmd.extend(["-w", site])

            # æ·»åŠ æœç´¢å…³é”®è¯
            cmd.append(query)

            result = subprocess.run(
                cmd, capture_output=True, text=True, timeout=30, check=False
            )

            if result.returncode != 0:
                return {
                    "stdout": "",
                    "stderr": f"ddgrå‘½ä»¤æ‰§è¡Œå¤±è´¥: {result.stderr}",
                    "success": False,
                }

            try:
                results = json.loads(result.stdout)
            except json.JSONDecodeError as e:
                return {
                    "stdout": "",
                    "stderr": f"è§£æddgr JSONè¾“å‡ºå¤±è´¥: {e}",
                    "success": False,
                }

            if not results:
                return {
                    "stdout": "æœªæ‰¾åˆ°æœç´¢ç»“æœã€‚",
                    "stderr": "æœªæ‰¾åˆ°æœç´¢ç»“æœã€‚",
                    "success": False,
                }

            # å…ˆæ‰“å°æœç´¢ç»“æœ
            PrettyOutput.auto_print("\nğŸ” ç½‘ç»œæœç´¢ç»“æœ")
            PrettyOutput.auto_print(f"ğŸ“ æŸ¥è¯¢å…³é”®è¯: {query}")
            PrettyOutput.auto_print(f"ğŸ“Š æœç´¢ç»“æœæ•°: {len(results)}")
            PrettyOutput.auto_print("\nğŸ“„ æœç´¢æ‘˜è¦:")
            for idx, r in enumerate(results[:10], 1):
                title = r.get("title", "")
                url = r.get("url", "")
                abstract = r.get("abstract", "")
                if title:
                    PrettyOutput.auto_print(f"  {idx}. {title}")
                    if url:
                        PrettyOutput.auto_print(f"     URL: {url}")
                    if abstract:
                        PrettyOutput.auto_print(
                            f"     æ‘˜è¦: {abstract[:150]}..."
                            if len(abstract) > 150
                            else f"     æ‘˜è¦: {abstract}"
                        )

            full_content = ""
            visited_urls = []
            visited_count = 0

            # é¦–å…ˆæ”¶é›†æ‰€æœ‰abstractä½œä¸ºåŸºç¡€å†…å®¹
            for r in results:
                url = r.get("url", "")
                title = r.get("title", "")
                abstract = r.get("abstract", "")

                # æ·»åŠ abstractåˆ°å†…å®¹ä¸­
                if abstract:
                    full_content += f"æ ‡é¢˜: {title}\næ‘˜è¦: {abstract}\n\n"

            # é¦–å…ˆè®¡ç®—ä¸€æ¬¡å†…å®¹é•¿åº¦é™åˆ¶ï¼ˆåŸºäºå‰©ä½™tokenï¼‰
            content_token_limit = calculate_content_token_limit(agent)

            # ç„¶åæŠ“å–å‰10ä¸ªURLçš„è¯¦ç»†å†…å®¹
            for r in results:
                if visited_count >= 10:
                    break

                url = r.get("url", "")
                if url:
                    PrettyOutput.auto_print(
                        f"\nâ³ æ­£åœ¨è®¿é—® ({visited_count + 1}/{min(10, len(results))}): {url}"
                    )
                    try:
                        response = http_get(url, timeout=10.0, allow_redirects=True)
                        content = md(response.text, strip=["script", "style"])
                        if content:
                            # è®¡ç®—å‰©ä½™å¯ç”¨çš„å†…å®¹é•¿åº¦é™åˆ¶ï¼ˆtokenæ•°ï¼‰
                            remaining_limit = (
                                content_token_limit
                                - get_context_token_count(full_content)
                            )
                            # å¦‚æœå‰©ä½™é™åˆ¶ä¸è¶³ï¼Œè·³è¿‡æ­¤URL
                            if remaining_limit <= 0:
                                PrettyOutput.auto_print(
                                    f"âš ï¸ å†…å®¹é•¿åº¦å·²è¾¾é™åˆ¶ï¼Œè·³è¿‡: {url}"
                                )
                                continue
                            # åŸºäºtokené™åˆ¶æˆªå–å†…å®¹ï¼ˆä¿å®ˆä¼°è®¡ï¼š1 token â‰ˆ 4 å­—ç¬¦ï¼Œç”¨å­—ç¬¦æ•°ä¿å®ˆæˆªå–ï¼‰
                            content_preview = content[: remaining_limit * 4]
                            full_content += (
                                f"URL: {url}\nå†…å®¹é¢„è§ˆ: {content_preview}\n\n"
                            )
                            visited_urls.append(url)
                            visited_count += 1
                            PrettyOutput.auto_print(
                                f"âœ… å·²æŠ“å–å†…å®¹ ({len(content_preview)} å­—ç¬¦)"
                            )
                    except requests.exceptions.HTTPError as e:
                        PrettyOutput.auto_print(
                            f"âš ï¸ HTTPé”™è¯¯ {e.response.status_code} è®¿é—® {url}"
                        )
                    except requests.exceptions.RequestException as e:
                        PrettyOutput.auto_print(f"âš ï¸ è¯·æ±‚é”™è¯¯: {e}")

            if not full_content.strip():
                return {
                    "stdout": "æ— æ³•ä»ä»»ä½•URLæŠ“å–æœ‰æ•ˆå†…å®¹ã€‚",
                    "stderr": "æŠ“å–å†…å®¹å¤±è´¥ã€‚",
                    "success": False,
                }

            urls_list = "\n".join(f"  - {u}" for u in visited_urls)
            if urls_list:
                full_content = f"å‚è€ƒURL:\n{urls_list}\n\n{full_content}"

            summary_prompt = f'è¯·ä¸ºæŸ¥è¯¢"{query}"æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼š\n\n{full_content}'

            # ä½¿ç”¨normalæ¨¡å‹è¿›è¡Œæ€»ç»“
            platform_name = get_normal_platform_name(None)
            model_name = get_normal_model_name(None)
            # è·å– normal_llm çš„ llm_configï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ API base å’Œ API key
            llm_config = get_llm_config("normal", None)

            model = PlatformRegistry().create_platform(platform_name, llm_config)
            if not model:
                return {
                    "stdout": "",
                    "stderr": "æ— æ³•åˆ›å»ºç”¨äºæ€»ç»“çš„æ¨¡å‹ã€‚",
                    "success": False,
                }

            model.set_model_name(model_name)
            model.set_suppress_output(False)
            summary = model.chat_until_success(summary_prompt)

            PrettyOutput.auto_print("\nğŸ’¡ æ€»ç»“ç»“æœ:")
            PrettyOutput.auto_print(summary)

            # æ·»åŠ æ¥æºä¿¡æ¯åˆ°æ€»ç»“æ–‡æœ¬ä¸­ï¼Œä¾¿äºLLMä½¿ç”¨read_webpageéªŒè¯
            if visited_urls:
                sources_text = "\n\nå‚è€ƒæ¥æº:\n" + "\n".join(
                    f"- {url}" for url in visited_urls
                )
                summary_with_sources = summary + sources_text
                PrettyOutput.auto_print("\nğŸ“š å‚è€ƒæ¥æº:")
                for url in visited_urls:
                    PrettyOutput.auto_print(f"  - {url}")
            else:
                summary_with_sources = summary
                visited_urls = []

            return {
                "stdout": summary_with_sources,
                "stderr": "",
                "success": True,
                "sources": visited_urls,
            }

        except subprocess.TimeoutExpired:
            return {
                "stdout": "",
                "stderr": "ddgrå‘½ä»¤æ‰§è¡Œè¶…æ—¶ã€‚",
                "success": False,
            }
        except Exception as e:
            PrettyOutput.auto_print(f"âŒ ç½‘é¡µæœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return {
                "stdout": "",
                "stderr": f"ç½‘é¡µæœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}",
                "success": False,
            }

    def execute(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """
        Executes the web search.

        Uses ddgr command to search the web and scrape pages for content.
        Supports site-specific search.
        """
        query = args.get("query")
        agent = args.get("agent")

        if not query:
            return {"stdout": "", "stderr": "ç¼ºå°‘æŸ¥è¯¢å‚æ•°ã€‚", "success": False}

        if not isinstance(agent, Agent) or not agent.model:
            return {
                "stdout": "",
                "stderr": "Agentæˆ–Agentæ¨¡å‹æœªæ‰¾åˆ°ã€‚",
                "success": False,
            }

        # æå–å¯é€‰å‚æ•°
        site = args.get("site")

        return self._search_with_ddgr(query=query, agent=agent, site=site)

    @staticmethod
    def check() -> bool:
        """Check if the tool is available."""
        return True
