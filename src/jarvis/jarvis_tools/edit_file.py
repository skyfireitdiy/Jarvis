# -*- coding: utf-8 -*-
"""æ™®é€šæ–‡ä»¶ç¼–è¾‘å·¥å…·ï¼ˆåŸºäº search/replace çš„éç»“æ„åŒ–ç¼–è¾‘ï¼‰"""

import difflib
import os
import shutil
from typing import Any, Dict, List, Optional, Tuple


class EditFileNormalTool:
    """æ™®é€šæ–‡ä»¶ç¼–è¾‘å·¥å…·ï¼Œå®Œå…¨åŸºäº search/replace è¿›è¡Œæ–‡ä»¶ç¼–è¾‘"""

    name = "edit_file"
    description = (
        "ä½¿ç”¨ search/replace å¯¹æ–‡ä»¶è¿›è¡Œæ™®é€šæ–‡æœ¬ç¼–è¾‘ï¼ˆä¸ä¾èµ–å—idï¼‰ï¼Œæ”¯æŒåŒæ—¶ä¿®æ”¹å¤šä¸ªæ–‡ä»¶ã€‚\n\n"
        "ğŸ’¡ ä½¿ç”¨æ–¹å¼ï¼š\n"
        "1. ç›´æ¥æŒ‡å®šè¦ç¼–è¾‘çš„æ–‡ä»¶è·¯å¾„\n"
        "2. ä¸ºæ¯ä¸ªæ–‡ä»¶æä¾›ä¸€ç»„ search/replace æ“ä½œ\n"
        "3. ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…æŸ¥æ‰¾ search æ–‡æœ¬ï¼Œç›¸ä¼¼åº¦é˜ˆå€¼ 0.85ï¼Œæ‰¾åˆ°åŒ¹é…åæ›¿æ¢ä¸ºæ–°æ–‡æœ¬\n\n"
        "âš ï¸ æç¤ºï¼š\n"
        "- search ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…ï¼ˆç›¸ä¼¼åº¦ >= 0.85ï¼‰ï¼Œä¸æ”¯æŒæ­£åˆ™è¡¨è¾¾å¼\n"
        "- search ä¸èƒ½ä¸ºç©ºå­—ç¬¦ä¸²\n"
        "- å¦‚æœæŸä¸ª search åœ¨æ–‡ä»¶ä¸­æ‰¾ä¸åˆ°ç›¸ä¼¼åº¦ >= 0.85 çš„åŒ¹é…ï¼Œå°†å¯¼è‡´è¯¥æ–‡ä»¶çš„ç¼–è¾‘å¤±è´¥ï¼Œæ–‡ä»¶å†…å®¹ä¼šå›æ»šåˆ°åŸå§‹çŠ¶æ€\n"
        "- åŒ¹é…æ—¶ä¼šæŸ¥æ‰¾æœ€ç›¸ä¼¼çš„ä½ç½®ï¼Œå¦‚æœå­˜åœ¨å¤šä¸ªç›¸ä¼¼ä½ç½®ï¼Œä¼šæ›¿æ¢ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„åŒ¹é…"
    )

    parameters = {
        "type": "object",
        "properties": {
            "files": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "file_path": {
                            "type": "string",
                            "description": "è¦ä¿®æ”¹çš„æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒç»å¯¹è·¯å¾„å’Œç›¸å¯¹è·¯å¾„ï¼‰",
                        },
                        "diffs": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "search": {
                                        "type": "string",
                                        "description": "è¦æœç´¢çš„åŸå§‹æ–‡æœ¬ï¼ˆä¸æ”¯æŒæ­£åˆ™è¡¨è¾¾å¼ï¼Œä¸èƒ½ä¸ºç©ºï¼‰",
                                    },
                                    "replace": {
                                        "type": "string",
                                        "description": "æ›¿æ¢åçš„æ–‡æœ¬ï¼ˆå¯ä»¥ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰",
                                    },
                                    "count": {
                                        "type": "integer",
                                        "description": "æ›¿æ¢æ¬¡æ•°ï¼Œ-1 æˆ–ç¼ºçœè¡¨ç¤ºæ›¿æ¢å…¨éƒ¨åŒ¹é…ï¼Œ1 è¡¨ç¤ºåªæ›¿æ¢ç¬¬ä¸€æ¬¡åŒ¹é…",
                                        "default": -1,
                                    },
                                },
                                "required": ["search", "replace"],
                            },
                            "description": "æ™®é€šæ–‡æœ¬æ›¿æ¢æ“ä½œåˆ—è¡¨ï¼ŒæŒ‰é¡ºåºä¾æ¬¡åº”ç”¨åˆ°æ–‡ä»¶å†…å®¹",
                        },
                    },
                    "required": ["file_path", "diffs"],
                },
                "description": "è¦ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡ä»¶åŒ…å«æ–‡ä»¶è·¯å¾„å’Œå¯¹åº”çš„ search/replace æ“ä½œåˆ—è¡¨",
            },
        },
        "required": ["files"],
    }

    def __init__(self):
        """åˆå§‹åŒ–æ™®é€šæ–‡ä»¶ç¼–è¾‘å·¥å…·"""
        pass

    @staticmethod
    def _validate_basic_args(args: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """éªŒè¯åŸºæœ¬å‚æ•°

        Returns:
            å¦‚æœéªŒè¯å¤±è´¥ï¼Œè¿”å›é”™è¯¯å“åº”ï¼›å¦åˆ™è¿”å›None
        """
        files = args.get("files")

        if not files:
            return {
                "success": False,
                "stdout": "",
                "stderr": "ç¼ºå°‘å¿…éœ€å‚æ•°ï¼šfiles",
            }

        if not isinstance(files, list):
            return {
                "success": False,
                "stdout": "",
                "stderr": "fileså‚æ•°å¿…é¡»æ˜¯æ•°ç»„ç±»å‹",
            }

        if len(files) == 0:
            return {
                "success": False,
                "stdout": "",
                "stderr": "filesæ•°ç»„ä¸èƒ½ä¸ºç©º",
            }

        # éªŒè¯æ¯ä¸ªæ–‡ä»¶é¡¹
        for idx, file_item in enumerate(files):
            if not isinstance(file_item, dict):
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": f"filesæ•°ç»„ç¬¬ {idx + 1} é¡¹å¿…é¡»æ˜¯å­—å…¸ç±»å‹",
                }

            file_path = file_item.get("file_path")
            diffs = file_item.get("diffs", [])

            if not file_path:
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": f"filesæ•°ç»„ç¬¬ {idx + 1} é¡¹ç¼ºå°‘å¿…éœ€å‚æ•°ï¼šfile_path",
                }

            if not diffs:
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": f"filesæ•°ç»„ç¬¬ {idx + 1} é¡¹ç¼ºå°‘å¿…éœ€å‚æ•°ï¼šdiffs",
                }

            if not isinstance(diffs, list):
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": f"filesæ•°ç»„ç¬¬ {idx + 1} é¡¹çš„diffså‚æ•°å¿…é¡»æ˜¯æ•°ç»„ç±»å‹",
                }

        return None

    @staticmethod
    def _read_file_with_backup(file_path: str) -> Tuple[str, Optional[str]]:
        """è¯»å–æ–‡ä»¶å¹¶åˆ›å»ºå¤‡ä»½

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            (æ–‡ä»¶å†…å®¹, å¤‡ä»½æ–‡ä»¶è·¯å¾„æˆ–None)
        """
        abs_path = os.path.abspath(file_path)
        os.makedirs(os.path.dirname(abs_path), exist_ok=True)

        file_content = ""
        backup_path = None
        if os.path.exists(abs_path):
            with open(abs_path, "r", encoding="utf-8") as f:
                file_content = f.read()
            # åˆ›å»ºå¤‡ä»½æ–‡ä»¶
            backup_path = abs_path + ".bak"
            try:
                shutil.copy2(abs_path, backup_path)
            except Exception:
                # å¤‡ä»½å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                backup_path = None

        return file_content, backup_path

    @staticmethod
    def _write_file_with_rollback(
        abs_path: str, content: str, backup_path: Optional[str]
    ) -> Tuple[bool, Optional[str]]:
        """å†™å…¥æ–‡ä»¶ï¼Œå¤±è´¥æ—¶å›æ»š

        Args:
            abs_path: æ–‡ä»¶ç»å¯¹è·¯å¾„
            content: è¦å†™å…¥çš„å†…å®¹
            backup_path: å¤‡ä»½æ–‡ä»¶è·¯å¾„æˆ–None

        Returns:
            (æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯æˆ–None)
        """
        try:
            with open(abs_path, "w", encoding="utf-8") as f:
                f.write(content)
            return (True, None)
        except Exception as write_error:
            # å†™å…¥å¤±è´¥ï¼Œå°è¯•å›æ»š
            if backup_path and os.path.exists(backup_path):
                try:
                    shutil.copy2(backup_path, abs_path)
                    os.remove(backup_path)
                except Exception:
                    pass
            error_msg = f"æ–‡ä»¶å†™å…¥å¤±è´¥: {str(write_error)}"
            print(f"âŒ {error_msg}")
            return (False, error_msg)

    @staticmethod
    def _validate_normal_diff(
        diff: Dict[str, Any], idx: int
    ) -> Tuple[Optional[Dict[str, Any]], Optional[Dict[str, Any]]]:
        """éªŒè¯å¹¶è½¬æ¢ normal ç±»å‹çš„ diff

        Returns:
            (é”™è¯¯å“åº”æˆ–None, è§„èŒƒåŒ–åçš„diffæˆ–None)
        """
        search = diff.get("search")
        replace = diff.get("replace")
        count = diff.get("count", -1)

        if search is None:
            return (
                {
                    "success": False,
                    "stdout": "",
                    "stderr": f"ç¬¬ {idx} ä¸ªdiffç¼ºå°‘searchå‚æ•°",
                },
                None,
            )
        if not isinstance(search, str):
            return (
                {
                    "success": False,
                    "stdout": "",
                    "stderr": f"ç¬¬ {idx} ä¸ªdiffçš„searchå‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²",
                },
                None,
            )
        if search == "":
            return (
                {
                    "success": False,
                    "stdout": "",
                    "stderr": f"ç¬¬ {idx} ä¸ªdiffçš„searchå‚æ•°ä¸èƒ½ä¸ºç©ºå­—ç¬¦ä¸²",
                },
                None,
            )

        if replace is None:
            return (
                {
                    "success": False,
                    "stdout": "",
                    "stderr": f"ç¬¬ {idx} ä¸ªdiffç¼ºå°‘replaceå‚æ•°",
                },
                None,
            )
        if not isinstance(replace, str):
            return (
                {
                    "success": False,
                    "stdout": "",
                    "stderr": f"ç¬¬ {idx} ä¸ªdiffçš„replaceå‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²",
                },
                None,
            )

        if count is None:
            count = -1
        if not isinstance(count, int):
            return (
                {
                    "success": False,
                    "stdout": "",
                    "stderr": f"ç¬¬ {idx} ä¸ªdiffçš„countå‚æ•°å¿…é¡»æ˜¯æ•´æ•°",
                },
                None,
            )

        return (
            None,
            {
                "search": search,
                "replace": replace,
                "count": count,
            },
        )

    @staticmethod
    def _find_best_match_position(
        content: str, search_text: str, min_similarity: float = 0.85
    ) -> Tuple[Optional[Tuple[int, int, float]], Optional[str]]:
        """åœ¨æ–‡ä»¶ä¸­æŸ¥æ‰¾æœ€ä½³åŒ¹é…ä½ç½®ï¼ˆä½¿ç”¨ç›¸ä¼¼åº¦åŒ¹é…ï¼‰

        Args:
            content: æ–‡ä»¶å†…å®¹
            search_text: è¦æœç´¢çš„æ–‡æœ¬
            min_similarity: æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé»˜è®¤ 0.85ï¼‰

        Returns:
            ((start_pos, end_pos, similarity), error_msg) æˆ– (None, error_msg)
        """
        if not search_text.strip():
            return None, "search æ–‡æœ¬ä¸èƒ½ä¸ºç©ºæˆ–åªåŒ…å«ç©ºç™½å­—ç¬¦"

        content_lines = content.splitlines(keepends=True)
        search_lines = search_text.splitlines(keepends=True)

        if len(search_lines) == 0:
            return None, "search æ–‡æœ¬ä¸èƒ½ä¸ºç©º"

        # æå–æ ¸å¿ƒæœç´¢æ–‡æœ¬ï¼ˆå»é™¤å‰åç©ºç™½è¡Œï¼‰
        search_core_lines = []
        for line in search_lines:
            if line.strip():
                search_core_lines.append(line)
        if not search_core_lines:
            return None, "search æ–‡æœ¬ä¸èƒ½åªåŒ…å«ç©ºç™½è¡Œ"

        search_core = "".join(search_core_lines)
        core_line_count = len(search_core_lines)

        best_match: Optional[Tuple[int, int, float]] = None
        best_similarity = 0.0

        # åœ¨æ–‡ä»¶ä¸­æ»‘åŠ¨çª—å£æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„ç‰‡æ®µ
        for start_line in range(len(content_lines)):
            # å°è¯•åŒ¹é…ä¸åŒé•¿åº¦çš„ä»£ç å—
            for line_diff in [-2, -1, 0, 1, 2]:
                end_line = start_line + core_line_count + line_diff
                if end_line <= start_line or end_line > len(content_lines):
                    continue

                window_lines = content_lines[start_line:end_line]
                window_content = "".join(window_lines)

                # è·³è¿‡ç©ºå†…å®¹æˆ–è¿‡çŸ­çš„å†…å®¹
                if (
                    not window_content.strip()
                    or len(window_content.strip()) < len(search_core.strip()) * 0.3
                ):
                    continue

                # è®¡ç®—ç›¸ä¼¼åº¦
                similarity = difflib.SequenceMatcher(
                    None, search_core, window_content, autojunk=False
                ).ratio()

                if similarity > best_similarity:
                    best_similarity = similarity
                    # è®¡ç®—å­—ç¬¦ä½ç½®
                    start_pos = sum(len(content_lines[i]) for i in range(start_line))
                    end_pos = start_pos + len(window_content)
                    best_match = (start_pos, end_pos, similarity)

                # å¦‚æœæ‰¾åˆ°å¾ˆå¥½çš„åŒ¹é…ï¼Œæå‰é€€å‡º
                if similarity >= 0.95:
                    break

            # å¦‚æœå·²ç»æ‰¾åˆ°å¾ˆå¥½çš„åŒ¹é…ï¼Œå¯ä»¥æå‰é€€å‡º
            if best_similarity >= 0.95:
                break

        # åªæœ‰å½“ç›¸ä¼¼åº¦è¶³å¤Ÿé«˜æ—¶æ‰è¿”å›åŒ¹é…ï¼ˆé˜ˆå€¼ 0.85ï¼‰
        if best_match is not None and best_similarity >= min_similarity:
            return best_match, None

        # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
        return (
            None,
            f"æœªæ‰¾åˆ°ç›¸ä¼¼åº¦ >= {min_similarity:.2%} çš„åŒ¹é…ï¼ˆæœ€ä½³ç›¸ä¼¼åº¦: {best_similarity:.2%}ï¼‰",
        )

    @staticmethod
    def _apply_normal_edits_to_content(
        original_content: str, diffs: List[Dict[str, Any]]
    ) -> Tuple[bool, str]:
        """å¯¹æ–‡ä»¶å†…å®¹æŒ‰é¡ºåºåº”ç”¨æ™®é€š search/replace ç¼–è¾‘ï¼ˆä½¿ç”¨ç›¸ä¼¼åº¦åŒ¹é…ï¼‰

        è¿”å›:
            (æ˜¯å¦æˆåŠŸ, æ–°å†…å®¹æˆ–é”™è¯¯ä¿¡æ¯)
        """
        content = original_content
        min_similarity = 0.85  # ç›¸ä¼¼åº¦é˜ˆå€¼

        for idx, diff in enumerate(diffs, start=1):
            search = diff["search"]
            replace = diff["replace"]
            count = diff.get("count", -1)

            # ä½¿ç”¨ç›¸ä¼¼åº¦åŒ¹é…æŸ¥æ‰¾ä½ç½®
            match_result, error_msg = EditFileNormalTool._find_best_match_position(
                content, search, min_similarity
            )

            if match_result is None:
                # æ‰¾ä¸åˆ°åŒ¹é…åˆ™å¤±è´¥
                error_info = f"ç¬¬ {idx} ä¸ªdiffå¤±è´¥ï¼š{error_msg}"
                if search:
                    error_info += f"\næœç´¢æ–‡æœ¬: {search[:200]}..."
                return False, error_info

            start_pos, end_pos, similarity = match_result

            # æ‰§è¡Œæ›¿æ¢
            content[start_pos:end_pos]
            new_content = content[:start_pos] + replace + content[end_pos:]

            # å¤„ç† count å‚æ•°
            if count is None or count < 0:
                # æ›¿æ¢å…¨éƒ¨åŒ¹é…ï¼ˆç»§ç»­æŸ¥æ‰¾å¹¶æ›¿æ¢æ‰€æœ‰åŒ¹é…ï¼‰
                content = new_content
                search_start_pos = end_pos + len(replace)
                while True:
                    remaining_content = content[search_start_pos:]
                    next_match, _ = EditFileNormalTool._find_best_match_position(
                        remaining_content, search, min_similarity
                    )
                    if next_match is None:
                        break
                    next_start, next_end, _ = next_match
                    # è°ƒæ•´ä½ç½®ï¼ˆç›¸å¯¹äºåŸå§‹ contentï¼‰
                    actual_start = search_start_pos + next_start
                    actual_end = search_start_pos + next_end
                    content = content[:actual_start] + replace + content[actual_end:]
                    # æ›´æ–°æœç´¢èµ·å§‹ä½ç½®ï¼ˆè·³è¿‡å·²æ›¿æ¢çš„å†…å®¹ï¼‰
                    search_start_pos = actual_start + len(replace)
            elif count == 0:
                # 0 æ¬¡æ›¿æ¢ï¼Œç›¸å½“äºè·³è¿‡
                continue
            elif count == 1:
                # åªæ›¿æ¢ç¬¬ä¸€æ¬¡åŒ¹é…
                content = new_content
            else:
                # æ›¿æ¢æŒ‡å®šæ¬¡æ•°
                content = new_content
                remaining_count = count - 1
                search_start_pos = end_pos + len(replace)
                while remaining_count > 0:
                    remaining_content = content[search_start_pos:]
                    next_match, _ = EditFileNormalTool._find_best_match_position(
                        remaining_content, search, min_similarity
                    )
                    if next_match is None:
                        break
                    next_start, next_end, _ = next_match
                    # è°ƒæ•´ä½ç½®ï¼ˆç›¸å¯¹äºåŸå§‹ contentï¼‰
                    actual_start = search_start_pos + next_start
                    actual_end = search_start_pos + next_end
                    content = content[:actual_start] + replace + content[actual_end:]
                    # æ›´æ–°æœç´¢èµ·å§‹ä½ç½®ï¼ˆè·³è¿‡å·²æ›¿æ¢çš„å†…å®¹ï¼‰
                    search_start_pos = actual_start + len(replace)
                    remaining_count -= 1

        return True, content

    def execute(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ™®é€š search/replace æ–‡ä»¶ç¼–è¾‘æ“ä½œï¼ˆæ”¯æŒåŒæ—¶ä¿®æ”¹å¤šä¸ªæ–‡ä»¶ï¼‰"""
        try:
            # éªŒè¯åŸºæœ¬å‚æ•°ï¼ˆfiles ç»“æ„ï¼‰
            error_response = EditFileNormalTool._validate_basic_args(args)
            if error_response:
                return error_response

            files = args.get("files", [])

            # è®°å½• PATCH æ“ä½œè°ƒç”¨ç»Ÿè®¡
            try:
                from jarvis.jarvis_stats.stats import StatsManager

                StatsManager.increment("patch_normal", group="tool")
            except Exception:
                pass

            all_results = []
            overall_success = True
            successful_files = []
            failed_files = []

            for file_item in files:
                file_path = file_item.get("file_path")
                diffs = file_item.get("diffs", [])

                # æ ¡éªŒå¹¶è§„èŒƒåŒ– diffs
                normalized_diffs: List[Dict[str, Any]] = []
                for idx, diff in enumerate(diffs, start=1):
                    if not isinstance(diff, dict):
                        all_results.append(
                            f"âŒ {file_path}: ç¬¬ {idx} ä¸ªdiffå¿…é¡»æ˜¯å­—å…¸ç±»å‹"
                        )
                        failed_files.append(file_path)
                        overall_success = False
                        normalized_diffs = []
                        break

                    error, normalized = EditFileNormalTool._validate_normal_diff(
                        diff, idx
                    )
                    if error:
                        all_results.append(
                            f"âŒ {file_path}: {error.get('stderr', 'å‚æ•°éªŒè¯å¤±è´¥')}"
                        )
                        failed_files.append(file_path)
                        overall_success = False
                        normalized_diffs = []
                        break

                    normalized_diffs.append(normalized)

                if not normalized_diffs:
                    # è¯¥æ–‡ä»¶çš„diffsæœ‰é—®é¢˜ï¼Œå·²è®°å½•é”™è¯¯ï¼Œè·³è¿‡
                    continue

                # è¯»å–åŸå§‹å†…å®¹å¹¶åˆ›å»ºå¤‡ä»½
                original_content, backup_path = (
                    EditFileNormalTool._read_file_with_backup(file_path)
                )

                # åº”ç”¨æ‰€æœ‰æ™®é€šç¼–è¾‘
                success, result_or_error = (
                    EditFileNormalTool._apply_normal_edits_to_content(
                        original_content, normalized_diffs
                    )
                )

                if not success:
                    # ä¸å†™å…¥æ–‡ä»¶ï¼Œåˆ é™¤å¤‡ä»½æ–‡ä»¶
                    if backup_path and os.path.exists(backup_path):
                        try:
                            os.remove(backup_path)
                        except Exception:
                            pass
                    all_results.append(f"âŒ {file_path}: {result_or_error}")
                    failed_files.append(file_path)
                    overall_success = False
                    continue

                # å†™å…¥æ–‡ä»¶ï¼ˆå¤±è´¥æ—¶å›æ»šï¼‰
                abs_path = os.path.abspath(file_path)
                write_success, write_error = (
                    EditFileNormalTool._write_file_with_rollback(
                        abs_path, result_or_error, backup_path
                    )
                )
                if write_success:
                    # å†™å…¥æˆåŠŸï¼Œåˆ é™¤å¤‡ä»½æ–‡ä»¶
                    if backup_path and os.path.exists(backup_path):
                        try:
                            os.remove(backup_path)
                        except Exception:
                            pass
                    all_results.append(f"âœ… {file_path}: ä¿®æ”¹æˆåŠŸ")
                    successful_files.append(file_path)
                else:
                    all_results.append(f"âŒ {file_path}: {write_error}")
                    failed_files.append(file_path)
                    overall_success = False

            # æ„å»ºè¾“å‡ºä¿¡æ¯
            output_lines = []
            if successful_files:
                output_lines.append(f"âœ… æˆåŠŸä¿®æ”¹ {len(successful_files)} ä¸ªæ–‡ä»¶:")
                for file_path in successful_files:
                    output_lines.append(f"   - {file_path}")

            if failed_files:
                output_lines.append(f"\nâŒ å¤±è´¥ {len(failed_files)} ä¸ªæ–‡ä»¶:")
                for file_path in failed_files:
                    output_lines.append(f"   - {file_path}")

            stdout_text = "\n".join(all_results)
            summary = "\n".join(output_lines) if output_lines else ""

            if overall_success:
                return {
                    "success": True,
                    "stdout": stdout_text + ("\n\n" + summary if summary else ""),
                    "stderr": "",
                }
            else:
                return {
                    "success": False,
                    "stdout": stdout_text + ("\n\n" + summary if summary else ""),
                    "stderr": summary if summary else "éƒ¨åˆ†æ–‡ä»¶ä¿®æ”¹å¤±è´¥",
                }

        except Exception as e:
            error_msg = f"æ–‡ä»¶ç¼–è¾‘å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return {"success": False, "stdout": "", "stderr": error_msg}


__all__ = ["EditFileNormalTool"]
