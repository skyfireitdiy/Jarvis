# -*- coding: utf-8 -*-
import os
from typing import Any, Dict, List

from jarvis.jarvis_utils.config import get_max_input_token_count
from jarvis.jarvis_utils.embedding import get_context_token_count
from jarvis.jarvis_utils.output import OutputType, PrettyOutput

# å°è¯•å¯¼å…¥è¯­è¨€æ”¯æŒæ¨¡å—
try:
    from jarvis.jarvis_code_agent.code_analyzer.language_support import (
        detect_language,
        get_dependency_analyzer,
    )
    from jarvis.jarvis_code_agent.code_analyzer.structured_code import StructuredCodeExtractor
    LANGUAGE_SUPPORT_AVAILABLE = True
except ImportError:
    LANGUAGE_SUPPORT_AVAILABLE = False
    def get_dependency_analyzer(language: str):
        return None
    StructuredCodeExtractor = None


class ReadCodeTool:
    name = "read_code"
    description = (
        "ç»“æ„åŒ–è¯»å–æºä»£ç æ–‡ä»¶ã€‚"
        "æ”¯æŒçš„è¯­è¨€æŒ‰è¯­æ³•å•å…ƒï¼ˆå‡½æ•°ã€ç±»ç­‰ï¼‰è¯»å–ï¼›ä¸æ”¯æŒçš„è¯­è¨€æŒ‰ç©ºç™½è¡Œåˆ†ç»„ï¼›"
        "raw_mode=true æ—¶æŒ‰æ¯20è¡Œåˆ†ç»„è¯»å–ã€‚"
    )
    # å·¥å…·æ ‡ç­¾
    parameters = {
        "type": "object",
        "properties": {
            "files": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "path": {"type": "string"},
                        "start_line": {"type": "number", "default": 1},
                        "end_line": {"type": "number", "default": -1},
                        "raw_mode": {"type": "boolean", "default": False},
                    },
                    "required": ["path"],
                },
                "description": "è¦è¯»å–çš„æ–‡ä»¶åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡ä»¶å¯æŒ‡å®šè¡Œå·èŒƒå›´ï¼ˆstart_line åˆ° end_lineï¼Œ-1 è¡¨ç¤ºæ–‡ä»¶æœ«å°¾ï¼‰ã€‚raw_modeä¸ºtrueæ—¶æŒ‰æ¯20è¡Œåˆ†ç»„è¯»å–ï¼ˆåŸå§‹æ¨¡å¼ï¼‰ã€‚",
            }
        },
        "required": ["files"],
    }
    
    def _extract_syntax_units(
        self, filepath: str, content: str, start_line: int, end_line: int
    ) -> List[Dict[str, Any]]:
        """æå–è¯­æ³•å•å…ƒï¼ˆå‡½æ•°ã€ç±»ç­‰ï¼‰
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            content: æ–‡ä»¶å†…å®¹
            start_line: èµ·å§‹è¡Œå·
            end_line: ç»“æŸè¡Œå·
            
        Returns:
            è¯­æ³•å•å…ƒåˆ—è¡¨ï¼Œæ¯ä¸ªå•å…ƒåŒ…å« id, start_line, end_line, content
        """
        if StructuredCodeExtractor:
            return StructuredCodeExtractor.extract_syntax_units(filepath, content, start_line, end_line)
        return []
    
    def _extract_blank_line_groups(
        self, content: str, start_line: int, end_line: int
    ) -> List[Dict[str, Any]]:
        """æŒ‰ç©ºç™½è¡Œåˆ†ç»„æå–å†…å®¹ï¼ˆå§”æ‰˜ç»™StructuredCodeExtractorï¼‰"""
        if StructuredCodeExtractor:
            return StructuredCodeExtractor.extract_blank_line_groups(content, start_line, end_line)
        return []
    
    def _extract_blank_line_groups_with_split(
        self, content: str, start_line: int, end_line: int
    ) -> List[Dict[str, Any]]:
        """å…ˆæŒ‰ç©ºç™½è¡Œåˆ†ç»„ï¼Œç„¶åå¯¹è¶…è¿‡20è¡Œçš„å—å†æŒ‰æ¯20è¡Œåˆ†å‰²
        
        Args:
            content: æ–‡ä»¶å†…å®¹
            start_line: èµ·å§‹è¡Œå·
            end_line: ç»“æŸè¡Œå·
            
        Returns:
            åˆ†ç»„åˆ—è¡¨ï¼Œæ¯ä¸ªåˆ†ç»„åŒ…å« id, start_line, end_line, content
        """
        # å…ˆè·å–ç©ºç™½è¡Œåˆ†ç»„
        blank_line_groups = self._extract_blank_line_groups(content, start_line, end_line)
        
        if not blank_line_groups:
            return []
        
        result = []
        for group in blank_line_groups:
            group_line_count = group['end_line'] - group['start_line'] + 1
            if group_line_count > 20:
                # å¦‚æœå—è¶…è¿‡20è¡Œï¼ŒæŒ‰æ¯20è¡Œåˆ†å‰²
                sub_groups = self._extract_line_groups(
                    content, group['start_line'], group['end_line'], group_size=20
                )
                result.extend(sub_groups)
            else:
                # å¦‚æœå—ä¸è¶…è¿‡20è¡Œï¼Œç›´æ¥æ·»åŠ 
                result.append(group)
        
        return result
    
    def _extract_line_groups(
        self, content: str, start_line: int, end_line: int, group_size: int = 20
    ) -> List[Dict[str, Any]]:
        """æŒ‰è¡Œå·åˆ†ç»„æå–å†…å®¹ï¼ˆå§”æ‰˜ç»™StructuredCodeExtractorï¼‰"""
        if StructuredCodeExtractor:
            return StructuredCodeExtractor.extract_line_groups(content, start_line, end_line, group_size)
        return []
    
    def _ensure_unique_ids(self, units: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç¡®ä¿å•å…ƒåˆ—è¡¨ä¸­æ‰€æœ‰idå”¯ä¸€ï¼ˆå§”æ‰˜ç»™StructuredCodeExtractorï¼‰"""
        if StructuredCodeExtractor:
            return StructuredCodeExtractor.ensure_unique_ids(units)
        return units
    
    def _extract_imports(self, filepath: str, content: str, start_line: int, end_line: int) -> List[Dict[str, Any]]:
        """æå–æ–‡ä»¶çš„å¯¼å…¥/åŒ…å«è¯­å¥ä½œä¸ºç»“æ„åŒ–å•å…ƒï¼ˆå§”æ‰˜ç»™StructuredCodeExtractorï¼‰"""
        if StructuredCodeExtractor:
            return StructuredCodeExtractor.extract_imports(filepath, content, start_line, end_line)
        return []
    
    def _create_import_unit(self, import_group: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ›å»ºå¯¼å…¥è¯­å¥å•å…ƒï¼ˆå§”æ‰˜ç»™StructuredCodeExtractorï¼‰"""
        if StructuredCodeExtractor:
            return StructuredCodeExtractor.create_import_unit(import_group)
        return {}
    
    def _format_structured_output(
        self, filepath: str, units: List[Dict[str, Any]], total_lines: int
    ) -> str:
        """æ ¼å¼åŒ–ç»“æ„åŒ–è¾“å‡º
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            units: è¯­æ³•å•å…ƒæˆ–è¡Œå·åˆ†ç»„åˆ—è¡¨ï¼ˆå·²åŒ…å«å¯¼å…¥è¯­å¥å•å…ƒï¼‰
            total_lines: æ–‡ä»¶æ€»è¡Œæ•°
            
        Returns:
            æ ¼å¼åŒ–åçš„è¾“å‡ºå­—ç¬¦ä¸²
        """
        output_lines = [
            f"\nğŸ” æ–‡ä»¶: {filepath}",
            f"ğŸ“„ æ€»è¡Œæ•°: {total_lines}",
            f"ğŸ“¦ ç»“æ„åŒ–å•å…ƒæ•°: {len(units)}\n",
        ]
        
        for unit in units:
            # æ˜¾ç¤ºid
            output_lines.append(f"[id:{unit['id']}]")
            # æ·»åŠ å†…å®¹ï¼Œä¿æŒåŸæœ‰ç¼©è¿›ï¼Œå¹¶æ·»åŠ è¡Œå·
            content_lines = unit['content'].split('\n')
            current_line_num = unit['start_line']
            for line in content_lines:
                # è¡Œå·æ ¼å¼ï¼š5ä½å³å¯¹é½ï¼Œåé¢åŠ å†’å·
                output_lines.append(f"{current_line_num:5d}:{line}")
                current_line_num += 1
            output_lines.append("")  # å•å…ƒä¹‹é—´ç©ºè¡Œåˆ†éš”
        
        return '\n'.join(output_lines)
    
    def _estimate_structured_tokens(
        self, filepath: str, content: str, start_line: int, end_line: int, total_lines: int, raw_mode: bool = False
    ) -> int:
        """ä¼°ç®—ç»“æ„åŒ–è¾“å‡ºçš„tokenæ•°
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            content: æ–‡ä»¶å†…å®¹
            start_line: èµ·å§‹è¡Œå·
            end_line: ç»“æŸè¡Œå·
            total_lines: æ–‡ä»¶æ€»è¡Œæ•°
            
        Returns:
            ä¼°ç®—çš„tokenæ•°
        """
        try:
            if raw_mode:
                # åŸå§‹æ¨¡å¼ï¼šæŒ‰æ¯20è¡Œåˆ†ç»„è®¡ç®—token
                line_groups = self._extract_line_groups(content, start_line, end_line, group_size=20)
                if line_groups:
                    import_units = self._extract_imports(filepath, content, start_line, end_line)
                    all_units = import_units + line_groups[:1]
                    # ç¡®ä¿idå”¯ä¸€
                    all_units = self._ensure_unique_ids(all_units)
                    # æŒ‰è¡Œå·æ’åº
                    all_units.sort(key=lambda u: u['start_line'])
                    sample_output = self._format_structured_output(filepath, all_units, total_lines)
                    if len(line_groups) > 1:
                        group_tokens = get_context_token_count(sample_output)
                        return group_tokens * len(line_groups)
                    else:
                        return get_context_token_count(sample_output)
            else:
                # å°è¯•æå–è¯­æ³•å•å…ƒ
                syntax_units = self._extract_syntax_units(filepath, content, start_line, end_line)
                
                if syntax_units:
                    # ä½¿ç”¨è¯­æ³•å•å…ƒç»“æ„åŒ–è¾“å‡ºæ ¼å¼è®¡ç®—token
                    import_units = self._extract_imports(filepath, content, start_line, end_line)
                    all_units = import_units + syntax_units[:1]
                    # ç¡®ä¿idå”¯ä¸€
                    all_units = self._ensure_unique_ids(all_units)
                    # æŒ‰è¡Œå·æ’åº
                    all_units.sort(key=lambda u: u['start_line'])
                    sample_output = self._format_structured_output(filepath, all_units, total_lines)
                    if len(syntax_units) > 1:
                        unit_tokens = get_context_token_count(sample_output)
                        return unit_tokens * len(syntax_units)
                    else:
                        return get_context_token_count(sample_output)
                else:
                    # ä½¿ç”¨ç©ºç™½è¡Œåˆ†ç»„æ ¼å¼è®¡ç®—tokenï¼ˆä¸æ”¯æŒè¯­è¨€æ—¶ï¼‰
                    # å…ˆæŒ‰ç©ºè¡Œåˆ†å‰²ï¼Œç„¶åå¯¹è¶…è¿‡20è¡Œçš„å—å†æŒ‰æ¯20è¡Œåˆ†å‰²
                    line_groups = self._extract_blank_line_groups_with_split(content, start_line, end_line)
                    if line_groups:
                        import_units = self._extract_imports(filepath, content, start_line, end_line)
                        all_units = import_units + line_groups[:1]
                        # ç¡®ä¿idå”¯ä¸€
                        all_units = self._ensure_unique_ids(all_units)
                        # æŒ‰è¡Œå·æ’åº
                        all_units.sort(key=lambda u: u['start_line'])
                        sample_output = self._format_structured_output(filepath, all_units, total_lines)
                        if len(line_groups) > 1:
                            group_tokens = get_context_token_count(sample_output)
                            return group_tokens * len(line_groups)
                        else:
                            return get_context_token_count(sample_output)
                    else:
                        # å›é€€åˆ°åŸå§‹æ ¼å¼è®¡ç®—
                        lines = content.split('\n')
                        selected_lines = lines[start_line - 1:end_line]
                        numbered_content = "".join(f"{i:5d}:{line}\n" for i, line in enumerate(selected_lines, start=start_line))
                        return get_context_token_count(numbered_content)
        except Exception:
            # å¦‚æœä¼°ç®—å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„è¡Œå·æ ¼å¼ä¼°ç®—
            lines = content.split('\n')
            selected_lines = lines[start_line - 1:end_line]
            numbered_content = "".join(f"{i:5d}:{line}\n" for i, line in enumerate(selected_lines, start=start_line))
            return get_context_token_count(numbered_content)
    
    def _get_max_token_limit(self, agent: Any = None) -> int:
        """è·å–åŸºäºæœ€å¤§çª—å£æ•°é‡çš„tokené™åˆ¶
        
        Args:
            agent: Agentå®ä¾‹ï¼Œç”¨äºè·å–æ¨¡å‹ç»„é…ç½®
            
        Returns:
            int: å…è®¸çš„æœ€å¤§tokenæ•°ï¼ˆ2/3æœ€å¤§çª—å£ï¼‰
        """
        try:
            # å°è¯•ä»agentè·å–æ¨¡å‹ç»„
            model_group = None
            if agent:
                model_group = getattr(agent, "model_group", None)
            
            max_input_tokens = get_max_input_token_count(model_group)
            # è®¡ç®—2/3é™åˆ¶çš„tokenæ•°
            limit_tokens = int(max_input_tokens * 2 / 3)
            return limit_tokens
        except Exception:
            # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆå‡è®¾32000 tokenï¼Œ2/3æ˜¯21333ï¼‰
            return 21333

    def _handle_single_file(
        self, filepath: str, start_line: int = 1, end_line: int = -1, agent: Any = None, raw_mode: bool = False
    ) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶çš„è¯»å–æ“ä½œ

        Args:
            filepath (str): æ–‡ä»¶è·¯å¾„
            start_line (int): èµ·å§‹è¡Œå·ï¼Œé»˜è®¤ä¸º1
            end_line (int): ç»“æŸè¡Œå·ï¼Œé»˜è®¤ä¸º-1è¡¨ç¤ºæ–‡ä»¶æœ«å°¾
            agent: Agentå®ä¾‹ï¼Œç”¨äºè·å–ä¸Šä¸‹æ–‡ç®¡ç†å™¨

        Returns:
            Dict[str, Any]: åŒ…å«æˆåŠŸçŠ¶æ€ã€è¾“å‡ºå†…å®¹å’Œé”™è¯¯ä¿¡æ¯çš„å­—å…¸
        """
        try:
            abs_path = os.path.abspath(filepath)

            # æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
            if not os.path.exists(abs_path):
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": f"æ–‡ä»¶ä¸å­˜åœ¨: {abs_path}",
                }

            # æ–‡ä»¶å¤§å°é™åˆ¶æ£€æŸ¥ï¼ˆ10MBï¼‰
            if os.path.getsize(abs_path) > 10 * 1024 * 1024:
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": "æ–‡ä»¶è¿‡å¤§ (>10MB)",
                }

            # è¯»å–æ–‡ä»¶å†…å®¹
            # ç¬¬ä¸€éæµå¼è¯»å–ï¼Œä»…ç»Ÿè®¡æ€»è¡Œæ•°ï¼Œé¿å…ä¸€æ¬¡æ€§è¯»å…¥å†…å­˜
            with open(abs_path, "r", encoding="utf-8", errors="ignore") as f:
                total_lines = sum(1 for _ in f)

            # å¤„ç†ç©ºæ–‡ä»¶æƒ…å†µ
            if total_lines == 0:
                return {
                    "success": True,
                    "stdout": f"\nğŸ” æ–‡ä»¶: {abs_path}\nğŸ“„ æ–‡ä»¶ä¸ºç©º (0è¡Œ)\n",
                    "stderr": "",
                }

            # å¤„ç†ç‰¹æ®Šå€¼-1è¡¨ç¤ºæ–‡ä»¶æœ«å°¾
            if end_line == -1:
                end_line = total_lines
            else:
                end_line = (
                    max(1, min(end_line, total_lines))
                    if end_line >= 0
                    else total_lines + end_line + 1
                )

            start_line = (
                max(1, min(start_line, total_lines))
                if start_line >= 0
                else total_lines + start_line + 1
            )

            if start_line > end_line:

                return {
                    "success": False,
                    "stdout": "",
                    "stderr": f"æ— æ•ˆçš„è¡ŒèŒƒå›´ [{start_line}-{end_line}] (æ€»è¡Œæ•°: {total_lines})",
                }

            # è¯»å–å®Œæ•´æ–‡ä»¶å†…å®¹ç”¨äºè¯­æ³•åˆ†æå’Œtokenè®¡ç®—
            with open(abs_path, "r", encoding="utf-8", errors="ignore") as f:
                full_content = f.read()
            
            # è¯»å–è¦è¯»å–çš„è¡ŒèŒƒå›´å†…å®¹
            selected_content_lines = []
            lines = full_content.split('\n')
            for i in range(start_line - 1, min(end_line, len(lines))):
                selected_content_lines.append(lines[i])
            
            # ä¼°ç®—ç»“æ„åŒ–è¾“å‡ºçš„tokenæ•°
            content_tokens = self._estimate_structured_tokens(abs_path, full_content, start_line, end_line, total_lines, raw_mode)
            
            max_token_limit = self._get_max_token_limit(agent)
            
            # æ£€æŸ¥å•æ–‡ä»¶è¯»å–tokenæ•°æ˜¯å¦è¶…è¿‡2/3é™åˆ¶
            if content_tokens > max_token_limit:
                read_lines = end_line - start_line + 1
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": (
                        f"âš ï¸ è¯»å–èŒƒå›´è¿‡å¤§: è¯·æ±‚è¯»å–å†…å®¹çº¦ {content_tokens} tokensï¼Œè¶…è¿‡é™åˆ¶ ({max_token_limit} tokensï¼Œçº¦2/3æœ€å¤§çª—å£)\n"
                        f"ğŸ“Š è¯»å–èŒƒå›´: {read_lines} è¡Œ (ç¬¬ {start_line}-{end_line} è¡Œï¼Œæ–‡ä»¶æ€»è¡Œæ•° {total_lines})\n"
                        f"ğŸ’¡ å»ºè®®ï¼š\n"
                        f"   1. åˆ†æ‰¹è¯»å–ï¼šå°†èŒƒå›´åˆ†æˆå¤šä¸ªè¾ƒå°çš„æ‰¹æ¬¡ï¼Œæ¯æ‰¹å†…å®¹ä¸è¶…è¿‡ {max_token_limit} tokens\n"
                        f"   2. å…ˆå®šä½ï¼šä½¿ç”¨æœç´¢æˆ–åˆ†æå·¥å…·å®šä½å¤§è‡´ä½ç½®ï¼Œå†è¯»å–å…·ä½“èŒƒå›´\n"
                        f"   3. ç¼©å°èŒƒå›´ï¼šä¸ºæ–‡ä»¶æŒ‡å®šæ›´ç²¾ç¡®çš„è¡Œå·èŒƒå›´"
                    ),
                }

            # æå–å¯¼å…¥/åŒ…å«è¯­å¥ä½œä¸ºç»“æ„åŒ–å•å…ƒ
            import_units = self._extract_imports(abs_path, full_content, start_line, end_line)
            
            # ç¡®å®šä½¿ç”¨çš„ç»“æ„åŒ–å•å…ƒï¼ˆè¯­æ³•å•å…ƒæˆ–è¡Œå·åˆ†ç»„ï¼‰
            structured_units = None
            # unit_type = None
            
            if raw_mode:
                # åŸå§‹è¯»å–æ¨¡å¼ï¼šæŒ‰æ¯20è¡Œåˆ†ç»„
                line_groups = self._extract_line_groups(full_content, start_line, end_line, group_size=20)
                # åˆå¹¶å¯¼å…¥å•å…ƒå’Œè¡Œå·åˆ†ç»„
                all_units = import_units + line_groups
                # ç¡®ä¿idå”¯ä¸€
                all_units = self._ensure_unique_ids(all_units)
                # æŒ‰è¡Œå·æ’åºï¼Œæ‰€æœ‰å•å…ƒæŒ‰åœ¨æ–‡ä»¶ä¸­çš„å®é™…ä½ç½®æ’åº
                all_units.sort(key=lambda u: u['start_line'])
                structured_units = all_units
                # unit_type = "line_groups"
                output = self._format_structured_output(abs_path, structured_units, total_lines)
            else:
                # å°è¯•æå–è¯­æ³•å•å…ƒï¼ˆç»“æ„åŒ–è¯»å–ï¼Œfull_content å·²åœ¨ä¸Šé¢è¯»å–ï¼‰
                syntax_units = self._extract_syntax_units(abs_path, full_content, start_line, end_line)
                
                # æ£€æµ‹è¯­è¨€ç±»å‹
                # language = None
                if LANGUAGE_SUPPORT_AVAILABLE:
                    try:
                        detect_language(abs_path)
                    except Exception:
                        pass
                
                if syntax_units:
                    # åˆå¹¶å¯¼å…¥å•å…ƒå’Œè¯­æ³•å•å…ƒ
                    all_units = import_units + syntax_units
                    # ç¡®ä¿idå”¯ä¸€
                    all_units = self._ensure_unique_ids(all_units)
                    # æŒ‰è¡Œå·æ’åºï¼Œæ‰€æœ‰å•å…ƒæŒ‰åœ¨æ–‡ä»¶ä¸­çš„å®é™…ä½ç½®æ’åº
                    all_units.sort(key=lambda u: u['start_line'])
                    structured_units = all_units
                    # unit_type = "syntax_units"
                    output = self._format_structured_output(abs_path, structured_units, total_lines)
                else:
                    # ä½¿ç”¨ç©ºç™½è¡Œåˆ†ç»„ç»“æ„åŒ–è¾“å‡ºï¼ˆä¸æ”¯æŒè¯­è¨€æ—¶ï¼‰
                    # å…ˆæŒ‰ç©ºè¡Œåˆ†å‰²ï¼Œç„¶åå¯¹è¶…è¿‡20è¡Œçš„å—å†æŒ‰æ¯20è¡Œåˆ†å‰²
                    line_groups = self._extract_blank_line_groups_with_split(full_content, start_line, end_line)
                    # åˆå¹¶å¯¼å…¥å•å…ƒå’Œè¡Œå·åˆ†ç»„
                    all_units = import_units + line_groups
                    # ç¡®ä¿idå”¯ä¸€
                    all_units = self._ensure_unique_ids(all_units)
                    # æŒ‰è¡Œå·æ’åºï¼Œæ‰€æœ‰å•å…ƒæŒ‰åœ¨æ–‡ä»¶ä¸­çš„å®é™…ä½ç½®æ’åº
                    all_units.sort(key=lambda u: u['start_line'])
                    structured_units = all_units
                    # unit_type = "line_groups"
                    output = self._format_structured_output(abs_path, structured_units, total_lines)

            # å°è¯•è·å–å¹¶é™„åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
            context_info = self._get_file_context(abs_path, start_line, end_line, agent)
            if context_info:
                output += context_info

            if agent:
                files = agent.get_user_data("files")
                if files:
                    files.append(abs_path)
                else:
                    files = [abs_path]
                agent.set_user_data("files", files)

            return {"success": True, "stdout": output, "stderr": ""}

        except Exception as e:
            PrettyOutput.print(str(e), OutputType.ERROR)
            return {"success": False, "stdout": "", "stderr": f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}"}

    def _get_file_context(
        self, filepath: str, start_line: int, end_line: int, agent: Any = None
    ) -> str:
        """è·å–æ–‡ä»¶çš„ä¸Šä¸‹æ–‡ä¿¡æ¯

        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            start_line: èµ·å§‹è¡Œå·
            end_line: ç»“æŸè¡Œå·
            agent: Agentå®ä¾‹

        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å­—ç¬¦ä¸²ï¼Œå¦‚æœæ— æ³•è·å–åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            # å°è¯•ä»Agentè·å–CodeAgentå®ä¾‹
            if not agent:
                return ""

            # é€šè¿‡agentè·å–CodeAgentå®ä¾‹
            # CodeAgentåœ¨åˆå§‹åŒ–æ—¶ä¼šå°†è‡ªèº«å…³è”åˆ°agent
            code_agent = getattr(agent, "_code_agent", None)
            if not code_agent:
                return ""

            # è·å–ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            context_manager = getattr(code_agent, "context_manager", None)
            if not context_manager:
                return ""

            # è¾“å‡ºä¸Šä¸‹æ–‡æ„ŸçŸ¥æ—¥å¿—
            file_name = os.path.basename(filepath)
            if start_line == end_line:
                line_info = f"ç¬¬{start_line}è¡Œ"
            else:
                line_info = f"ç¬¬{start_line}-{end_line}è¡Œ"
            PrettyOutput.print(f"ğŸ§  æ­£åœ¨åˆ†æä»£ç ä¸Šä¸‹æ–‡ ({file_name}, {line_info})...", OutputType.INFO)

            # ç¡®ä¿æ–‡ä»¶å·²æ›´æ–°åˆ°ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            # å¦‚æœæ–‡ä»¶å†…å®¹å·²ç¼“å­˜ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™è¯»å–å¹¶æ›´æ–°
            if not hasattr(context_manager, "_file_cache") or filepath not in context_manager._file_cache:
                try:
                    with open(filepath, "r", encoding="utf-8", errors="replace") as f:
                        content = f.read()
                    context_manager.update_context_for_file(filepath, content)
                except Exception:
                    # å¦‚æœè¯»å–å¤±è´¥ï¼Œå°è¯•è·å–å·²æœ‰ä¸Šä¸‹æ–‡
                    pass

            # è·å–ç¼–è¾‘ä¸Šä¸‹æ–‡
            edit_context = context_manager.get_edit_context(filepath, start_line, end_line)

            # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
            if not edit_context.context_summary or edit_context.context_summary == "No context available":
                return ""

            # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ä¿¡æ¯
            context_lines = ["\nğŸ“‹ ä»£ç ä¸Šä¸‹æ–‡ä¿¡æ¯:"]
            context_lines.append("â”€" * 60)

            if edit_context.current_scope:
                scope_info = f"ğŸ“ å½“å‰ä½œç”¨åŸŸ: {edit_context.current_scope.kind} `{edit_context.current_scope.name}`"
                if edit_context.current_scope.signature:
                    scope_info += f"\n   â””â”€ ç­¾å: {edit_context.current_scope.signature}"
                context_lines.append(scope_info)

            if edit_context.used_symbols:
                symbol_names = [s.name for s in edit_context.used_symbols[:10]]
                symbols_str = ", ".join(f"`{name}`" for name in symbol_names)
                more = len(edit_context.used_symbols) - 10
                if more > 0:
                    symbols_str += f" (è¿˜æœ‰{more}ä¸ª)"
                context_lines.append(f"ğŸ”— ä½¿ç”¨çš„ç¬¦å·: {symbols_str}")

            # ä¸å†æ„ŸçŸ¥å¯¼å…¥ç¬¦å·

            if edit_context.relevant_files:
                rel_files = edit_context.relevant_files[:10]
                files_str = "\n   ".join(f"â€¢ {os.path.relpath(f, context_manager.project_root)}" for f in rel_files)
                more = len(edit_context.relevant_files) - 10
                if more > 0:
                    files_str += f"\n   ... è¿˜æœ‰{more}ä¸ªç›¸å…³æ–‡ä»¶"
                context_lines.append(f"ğŸ“ ç›¸å…³æ–‡ä»¶ ({len(edit_context.relevant_files)}ä¸ª):\n   {files_str}")

            context_lines.append("â”€" * 60)
            context_lines.append("")  # ç©ºè¡Œ

            # æ‰“å°ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç»“æœåˆ°æ§åˆ¶å°
            context_output = "\n".join(context_lines)
            PrettyOutput.print(f"ğŸ§  ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç»“æœ:\n{context_output}", OutputType.INFO)
            
            return context_output

        except Exception:
            # é™é»˜å¤±è´¥ï¼Œä¸å½±å“æ–‡ä»¶è¯»å–
            return ""

    def execute(self, args: Dict) -> Dict[str, Any]:
        """æ‰§è¡Œä»£ç è¯»å–æ“ä½œ

        Args:
            args (Dict): åŒ…å«æ–‡ä»¶åˆ—è¡¨çš„å‚æ•°å­—å…¸

        Returns:
            Dict[str, Any]: åŒ…å«æˆåŠŸçŠ¶æ€ã€è¾“å‡ºå†…å®¹å’Œé”™è¯¯ä¿¡æ¯çš„å­—å…¸
        """
        try:
            agent = args.get("agent", None)
            if "files" not in args or not isinstance(args["files"], list):
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": "å‚æ•°ä¸­å¿…é¡»åŒ…å«æ–‡ä»¶åˆ—è¡¨",
                }

            all_outputs = []
            overall_success = True
            status_lines = []
            total_tokens = 0  # ç´¯è®¡è¯»å–çš„tokenæ•°
            max_token_limit = self._get_max_token_limit(agent)

            # ç¬¬ä¸€éï¼šæ£€æŸ¥æ‰€æœ‰æ–‡ä»¶çš„ç´¯è®¡tokenæ•°æ˜¯å¦è¶…è¿‡é™åˆ¶
            file_read_info = []  # å­˜å‚¨æ¯ä¸ªæ–‡ä»¶è¦è¯»å–çš„ä¿¡æ¯
            for file_info in args["files"]:
                if not isinstance(file_info, dict) or "path" not in file_info:
                    continue
                
                filepath = file_info["path"].strip()
                start_line = file_info.get("start_line", 1)
                end_line = file_info.get("end_line", -1)
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶è®¡ç®—è¦è¯»å–çš„tokenæ•°
                abs_path = os.path.abspath(filepath)
                if not os.path.exists(abs_path):
                    continue
                
                try:
                    # ç»Ÿè®¡æ€»è¡Œæ•°
                    with open(abs_path, "r", encoding="utf-8", errors="ignore") as f:
                        total_lines = sum(1 for _ in f)
                    
                    if total_lines == 0:
                        continue
                    
                    # è®¡ç®—å®é™…è¦è¯»å–çš„è¡ŒèŒƒå›´
                    if end_line == -1:
                        actual_end_line = total_lines
                    else:
                        actual_end_line = (
                            max(1, min(end_line, total_lines))
                            if end_line >= 0
                            else total_lines + end_line + 1
                        )
                    
                    actual_start_line = (
                        max(1, min(start_line, total_lines))
                        if start_line >= 0
                        else total_lines + start_line + 1
                    )
                    
                    if actual_start_line <= actual_end_line:
                        # è¯»å–å®Œæ•´æ–‡ä»¶å†…å®¹ç”¨äºtokenä¼°ç®—
                        with open(abs_path, "r", encoding="utf-8", errors="ignore") as f:
                            file_content = f.read()
                        
                        # ä¼°ç®—ç»“æ„åŒ–è¾“å‡ºçš„tokenæ•°
                        raw_mode = file_info.get("raw_mode", False)
                        content_tokens = self._estimate_structured_tokens(
                            abs_path, file_content, actual_start_line, actual_end_line, total_lines, raw_mode
                        )
                        
                        file_read_info.append({
                            "filepath": filepath,
                            "start_line": actual_start_line,
                            "end_line": actual_end_line,
                            "read_lines": actual_end_line - actual_start_line + 1,
                            "tokens": content_tokens,
                            "file_info": file_info,
                        })
                        total_tokens += content_tokens
                except Exception:
                    continue

            # æ£€æŸ¥ç´¯è®¡tokenæ•°æ˜¯å¦è¶…è¿‡é™åˆ¶
            if total_tokens > max_token_limit:
                file_list = "\n   ".join(
                    f"â€¢ {info['filepath']}: {info['tokens']} tokens ({info['read_lines']} è¡Œ, èŒƒå›´: {info['start_line']}-{info['end_line']})"
                    for info in file_read_info[:10]
                )
                more_files = len(file_read_info) - 10
                if more_files > 0:
                    file_list += f"\n   ... è¿˜æœ‰ {more_files} ä¸ªæ–‡ä»¶"
                
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": (
                        f"âš ï¸ ç´¯è®¡è¯»å–èŒƒå›´è¿‡å¤§: è¯·æ±‚ç´¯è®¡è¯»å–å†…å®¹çº¦ {total_tokens} tokensï¼Œè¶…è¿‡é™åˆ¶ ({max_token_limit} tokensï¼Œçº¦2/3æœ€å¤§çª—å£)\n"
                        f"ğŸ“‹ æ–‡ä»¶åˆ—è¡¨ ({len(file_read_info)} ä¸ªæ–‡ä»¶):\n   {file_list}\n"
                        f"ğŸ’¡ å»ºè®®ï¼š\n"
                        f"   1. åˆ†æ‰¹è¯»å–ï¼šå°†æ–‡ä»¶åˆ†æˆå¤šä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹ç´¯è®¡å†…å®¹ä¸è¶…è¿‡ {max_token_limit} tokens\n"
                        f"   2. å…ˆå®šä½ï¼šä½¿ç”¨æœç´¢æˆ–åˆ†æå·¥å…·å®šä½å…³é”®ä»£ç ä½ç½®ï¼Œå†è¯»å–å…·ä½“èŒƒå›´\n"
                        f"   3. ç¼©å°èŒƒå›´ï¼šä¸ºæ¯ä¸ªæ–‡ä»¶æŒ‡å®šæ›´ç²¾ç¡®çš„è¡Œå·èŒƒå›´"
                    ),
                }

            # ç¬¬äºŒéï¼šå®é™…è¯»å–æ–‡ä»¶
            for file_info in args["files"]:
                if not isinstance(file_info, dict) or "path" not in file_info:
                    continue

                result = self._handle_single_file(
                    file_info["path"].strip(),
                    file_info.get("start_line", 1),
                    file_info.get("end_line", -1),
                    agent,
                    file_info.get("raw_mode", False),
                )

                if result["success"]:
                    all_outputs.append(result["stdout"])
                    status_lines.append(f"âœ… {file_info['path']} æ–‡ä»¶è¯»å–æˆåŠŸ")
                else:
                    all_outputs.append(f"âŒ {file_info['path']}: {result['stderr']}")
                    status_lines.append(f"âŒ {file_info['path']} æ–‡ä»¶è¯»å–å¤±è´¥")
                    overall_success = False

            stdout_text = "\n".join(all_outputs)
            # ä»…æ‰“å°æ¯ä¸ªæ–‡ä»¶çš„è¯»å–çŠ¶æ€ï¼Œä¸æ‰“å°å…·ä½“å†…å®¹
            try:
                if status_lines:
                    print("\n".join(status_lines), end="\n")
            except Exception:
                pass
            return {
                "success": overall_success,
                "stdout": stdout_text,
                "stderr": "",
            }

        except Exception as e:
            PrettyOutput.print(str(e), OutputType.ERROR)
            return {"success": False, "stdout": "", "stderr": f"ä»£ç è¯»å–å¤±è´¥: {str(e)}"}


def main():
    """æµ‹è¯•ç»“æ„åŒ–è¯»å–åŠŸèƒ½"""
    import tempfile
    import os
    
    tool = ReadCodeTool()
    
    print("=" * 80)
    print("æµ‹è¯•ç»“æ„åŒ–è¯»å–åŠŸèƒ½")
    print("=" * 80)
    
    # æµ‹è¯•1: Cè¯­è¨€æ–‡ä»¶ï¼ˆtree-sitteræ”¯æŒï¼‰
    print("\nã€æµ‹è¯•1ã€‘Cè¯­è¨€æ–‡ä»¶ - è¯­æ³•å•å…ƒæå–")
    print("-" * 80)
    
    c_code = """#include <stdio.h>

void main() {
    printf("Hello, World!\\n");
}

int add(int a, int b) {
    return a + b;
}

int sub(int a, int b) {
    return a - b;
}

struct Point {
    int x;
    int y;
};
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.c', delete=False) as f:
        c_file = f.name
        f.write(c_code)
    
    try:
        result = tool.execute({
            "files": [{"path": c_file, "start_line": 1, "end_line": -1}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… Cè¯­è¨€æ–‡ä»¶è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹:")
            print(result["stdout"])
        else:
            print(f"âŒ Cè¯­è¨€æ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(c_file)
    
    # æµ‹è¯•2: Pythonæ–‡ä»¶ï¼ˆASTæ”¯æŒï¼‰
    print("\nã€æµ‹è¯•2ã€‘Pythonæ–‡ä»¶ - è¯­æ³•å•å…ƒæå–")
    print("-" * 80)
    
    python_code = """def main():
    print("Hello, World!")

def add(a, b):
    return a + b

def sub(a, b):
    return a - b

class Point:
    def __init__(self, x, y):
        self.x = x
        self.y = y
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        py_file = f.name
        f.write(python_code)
    
    try:
        result = tool.execute({
            "files": [{"path": py_file, "start_line": 1, "end_line": -1}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… Pythonæ–‡ä»¶è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹:")
            print(result["stdout"])
        else:
            print(f"âŒ Pythonæ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(py_file)
    
    # æµ‹è¯•3: ä¸æ”¯æŒçš„è¯­è¨€ - è¡Œå·åˆ†ç»„
    print("\nã€æµ‹è¯•3ã€‘ä¸æ”¯æŒçš„è¯­è¨€ - è¡Œå·åˆ†ç»„ï¼ˆ20è¡Œä¸€ç»„ï¼‰")
    print("-" * 80)
    
    text_content = "\n".join([f"è¿™æ˜¯ç¬¬ {i} è¡Œå†…å®¹" for i in range(1, 51)])
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        txt_file = f.name
        f.write(text_content)
    
    try:
        result = tool.execute({
            "files": [{"path": txt_file, "start_line": 1, "end_line": -1}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… æ–‡æœ¬æ–‡ä»¶è¯»å–æˆåŠŸï¼ˆä½¿ç”¨è¡Œå·åˆ†ç»„ï¼‰")
            print("\nè¾“å‡ºå†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰:")
            print(result["stdout"][:500] + "..." if len(result["stdout"]) > 500 else result["stdout"])
        else:
            print(f"âŒ æ–‡æœ¬æ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(txt_file)
    
    # æµ‹è¯•4: æŒ‡å®šè¡Œå·èŒƒå›´
    print("\nã€æµ‹è¯•4ã€‘æŒ‡å®šè¡Œå·èŒƒå›´è¯»å–")
    print("-" * 80)
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.c', delete=False) as f:
        c_file2 = f.name
        f.write(c_code)
    
    try:
        result = tool.execute({
            "files": [{"path": c_file2, "start_line": 1, "end_line": 10}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… æŒ‡å®šèŒƒå›´è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹:")
            print(result["stdout"])
        else:
            print(f"âŒ æŒ‡å®šèŒƒå›´è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(c_file2)
    
    # æµ‹è¯•5: è¾¹ç•Œæƒ…å†µ - è¿”å›è¾¹ç•Œä¸Šçš„è¯­æ³•å•å…ƒ
    print("\nã€æµ‹è¯•5ã€‘è¾¹ç•Œæƒ…å†µ - è¿”å›è¾¹ç•Œä¸Šçš„è¯­æ³•å•å…ƒ")
    print("-" * 80)
    
    boundary_test_code = """def func1():
    line1 = 1
    line2 = 2
    line3 = 3

def func2():
    line1 = 1
    line2 = 2

def func3():
    line1 = 1
    line2 = 2
    line3 = 3
    line4 = 4
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        boundary_file = f.name
        f.write(boundary_test_code)
    
    try:
        # è¯·æ±‚ç¬¬3-8è¡Œ
        # func1: 1-4è¡Œï¼ˆç»“æŸè¡Œ4åœ¨èŒƒå›´å†…ï¼Œåº”è¯¥è¿”å›å®Œæ•´func1ï¼‰
        # func2: 6-8è¡Œï¼ˆå¼€å§‹è¡Œ6åœ¨èŒƒå›´å†…ï¼Œåº”è¯¥è¿”å›å®Œæ•´func2ï¼‰
        # func3: 10-14è¡Œï¼ˆå®Œå…¨ä¸åœ¨èŒƒå›´å†…ï¼Œä¸åº”è¯¥è¿”å›ï¼‰
        result = tool.execute({
            "files": [{"path": boundary_file, "start_line": 3, "end_line": 8}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… è¾¹ç•Œæƒ…å†µæµ‹è¯•æˆåŠŸ")
            print("è¯·æ±‚èŒƒå›´: 3-8è¡Œ")
            print("é¢„æœŸç»“æœ:")
            print("  - func1 (1-4è¡Œ): ç»“æŸè¡Œ4åœ¨èŒƒå›´å†…ï¼Œåº”è¿”å›å®Œæ•´func1")
            print("  - func2 (6-8è¡Œ): å¼€å§‹è¡Œ6åœ¨èŒƒå›´å†…ï¼Œåº”è¿”å›å®Œæ•´func2")
            print("  - func3 (10-14è¡Œ): å®Œå…¨ä¸åœ¨èŒƒå›´å†…ï¼Œä¸åº”è¿”å›")
            print("\nå®é™…è¾“å‡º:")
            print(result["stdout"])
        else:
            print(f"âŒ è¾¹ç•Œæƒ…å†µæµ‹è¯•å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(boundary_file)
    
    # æµ‹è¯•6: å¤šä¸ªæ–‡ä»¶
    print("\nã€æµ‹è¯•6ã€‘å¤šä¸ªæ–‡ä»¶è¯»å–")
    print("-" * 80)
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.c', delete=False) as f1, \
         tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f2:
        c_file3 = f1.name
        py_file2 = f2.name
        f1.write(c_code)
        f2.write(python_code)
    
    try:
        result = tool.execute({
            "files": [
                {"path": c_file3, "start_line": 1, "end_line": -1},
                {"path": py_file2, "start_line": 1, "end_line": -1}
            ],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… å¤šæ–‡ä»¶è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹ï¼ˆå‰800å­—ç¬¦ï¼‰:")
            print(result["stdout"][:800] + "..." if len(result["stdout"]) > 800 else result["stdout"])
        else:
            print(f"âŒ å¤šæ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(c_file3)
        os.unlink(py_file2)
    
    # æµ‹è¯•7: åµŒå¥—ä½œç”¨åŸŸçš„è¾¹ç•Œæƒ…å†µ
    print("\nã€æµ‹è¯•7ã€‘åµŒå¥—ä½œç”¨åŸŸçš„è¾¹ç•Œæƒ…å†µ")
    print("-" * 80)
    
    nested_code = """class Outer:
    def method1(self):
        line1 = 1
        line2 = 2
    
    def method2(self):
        line1 = 1
        line2 = 2
        line3 = 3

def standalone_func():
    line1 = 1
    line2 = 2
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        nested_file = f.name
        f.write(nested_code)
    
    try:
        # è¯·æ±‚ç¬¬4-7è¡Œ
        # Outer.method1: 2-4è¡Œï¼ˆç»“æŸè¡Œ4åœ¨èŒƒå›´å†…ï¼Œåº”è¯¥è¿”å›å®Œæ•´method1ï¼‰
        # Outer.method2: 6-9è¡Œï¼ˆå¼€å§‹è¡Œ6åœ¨èŒƒå›´å†…ï¼Œåº”è¯¥è¿”å›å®Œæ•´method2ï¼‰
        # Outerç±»: 1-9è¡Œï¼ˆåŒ…å«method1å’Œmethod2ï¼Œåº”è¯¥è¿”å›ï¼‰
        # standalone_func: 11-13è¡Œï¼ˆå®Œå…¨ä¸åœ¨èŒƒå›´å†…ï¼Œä¸åº”è¿”å›ï¼‰
        result = tool.execute({
            "files": [{"path": nested_file, "start_line": 4, "end_line": 7}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… åµŒå¥—ä½œç”¨åŸŸè¾¹ç•Œæµ‹è¯•æˆåŠŸ")
            print("è¯·æ±‚èŒƒå›´: 4-7è¡Œ")
            print("é¢„æœŸç»“æœ:")
            print("  - Outerç±» (1-9è¡Œ): åŒ…å«method1å’Œmethod2ï¼Œåº”è¿”å›")
            print("  - Outer.method1 (2-4è¡Œ): ç»“æŸè¡Œ4åœ¨èŒƒå›´å†…ï¼Œåº”è¿”å›å®Œæ•´method1")
            print("  - Outer.method2 (6-9è¡Œ): å¼€å§‹è¡Œ6åœ¨èŒƒå›´å†…ï¼Œåº”è¿”å›å®Œæ•´method2")
            print("\nå®é™…è¾“å‡º:")
            print(result["stdout"])
        else:
            print(f"âŒ åµŒå¥—ä½œç”¨åŸŸè¾¹ç•Œæµ‹è¯•å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(nested_file)
    
    # æµ‹è¯•8: Javaæ–‡ä»¶ï¼ˆtree-sitteræ”¯æŒï¼‰
    print("\nã€æµ‹è¯•8ã€‘Javaæ–‡ä»¶ - è¯­æ³•å•å…ƒæå–")
    print("-" * 80)
    
    java_code = """public class Main {
    public static void main(String[] args) {
        System.out.println("Hello, World!");
    }
    
    public int add(int a, int b) {
        return a + b;
    }
    
    private int subtract(int a, int b) {
        return a - b;
    }
}

class Point {
    private int x;
    private int y;
    
    public Point(int x, int y) {
        this.x = x;
        this.y = y;
    }
}
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.java', delete=False) as f:
        java_file = f.name
        f.write(java_code)
    
    try:
        result = tool.execute({
            "files": [{"path": java_file, "start_line": 1, "end_line": -1}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… Javaæ–‡ä»¶è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹:")
            print(result["stdout"])
        else:
            print(f"âŒ Javaæ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(java_file)
    
    # æµ‹è¯•9: Rustæ–‡ä»¶ï¼ˆtree-sitteræ”¯æŒï¼‰
    print("\nã€æµ‹è¯•9ã€‘Rustæ–‡ä»¶ - è¯­æ³•å•å…ƒæå–")
    print("-" * 80)
    
    rust_code = """fn main() {
    println!("Hello, World!");
}

fn add(a: i32, b: i32) -> i32 {
    a + b
}

fn subtract(a: i32, b: i32) -> i32 {
    a - b
}

struct Point {
    x: i32,
    y: i32,
}

impl Point {
    fn new(x: i32, y: i32) -> Point {
        Point { x, y }
    }
}

enum Color {
    Red,
    Green,
    Blue,
}
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.rs', delete=False) as f:
        rust_file = f.name
        f.write(rust_code)
    
    try:
        result = tool.execute({
            "files": [{"path": rust_file, "start_line": 1, "end_line": -1}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… Rustæ–‡ä»¶è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹:")
            print(result["stdout"])
        else:
            print(f"âŒ Rustæ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(rust_file)
    
    # æµ‹è¯•10: Goæ–‡ä»¶ï¼ˆtree-sitteræ”¯æŒï¼‰
    print("\nã€æµ‹è¯•10ã€‘Goæ–‡ä»¶ - è¯­æ³•å•å…ƒæå–")
    print("-" * 80)
    
    go_code = """package main

import "fmt"

func main() {
    fmt.Println("Hello, World!")
}

func add(a int, b int) int {
    return a + b
}

func subtract(a int, b int) int {
    return a - b
}

type Point struct {
    x int
    y int
}

func (p *Point) New(x int, y int) {
    p.x = x
    p.y = y
}

type Color int

const (
    Red Color = iota
    Green
    Blue
)

type Shape interface {
    Area() float64
    Perimeter() float64
}

type Drawable interface {
    Draw()
}
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.go', delete=False) as f:
        go_file = f.name
        f.write(go_code)
    
    try:
        result = tool.execute({
            "files": [{"path": go_file, "start_line": 1, "end_line": -1}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… Goæ–‡ä»¶è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹:")
            print(result["stdout"])
        else:
            print(f"âŒ Goæ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(go_file)
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 80)


if __name__ == "__main__":
    main()
