# -*- coding: utf-8 -*-
import os
from typing import Any, Dict, List, Optional

from jarvis.jarvis_utils.config import get_max_input_token_count
from jarvis.jarvis_utils.embedding import get_context_token_count
from jarvis.jarvis_utils.globals import get_global_model_group
from jarvis.jarvis_utils.output import PrettyOutput


class ReadCodeTool:
    name = "read_code"
    description = "è¯»å–æºä»£ç æ–‡ä»¶çš„æŒ‡å®šè¡Œå·èŒƒå›´ï¼Œå¹¶ä¸ºæ¯è¡Œæ·»åŠ è¡Œå·åè¿”å›ã€‚"
    parameters = {
        "type": "object",
        "properties": {
            "files": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "path": {"type": "string"},
                        "start_line": {"type": "number", "default": 1},
                        "end_line": {"type": "number", "default": -1},
                    },
                    "required": ["path"],
                },
                "description": "è¦è¯»å–çš„æ–‡ä»¶åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡ä»¶å¯æŒ‡å®šè¡Œå·èŒƒå›´ï¼ˆstart_line åˆ° end_lineï¼Œ-1 è¡¨ç¤ºæ–‡ä»¶æœ«å°¾ï¼‰ã€‚",
            }
        },
        "required": ["files"],
    }

    def _get_max_token_limit(self, agent: Optional[Any] = None) -> int:
        """è·å–åŸºäºå‰©ä½™tokenæ•°é‡çš„tokené™åˆ¶

        Args:
            agent: Agentå®ä¾‹ï¼Œç”¨äºè·å–æ¨¡å‹å’Œå‰©ä½™tokenæ•°é‡

        Returns:
            int: å…è®¸çš„æœ€å¤§tokenæ•°ï¼ˆå‰©ä½™tokençš„2/3ï¼Œæˆ–è‡³å°‘ä¿ç•™1/3å‰©ä½™tokenï¼‰
        """
        try:
            # ä¼˜å…ˆä½¿ç”¨å‰©ä½™tokenæ•°é‡
            if agent and hasattr(agent, "model"):
                try:
                    remaining_tokens = agent.model.get_remaining_token_count()
                    # ä½¿ç”¨å‰©ä½™tokençš„1/2ä½œä¸ºé™åˆ¶ï¼Œä¿ç•™1/2ä½œä¸ºå®‰å…¨ä½™é‡
                    limit_tokens = int(remaining_tokens * 1 / 2)
                    # ç¡®ä¿è‡³å°‘è¿”å›ä¸€ä¸ªåˆç†çš„å€¼
                    if limit_tokens > 0:
                        return limit_tokens
                except Exception:
                    pass

            # å›é€€æ–¹æ¡ˆï¼šä½¿ç”¨è¾“å…¥çª—å£çš„2/3
            # ä½¿ç”¨å…¨å±€æ¨¡å‹ç»„ï¼ˆä¸å†ä» agent ç»§æ‰¿ï¼‰
            model_group = get_global_model_group()

            max_input_tokens = get_max_input_token_count(model_group)
            # è®¡ç®—1/2é™åˆ¶çš„tokenæ•°
            limit_tokens = int(max_input_tokens * 1 / 2)
            return limit_tokens
        except Exception:
            # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆå‡è®¾128000 tokenï¼Œ2/3æ˜¯85333ï¼‰
            return 21333

    def _handle_single_file(
        self,
        filepath: str,
        start_line: int = 1,
        end_line: int = -1,
        agent: Optional[Any] = None,
    ) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶çš„è¯»å–æ“ä½œ

        Args:
            filepath (str): æ–‡ä»¶è·¯å¾„
            start_line (int): èµ·å§‹è¡Œå·ï¼Œé»˜è®¤ä¸º1
            end_line (int): ç»“æŸè¡Œå·ï¼Œé»˜è®¤ä¸º-1è¡¨ç¤ºæ–‡ä»¶æœ«å°¾
            agent: Agentå®ä¾‹ï¼Œç”¨äºè·å–tokené™åˆ¶

        Returns:
            Dict[str, Any]: åŒ…å«æˆåŠŸçŠ¶æ€ã€è¾“å‡ºå†…å®¹å’Œé”™è¯¯ä¿¡æ¯çš„å­—å…¸
        """
        try:
            abs_path = os.path.abspath(filepath)

            # æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
            if not os.path.exists(abs_path):
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": f"æ–‡ä»¶ä¸å­˜åœ¨: {abs_path}",
                }

            # æ–‡ä»¶å¤§å°é™åˆ¶æ£€æŸ¥ï¼ˆ10MBï¼‰
            if os.path.getsize(abs_path) > 10 * 1024 * 1024:
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": "æ–‡ä»¶è¿‡å¤§ (>10MB)",
                }

            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(abs_path, "r", encoding="utf-8", errors="ignore") as f:
                lines = f.readlines()

            total_lines = len(lines)

            # å¤„ç†ç©ºæ–‡ä»¶æƒ…å†µ
            if total_lines == 0:
                return {
                    "success": True,
                    "stdout": f"\nğŸ” æ–‡ä»¶: {abs_path}\nğŸ“„ æ–‡ä»¶ä¸ºç©º (0è¡Œ)\n",
                    "stderr": "",
                }

            # å¤„ç†ç‰¹æ®Šå€¼-1è¡¨ç¤ºæ–‡ä»¶æœ«å°¾
            if end_line == -1:
                end_line = total_lines
            else:
                end_line = (
                    max(1, min(end_line, total_lines))
                    if end_line >= 0
                    else total_lines + end_line + 1
                )

            start_line = (
                max(1, min(start_line, total_lines))
                if start_line >= 0
                else total_lines + start_line + 1
            )

            if start_line > end_line:
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": f"æ— æ•ˆçš„è¡ŒèŒƒå›´ [{start_line}-{end_line}] (æ€»è¡Œæ•°: {total_lines})",
                }

            # è¯»å–æŒ‡å®šè¡Œå·èŒƒå›´çš„å†…å®¹
            selected_lines = lines[start_line - 1 : end_line]

            # ä¸ºæ¯è¡Œæ·»åŠ è¡Œå·
            numbered_lines = []
            for i, line in enumerate(selected_lines, start=start_line):
                # è¡Œå·å³å¯¹é½ï¼Œå 4ä½
                line_number_str = f"{i:4d}"
                # ç§»é™¤è¡Œå°¾çš„æ¢è¡Œç¬¦ï¼Œå› ä¸ºæˆ‘ä»¬ä¼šåœ¨åé¢ç»Ÿä¸€æ·»åŠ 
                line_content = line.rstrip("\n\r")
                numbered_lines.append(f"{line_number_str}:{line_content}")

            # æ„é€ è¾“å‡ºå†…å®¹
            output_content = "\n".join(numbered_lines)

            # ä¼°ç®—tokenæ•°
            content_tokens = get_context_token_count(output_content)
            max_token_limit = self._get_max_token_limit(agent)

            # æ£€æŸ¥tokenæ•°æ˜¯å¦è¶…è¿‡é™åˆ¶
            if content_tokens > max_token_limit:
                read_lines = end_line - start_line + 1

                # è®¡ç®—å®‰å…¨è¯»å–çš„è¡Œæ•° (æŒ‰æ¯”ä¾‹ç¼©å‡)
                safe_lines = int((max_token_limit / content_tokens) * read_lines)
                safe_lines = max(1, min(safe_lines, read_lines))
                safe_end_line = start_line + safe_lines - 1

                # è¯»å–å®‰å…¨èŒƒå›´å†…çš„å†…å®¹
                safe_selected_lines = lines[start_line - 1 : safe_end_line]
                safe_numbered_lines = []
                for i, line in enumerate(safe_selected_lines, start=start_line):
                    line_number_str = f"{i:4d}"
                    line_content = line.rstrip("\n\r")
                    safe_numbered_lines.append(f"{line_number_str}:{line_content}")

                # æ„é€ éƒ¨åˆ†è¯»å–ç»“æœ
                partial_content = "\n".join(safe_numbered_lines)

                return {
                    "success": True,
                    "stdout": (
                        f"âš ï¸ è­¦å‘Š: ä»…è¯»å–å‰{safe_lines}è¡Œ (å…±{read_lines}è¡Œ)ï¼Œå› ä¸ºå†…å®¹è¶…å‡ºé™åˆ¶\n"
                        f"ğŸ“Š å®é™…è¯»å–èŒƒå›´: {start_line}-{safe_end_line} (åŸè¯·æ±‚èŒƒå›´: {start_line}-{end_line})\n\n"
                        f"{partial_content}\n\n"
                        f"ğŸ’¡ å»ºè®®:\n"
                        f"   1. å¦‚éœ€ç»§ç»­è¯»å–ï¼Œè¯·ä½¿ç”¨:\n"
                        f"      start_line={safe_end_line + 1}&end_line={end_line}\n"
                        f"   2. éœ€è¦è¯»å–å…¨éƒ¨å†…å®¹? è¯·ç¼©å°è¡ŒèŒƒå›´æˆ–åˆ†æ‰¹è¯»å–"
                    ),
                    "stderr": (
                        f"åŸå§‹è¯·æ±‚èŒƒå›´ {start_line}-{end_line} è¶…è¿‡tokené™åˆ¶ "
                        f"({content_tokens}/{max_token_limit} tokens)"
                    ),
                }

            # æ„é€ å®Œæ•´è¾“å‡º
            read_lines = end_line - start_line + 1
            output = f"\nğŸ” æ–‡ä»¶: {abs_path}\nğŸ“„ æ€»è¡Œæ•°: {total_lines}\nğŸ“Š è¯»å–èŒƒå›´: {start_line}-{end_line}\nğŸ“ˆ è¯»å–è¡Œæ•°: {read_lines}\n"
            output += "=" * 80 + "\n"
            output += output_content
            output += "\n" + "=" * 80 + "\n"

            # å°è¯•è·å–å¹¶é™„åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
            context_info = self._get_file_context(abs_path, start_line, end_line, agent)
            if context_info:
                output += context_info

            if agent:
                files = agent.get_user_data("files")
                if files:
                    files.append(abs_path)
                else:
                    files = [abs_path]
                agent.set_user_data("files", files)

            return {"success": True, "stdout": output, "stderr": ""}

        except Exception as e:
            PrettyOutput.auto_print(f"âŒ {str(e)}")
            return {"success": False, "stdout": "", "stderr": f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}"}

    def _get_file_context(
        self, filepath: str, start_line: int, end_line: int, agent: Optional[Any] = None
    ) -> str:
        """è·å–æ–‡ä»¶çš„ä¸Šä¸‹æ–‡ä¿¡æ¯

        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            start_line: èµ·å§‹è¡Œå·
            end_line: ç»“æŸè¡Œå·
            agent: Agentå®ä¾‹

        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å­—ç¬¦ä¸²ï¼Œå¦‚æœæ— æ³•è·å–åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            # å°è¯•ä»Agentè·å–CodeAgentå®ä¾‹
            if not agent:
                return ""

            # é€šè¿‡agentè·å–CodeAgentå®ä¾‹
            # CodeAgentåœ¨åˆå§‹åŒ–æ—¶ä¼šå°†è‡ªèº«å…³è”åˆ°agent
            code_agent = getattr(agent, "_code_agent", None)
            if not code_agent:
                return ""

            # è·å–ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            context_manager = getattr(code_agent, "context_manager", None)
            if not context_manager:
                return ""

            # ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ—¥å¿—å·²ç§»é™¤

            # ç¡®ä¿æ–‡ä»¶å·²æ›´æ–°åˆ°ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            # å¦‚æœæ–‡ä»¶å†…å®¹å·²ç¼“å­˜ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™è¯»å–å¹¶æ›´æ–°
            if (
                not hasattr(context_manager, "_file_cache")
                or filepath not in context_manager._file_cache
            ):
                try:
                    with open(filepath, "r", encoding="utf-8", errors="replace") as f:
                        content = f.read()
                    context_manager.update_context_for_file(filepath, content)
                except Exception:
                    # å¦‚æœè¯»å–å¤±è´¥ï¼Œå°è¯•è·å–å·²æœ‰ä¸Šä¸‹æ–‡
                    pass

            # è·å–ç¼–è¾‘ä¸Šä¸‹æ–‡
            edit_context = context_manager.get_edit_context(
                filepath, start_line, end_line
            )

            # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
            if (
                not edit_context.context_summary
                or edit_context.context_summary == "No context available"
            ):
                return ""

            # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ä¿¡æ¯
            context_lines = ["\nğŸ“‹ ä»£ç ä¸Šä¸‹æ–‡ä¿¡æ¯:"]
            context_lines.append("â”€" * 60)

            if edit_context.current_scope:
                scope_info = f"ğŸ“ å½“å‰ä½œç”¨åŸŸ: {edit_context.current_scope.kind} `{edit_context.current_scope.name}`"
                if edit_context.current_scope.signature:
                    scope_info += (
                        f"\n   â””â”€ ç­¾å: {edit_context.current_scope.signature}"
                    )
                context_lines.append(scope_info)

            if edit_context.used_symbols:
                # å¯¹ç¬¦å·å»é‡ï¼ˆåŸºäº name + file_path + line_startï¼‰
                seen_symbols = set()
                unique_symbols = []
                for s in edit_context.used_symbols:
                    key = (
                        s.name,
                        getattr(s, "file_path", ""),
                        getattr(s, "line_start", 0),
                    )
                    if key not in seen_symbols:
                        seen_symbols.add(key)
                        unique_symbols.append(s)

                # åŒºåˆ†å®šä¹‰å’Œè°ƒç”¨ï¼Œæ˜¾ç¤ºå®šä¹‰ä½ç½®ä¿¡æ¯
                definitions = []
                calls = []
                for symbol in unique_symbols[:10]:
                    is_def = getattr(symbol, "is_definition", False)
                    if is_def:
                        definitions.append(symbol)
                    else:
                        calls.append(symbol)

                # æ˜¾ç¤ºå®šä¹‰
                if definitions:
                    def_names = [f"`{s.name}`" for s in definitions]
                    context_lines.append(f"ğŸ“ å®šä¹‰çš„ç¬¦å·: {', '.join(def_names)}")

                # æ˜¾ç¤ºè°ƒç”¨ï¼ˆå¸¦å®šä¹‰ä½ç½®ä¿¡æ¯ï¼‰
                if calls:
                    call_info = []
                    for symbol in calls:
                        def_loc = getattr(symbol, "definition_location", None)
                        if def_loc:
                            def_file = os.path.basename(def_loc.file_path)
                            def_line = def_loc.line_start
                            call_info.append(f"`{symbol.name}` â†’ {def_file}:{def_line}")
                        else:
                            call_info.append(f"`{symbol.name}`")
                    context_lines.append(f"ğŸ”— è°ƒç”¨çš„ç¬¦å·: {', '.join(call_info)}")

                # å¦‚æœè¿˜æœ‰æ›´å¤šç¬¦å·
                more = len(edit_context.used_symbols) - 10
                if more > 0:
                    context_lines.append(f"   ... è¿˜æœ‰{more}ä¸ªç¬¦å·")

            if edit_context.relevant_files:
                # å¯¹ç›¸å…³æ–‡ä»¶å»é‡
                unique_files = list(dict.fromkeys(edit_context.relevant_files))
                rel_files = unique_files[:10]
                files_str = "\n   ".join(
                    f"â€¢ {os.path.relpath(f, context_manager.project_root)}"
                    for f in rel_files
                )
                more = len(unique_files) - 10
                if more > 0:
                    files_str += f"\n   ... è¿˜æœ‰{more}ä¸ªç›¸å…³æ–‡ä»¶"
                context_lines.append(
                    f"ğŸ“ ç›¸å…³æ–‡ä»¶ ({len(unique_files)}ä¸ª):\n   {files_str}"
                )

            context_lines.append("â”€" * 60)
            context_lines.append("")  # ç©ºè¡Œ

            # ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç»“æœå·²ç§»é™¤ï¼Œä¸å†æ‰“å°åˆ°æ§åˆ¶å°
            context_output = "\n".join(context_lines)
            return context_output

        except Exception:
            # é™é»˜å¤±è´¥ï¼Œä¸å½±å“æ–‡ä»¶è¯»å–
            return ""

    def _handle_merged_ranges(
        self, filepath: str, requests: List[Dict[str, Any]], agent: Optional[Any] = None
    ) -> Dict[str, Any]:
        """å¤„ç†åŒä¸€æ–‡ä»¶çš„å¤šä¸ªèŒƒå›´è¯·æ±‚ï¼Œåˆå¹¶åå»é‡

        Args:
            filepath: æ–‡ä»¶ç»å¯¹è·¯å¾„
            requests: èŒƒå›´è¯·æ±‚åˆ—è¡¨ï¼Œæ¯ä¸ªè¯·æ±‚åŒ…å« start_line, end_line
            agent: Agentå®ä¾‹

        Returns:
            Dict[str, Any]: åŒ…å«æˆåŠŸçŠ¶æ€ã€è¾“å‡ºå†…å®¹å’Œé”™è¯¯ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
            if not os.path.exists(filepath):
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}",
                }

            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(filepath, "r", encoding="utf-8", errors="ignore") as f:
                lines = f.readlines()

            total_lines = len(lines)
            if total_lines == 0:
                return {
                    "success": True,
                    "stdout": f"\nğŸ” æ–‡ä»¶: {filepath}\nğŸ“„ æ–‡ä»¶ä¸ºç©º (0è¡Œ)\n",
                    "stderr": "",
                }

            # åˆå¹¶æ‰€æœ‰èŒƒå›´ï¼Œè®¡ç®—æœ€å°èµ·å§‹è¡Œå’Œæœ€å¤§ç»“æŸè¡Œ
            min_start = float("inf")
            max_end = 0
            for req in requests:
                start_line = req.get("start_line", 1)
                end_line = req.get("end_line", -1)

                # å¤„ç†ç‰¹æ®Šå€¼
                if end_line == -1:
                    end_line = total_lines
                else:
                    end_line = (
                        max(1, min(end_line, total_lines))
                        if end_line >= 0
                        else total_lines + end_line + 1
                    )
                start_line = (
                    max(1, min(start_line, total_lines))
                    if start_line >= 0
                    else total_lines + start_line + 1
                )

                min_start = min(min_start, start_line)
                max_end = max(max_end, end_line)

            # ç”¨åˆå¹¶åçš„èŒƒå›´è¯»å–ä¸€æ¬¡ï¼Œè‡ªç„¶å°±å»é‡äº†
            result = self._handle_single_file(
                filepath, int(min_start), int(max_end), agent
            )
            return result

        except Exception as e:
            return {
                "success": False,
                "stdout": "",
                "stderr": f"åˆå¹¶èŒƒå›´è¯»å–å¤±è´¥: {str(e)}",
            }

    def execute(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œä»£ç è¯»å–æ“ä½œ

        Args:
            args (Dict): åŒ…å«æ–‡ä»¶åˆ—è¡¨çš„å‚æ•°å­—å…¸

        Returns:
            Dict[str, Any]: åŒ…å«æˆåŠŸçŠ¶æ€ã€è¾“å‡ºå†…å®¹å’Œé”™è¯¯ä¿¡æ¯çš„å­—å…¸
        """
        try:
            agent = args.get("agent", None)
            if "files" not in args or not isinstance(args["files"], list):
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": "å‚æ•°ä¸­å¿…é¡»åŒ…å«æ–‡ä»¶åˆ—è¡¨",
                }

            if len(args["files"]) == 0:
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": "æ–‡ä»¶åˆ—è¡¨ä¸èƒ½ä¸ºç©º",
                }

            all_outputs = []
            overall_success = True
            status_lines = []
            total_tokens = 0  # ç´¯è®¡è¯»å–çš„tokenæ•°
            max_token_limit = self._get_max_token_limit(agent)

            # ç¬¬ä¸€éï¼šæ£€æŸ¥æ‰€æœ‰æ–‡ä»¶çš„ç´¯è®¡tokenæ•°æ˜¯å¦è¶…è¿‡é™åˆ¶
            file_read_info = []  # å­˜å‚¨æ¯ä¸ªæ–‡ä»¶è¦è¯»å–çš„ä¿¡æ¯
            for file_info in args["files"]:
                if not isinstance(file_info, dict) or "path" not in file_info:
                    continue

                filepath = file_info["path"].strip()
                start_line = file_info.get("start_line", 1)
                end_line = file_info.get("end_line", -1)

                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶è®¡ç®—è¦è¯»å–çš„tokenæ•°
                abs_path = os.path.abspath(filepath)
                if not os.path.exists(abs_path):
                    continue

                try:
                    # è¯»å–æ–‡ä»¶å†…å®¹
                    with open(abs_path, "r", encoding="utf-8", errors="ignore") as f:
                        lines = f.readlines()

                    total_lines = len(lines)

                    if total_lines == 0:
                        continue

                    # è®¡ç®—å®é™…è¦è¯»å–çš„è¡ŒèŒƒå›´
                    if end_line == -1:
                        actual_end_line = total_lines
                    else:
                        actual_end_line = (
                            max(1, min(end_line, total_lines))
                            if end_line >= 0
                            else total_lines + end_line + 1
                        )

                    actual_start_line = (
                        max(1, min(start_line, total_lines))
                        if start_line >= 0
                        else total_lines + start_line + 1
                    )

                    if actual_start_line <= actual_end_line:
                        # è¯»å–æŒ‡å®šè¡Œå·èŒƒå›´çš„å†…å®¹
                        selected_lines = lines[actual_start_line - 1 : actual_end_line]

                        # ä¸ºæ¯è¡Œæ·»åŠ è¡Œå·
                        numbered_lines = []
                        for i, line in enumerate(
                            selected_lines, start=actual_start_line
                        ):
                            line_number_str = f"{i:4d}"
                            line_content = line.rstrip("\n\r")
                            numbered_lines.append(f"{line_number_str}:{line_content}")

                        # æ„é€ è¾“å‡ºå†…å®¹ç”¨äºtokenä¼°ç®—
                        output_content = "\n".join(numbered_lines)
                        content_tokens = get_context_token_count(output_content)

                        file_read_info.append(
                            {
                                "filepath": filepath,
                                "start_line": actual_start_line,
                                "end_line": actual_end_line,
                                "read_lines": actual_end_line - actual_start_line + 1,
                                "tokens": content_tokens,
                                "file_info": file_info,
                            }
                        )
                        total_tokens += content_tokens
                except Exception:
                    continue

            # æ£€æŸ¥ç´¯è®¡tokenæ•°æ˜¯å¦è¶…è¿‡é™åˆ¶
            if total_tokens > max_token_limit:
                file_list = "\n   ".join(
                    f"â€¢ {info['filepath']}: {info['tokens']} tokens ({info['read_lines']} è¡Œ, èŒƒå›´: {info['start_line']}-{info['end_line']})"
                    for info in file_read_info[:10]
                )
                more_files = len(file_read_info) - 10
                if more_files > 0:
                    file_list += f"\n   ... è¿˜æœ‰ {more_files} ä¸ªæ–‡ä»¶"

                return {
                    "success": False,
                    "stdout": "",
                    "stderr": (
                        f"âš ï¸ ç´¯è®¡è¯»å–èŒƒå›´è¿‡å¤§: è¯·æ±‚ç´¯è®¡è¯»å–å†…å®¹çº¦ {total_tokens} tokensï¼Œè¶…è¿‡é™åˆ¶ ({max_token_limit} tokensï¼Œçº¦2/3æœ€å¤§çª—å£)\n"
                        f"ğŸ“‹ æ–‡ä»¶åˆ—è¡¨ ({len(file_read_info)} ä¸ªæ–‡ä»¶):\n   {file_list}\n"
                        f"ğŸ’¡ å»ºè®®ï¼š\n"
                        f"   1. åˆ†æ‰¹è¯»å–ï¼šå°†æ–‡ä»¶åˆ†æˆå¤šä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹ç´¯è®¡å†…å®¹ä¸è¶…è¿‡ {max_token_limit} tokens\n"
                        f"   2. å…ˆå®šä½ï¼šä½¿ç”¨æœç´¢æˆ–åˆ†æå·¥å…·å®šä½å…³é”®ä»£ç ä½ç½®ï¼Œå†è¯»å–å…·ä½“èŒƒå›´\n"
                        f"   3. ç¼©å°èŒƒå›´ï¼šä¸ºæ¯ä¸ªæ–‡ä»¶æŒ‡å®šæ›´ç²¾ç¡®çš„è¡Œå·èŒƒå›´"
                    ),
                }

            # ç¬¬äºŒéï¼šå®é™…è¯»å–æ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åˆ†ç»„ï¼Œåˆå¹¶åŒä¸€æ–‡ä»¶çš„å¤šä¸ªèŒƒå›´è¯·æ±‚ï¼Œé¿å…å—é‡å¤ï¼‰
            # æŒ‰æ–‡ä»¶è·¯å¾„åˆ†ç»„
            from collections import defaultdict

            file_requests = defaultdict(list)
            for file_info in args["files"]:
                if not isinstance(file_info, dict) or "path" not in file_info:
                    continue
                abs_path = os.path.abspath(file_info["path"].strip())
                file_requests[abs_path].append(file_info)

            # æŒ‰æ–‡ä»¶å¤„ç†ï¼Œåˆå¹¶åŒä¸€æ–‡ä»¶çš„å¤šä¸ªèŒƒå›´è¯·æ±‚
            for abs_path, requests in file_requests.items():
                if len(requests) == 1:
                    # å•ä¸ªèŒƒå›´è¯·æ±‚ï¼Œç›´æ¥å¤„ç†
                    file_info = requests[0]
                    result = self._handle_single_file(
                        file_info["path"].strip(),
                        file_info.get("start_line", 1),
                        file_info.get("end_line", -1),
                        agent,
                    )
                    if result["success"]:
                        all_outputs.append(result["stdout"])
                        status_lines.append(
                            f"âœ… {file_info['path']} æ–‡ä»¶è¯»å–æˆåŠŸ (èŒƒå›´: {file_info.get('start_line', 1)}-{file_info.get('end_line', -1)})"
                        )
                    else:
                        all_outputs.append(
                            f"âŒ {file_info['path']}: {result['stderr']}"
                        )
                        status_lines.append(f"âŒ {file_info['path']} æ–‡ä»¶è¯»å–å¤±è´¥")
                        overall_success = False
                else:
                    # å¤šä¸ªèŒƒå›´è¯·æ±‚ï¼Œåˆå¹¶å¤„ç†å¹¶å»é‡
                    merged_result = self._handle_merged_ranges(
                        abs_path, requests, agent
                    )
                    display_path = requests[0]["path"]
                    if merged_result["success"]:
                        all_outputs.append(merged_result["stdout"])
                        # è·å–åˆå¹¶åçš„èŒƒå›´ä¿¡æ¯
                        min_start = min(req.get("start_line", 1) for req in requests)
                        max_end = max(req.get("end_line", -1) for req in requests)
                        status_lines.append(
                            f"âœ… {display_path} æ–‡ä»¶è¯»å–æˆåŠŸ (åˆå¹¶{len(requests)}ä¸ªèŒƒå›´è¯·æ±‚ï¼Œå·²å»é‡ï¼ŒèŒƒå›´: {min_start}-{max_end})"
                        )
                    else:
                        all_outputs.append(
                            f"âŒ {display_path}: {merged_result['stderr']}"
                        )
                        status_lines.append(f"âŒ {display_path} æ–‡ä»¶è¯»å–å¤±è´¥")
                        overall_success = False

            stdout_text = "\n".join(all_outputs)
            # ä»…æ‰“å°æ¯ä¸ªæ–‡ä»¶çš„è¯»å–çŠ¶æ€ï¼Œä¸æ‰“å°å…·ä½“å†…å®¹
            try:
                if status_lines:
                    PrettyOutput.auto_print("\n".join(status_lines))
            except Exception:
                pass
            return {
                "success": overall_success,
                "stdout": stdout_text,
                "stderr": "",
            }

        except Exception as e:
            PrettyOutput.auto_print(f"âŒ {str(e)}")
            return {"success": False, "stdout": "", "stderr": f"ä»£ç è¯»å–å¤±è´¥: {str(e)}"}


def main() -> None:
    """æµ‹è¯•è¯»å–åŠŸèƒ½"""
    import os
    import tempfile

    tool = ReadCodeTool()

    PrettyOutput.auto_print("=" * 80)
    PrettyOutput.auto_print("æµ‹è¯•è¯»å–åŠŸèƒ½")
    PrettyOutput.auto_print("=" * 80)

    # æµ‹è¯•1: åŸºæœ¬è¯»å–
    PrettyOutput.auto_print("\nã€æµ‹è¯•1ã€‘åŸºæœ¬è¯»å–")
    PrettyOutput.auto_print("-" * 80)

    test_code = """def hello():
    PrettyOutput.auto_print("Hello, World!")

def add(a, b):
    return a + b

def sub(a, b):
    return a - b
"""

    with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
        test_file = f.name
        f.write(test_code)

    try:
        result = tool.execute(
            {
                "files": [{"path": test_file, "start_line": 1, "end_line": -1}],
                "agent": None,
            }
        )

        if result["success"]:
            PrettyOutput.auto_print("âœ… æ–‡ä»¶è¯»å–æˆåŠŸ")
            PrettyOutput.auto_print("\nè¾“å‡ºå†…å®¹:")
            PrettyOutput.auto_print(result["stdout"])
        else:
            PrettyOutput.auto_print(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(test_file)

    # æµ‹è¯•2: æŒ‡å®šè¡Œå·èŒƒå›´
    PrettyOutput.auto_print("\nã€æµ‹è¯•2ã€‘æŒ‡å®šè¡Œå·èŒƒå›´è¯»å–")
    PrettyOutput.auto_print("-" * 80)

    with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
        test_file2 = f.name
        f.write(test_code)

    try:
        result = tool.execute(
            {
                "files": [{"path": test_file2, "start_line": 1, "end_line": 3}],
                "agent": None,
            }
        )

        if result["success"]:
            PrettyOutput.auto_print("âœ… æŒ‡å®šèŒƒå›´è¯»å–æˆåŠŸ")
            PrettyOutput.auto_print("\nè¾“å‡ºå†…å®¹:")
            PrettyOutput.auto_print(result["stdout"])
        else:
            PrettyOutput.auto_print(f"âŒ æŒ‡å®šèŒƒå›´è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(test_file2)

    # æµ‹è¯•3: å¤šä¸ªæ–‡ä»¶
    PrettyOutput.auto_print("\nã€æµ‹è¯•3ã€‘å¤šä¸ªæ–‡ä»¶è¯»å–")
    PrettyOutput.auto_print("-" * 80)

    with (
        tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f1,
        tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f2,
    ):
        test_file3 = f1.name
        test_file4 = f2.name
        f1.write(test_code)
        f2.write(test_code)

    try:
        result = tool.execute(
            {
                "files": [
                    {"path": test_file3, "start_line": 1, "end_line": -1},
                    {"path": test_file4, "start_line": 1, "end_line": -1},
                ],
                "agent": None,
            }
        )

        if result["success"]:
            PrettyOutput.auto_print("âœ… å¤šæ–‡ä»¶è¯»å–æˆåŠŸ")
            PrettyOutput.auto_print("\nè¾“å‡ºå†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰:")
            PrettyOutput.auto_print(
                result["stdout"][:500] + "..."
                if len(result["stdout"]) > 500
                else result["stdout"]
            )
        else:
            PrettyOutput.auto_print(f"âŒ å¤šæ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(test_file3)
        os.unlink(test_file4)

    PrettyOutput.auto_print("\n" + "=" * 80)
    PrettyOutput.auto_print("æµ‹è¯•å®Œæˆ")
    PrettyOutput.auto_print("=" * 80)


if __name__ == "__main__":
    main()
