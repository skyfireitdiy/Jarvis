# -*- coding: utf-8 -*-
import os
import time
from typing import Any, Dict, List

from jarvis.jarvis_utils.config import get_max_input_token_count
from jarvis.jarvis_utils.embedding import get_context_token_count

# å°è¯•å¯¼å…¥è¯­è¨€æ”¯æŒæ¨¡å—
try:
    from jarvis.jarvis_code_agent.code_analyzer.language_support import (
        detect_language,
        get_dependency_analyzer,
    )
    from jarvis.jarvis_code_agent.code_analyzer.structured_code import StructuredCodeExtractor
    LANGUAGE_SUPPORT_AVAILABLE = True
except ImportError:
    LANGUAGE_SUPPORT_AVAILABLE = False
    def get_dependency_analyzer(language: str):
        return None
    StructuredCodeExtractor = None


class ReadCodeTool:
    name = "read_code"
    description = (
        "ç»“æ„åŒ–è¯»å–æºä»£ç æ–‡ä»¶ã€‚"
        "æ”¯æŒçš„è¯­è¨€æŒ‰è¯­æ³•å•å…ƒï¼ˆå‡½æ•°ã€ç±»ç­‰ï¼‰è¯»å–ï¼›ä¸æ”¯æŒçš„è¯­è¨€æŒ‰ç©ºç™½è¡Œåˆ†ç»„ï¼›"
        "raw_mode=true æ—¶æŒ‰æ¯20è¡Œåˆ†ç»„è¯»å–ã€‚"
    )
    # å·¥å…·æ ‡ç­¾
    parameters = {
        "type": "object",
        "properties": {
            "files": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "path": {"type": "string"},
                        "start_line": {"type": "number", "default": 1},
                        "end_line": {"type": "number", "default": -1},
                        "raw_mode": {"type": "boolean", "default": False},
                    },
                    "required": ["path"],
                },
                "description": "è¦è¯»å–çš„æ–‡ä»¶åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡ä»¶å¯æŒ‡å®šè¡Œå·èŒƒå›´ï¼ˆstart_line åˆ° end_lineï¼Œ-1 è¡¨ç¤ºæ–‡ä»¶æœ«å°¾ï¼‰ã€‚raw_modeä¸ºtrueæ—¶æŒ‰æ¯20è¡Œåˆ†ç»„è¯»å–ï¼ˆåŸå§‹æ¨¡å¼ï¼‰ã€‚",
            }
        },
        "required": ["files"],
    }
    
    def _extract_syntax_units(
        self, filepath: str, content: str, start_line: int, end_line: int
    ) -> List[Dict[str, Any]]:
        """æå–è¯­æ³•å•å…ƒï¼ˆå‡½æ•°ã€ç±»ç­‰ï¼‰
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            content: æ–‡ä»¶å†…å®¹
            start_line: èµ·å§‹è¡Œå·
            end_line: ç»“æŸè¡Œå·
            
        Returns:
            è¯­æ³•å•å…ƒåˆ—è¡¨ï¼Œæ¯ä¸ªå•å…ƒåŒ…å« id, start_line, end_line, content
        """
        if StructuredCodeExtractor:
            return StructuredCodeExtractor.extract_syntax_units(filepath, content, start_line, end_line)
        return []
    
    def _extract_syntax_units_with_split(
        self, filepath: str, content: str, start_line: int, end_line: int
    ) -> List[Dict[str, Any]]:
        """æå–è¯­æ³•å•å…ƒï¼Œç„¶åå¯¹è¶…è¿‡50è¡Œçš„å•å…ƒå†æŒ‰æ¯50è¡Œåˆ†å‰²
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            content: æ–‡ä»¶å†…å®¹
            start_line: èµ·å§‹è¡Œå·
            end_line: ç»“æŸè¡Œå·
            
        Returns:
            è¯­æ³•å•å…ƒåˆ—è¡¨ï¼Œæ¯ä¸ªå•å…ƒä¸è¶…è¿‡50è¡Œ
        """
        # å…ˆè·å–è¯­æ³•å•å…ƒ
        syntax_units = self._extract_syntax_units(filepath, content, start_line, end_line)
        
        if not syntax_units:
            return []
        
        result = []
        for unit in syntax_units:
            unit_line_count = unit['end_line'] - unit['start_line'] + 1
            if unit_line_count > 50:
                # å¦‚æœå•å…ƒè¶…è¿‡50è¡Œï¼ŒæŒ‰æ¯50è¡Œåˆ†å‰²
                sub_groups = self._extract_line_groups(
                    content, unit['start_line'], unit['end_line'], group_size=50
                )
                result.extend(sub_groups)
            else:
                # å¦‚æœå•å…ƒä¸è¶…è¿‡50è¡Œï¼Œç›´æ¥æ·»åŠ 
                result.append(unit)
        
        return result
    
    def _extract_blank_line_groups(
        self, content: str, start_line: int, end_line: int
    ) -> List[Dict[str, Any]]:
        """æŒ‰ç©ºç™½è¡Œåˆ†ç»„æå–å†…å®¹ï¼ˆå§”æ‰˜ç»™StructuredCodeExtractorï¼‰"""
        if StructuredCodeExtractor:
            return StructuredCodeExtractor.extract_blank_line_groups(content, start_line, end_line)
        return []
    
    def _extract_blank_line_groups_with_split(
        self, content: str, start_line: int, end_line: int
    ) -> List[Dict[str, Any]]:
        """å…ˆæŒ‰ç©ºç™½è¡Œåˆ†ç»„ï¼Œç„¶åå¯¹è¶…è¿‡20è¡Œçš„å—å†æŒ‰æ¯20è¡Œåˆ†å‰²
        
        Args:
            content: æ–‡ä»¶å†…å®¹
            start_line: èµ·å§‹è¡Œå·
            end_line: ç»“æŸè¡Œå·
            
        Returns:
            åˆ†ç»„åˆ—è¡¨ï¼Œæ¯ä¸ªåˆ†ç»„åŒ…å« id, start_line, end_line, content
        """
        # å…ˆè·å–ç©ºç™½è¡Œåˆ†ç»„
        blank_line_groups = self._extract_blank_line_groups(content, start_line, end_line)
        
        if not blank_line_groups:
            return []
        
        result = []
        for group in blank_line_groups:
            group_line_count = group['end_line'] - group['start_line'] + 1
            if group_line_count > 20:
                # å¦‚æœå—è¶…è¿‡20è¡Œï¼ŒæŒ‰æ¯20è¡Œåˆ†å‰²
                sub_groups = self._extract_line_groups(
                    content, group['start_line'], group['end_line'], group_size=20
                )
                result.extend(sub_groups)
            else:
                # å¦‚æœå—ä¸è¶…è¿‡20è¡Œï¼Œç›´æ¥æ·»åŠ 
                result.append(group)
        
        return result
    
    def _extract_line_groups(
        self, content: str, start_line: int, end_line: int, group_size: int = 20
    ) -> List[Dict[str, Any]]:
        """æŒ‰è¡Œå·åˆ†ç»„æå–å†…å®¹ï¼ˆå§”æ‰˜ç»™StructuredCodeExtractorï¼‰"""
        if StructuredCodeExtractor:
            return StructuredCodeExtractor.extract_line_groups(content, start_line, end_line, group_size)
        return []
    
    def _ensure_unique_ids(self, units: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç¡®ä¿å•å…ƒåˆ—è¡¨ä¸­æ‰€æœ‰idå”¯ä¸€ï¼ˆå§”æ‰˜ç»™StructuredCodeExtractorï¼‰"""
        if StructuredCodeExtractor:
            return StructuredCodeExtractor.ensure_unique_ids(units)
        return units
    
    def _extract_imports(self, filepath: str, content: str, start_line: int, end_line: int) -> List[Dict[str, Any]]:
        """æå–æ–‡ä»¶çš„å¯¼å…¥/åŒ…å«è¯­å¥ä½œä¸ºç»“æ„åŒ–å•å…ƒï¼ˆå§”æ‰˜ç»™StructuredCodeExtractorï¼‰"""
        if StructuredCodeExtractor:
            return StructuredCodeExtractor.extract_imports(filepath, content, start_line, end_line)
        return []
    
    def _create_import_unit(self, import_group: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ›å»ºå¯¼å…¥è¯­å¥å•å…ƒï¼ˆå§”æ‰˜ç»™StructuredCodeExtractorï¼‰"""
        if StructuredCodeExtractor:
            return StructuredCodeExtractor.create_import_unit(import_group)
        return {}
    
    def _format_structured_output(
        self, filepath: str, units: List[Dict[str, Any]], total_lines: int, agent: Any = None
    ) -> str:
        """æ ¼å¼åŒ–ç»“æ„åŒ–è¾“å‡º
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            units: è¯­æ³•å•å…ƒæˆ–è¡Œå·åˆ†ç»„åˆ—è¡¨ï¼ˆå·²åŒ…å«å¯¼å…¥è¯­å¥å•å…ƒï¼‰
            total_lines: æ–‡ä»¶æ€»è¡Œæ•°
            agent: Agentå®ä¾‹ï¼Œç”¨äºä»ç¼“å­˜ä¸­è·å–block_id
            
        Returns:
            æ ¼å¼åŒ–åçš„è¾“å‡ºå­—ç¬¦ä¸²
        """
        # æ–‡ä»¶å¼€å§‹åˆ†ç•Œç¬¦
        output_lines = [
            "=" * 80,
            f"ğŸ” æ–‡ä»¶: {filepath}",
            f"ğŸ“„ æ€»è¡Œæ•°: {total_lines}",
            f"ğŸ“¦ ç»“æ„åŒ–å•å…ƒæ•°: {len(units)}",
            "=" * 80,
            "",
        ]
        
        # ä¸ºæ¯ä¸ªå•å…ƒåˆ†é…block-id
        # å¦‚æœunitå·²ç»æœ‰block_idï¼ˆä»ç¼“å­˜ä¸­è·å–ï¼‰ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™æŒ‰é¡ºåºç”Ÿæˆ
        for idx, unit in enumerate(units, start=1):
            # å¦‚æœunitå·²ç»æœ‰block_idï¼Œç›´æ¥ä½¿ç”¨ï¼ˆåœ¨ç”Ÿæˆstructured_unitsæ—¶å·²åˆ†é…ï¼‰
            block_id = unit.get('block_id')
            if not block_id:
                # å¦åˆ™æŒ‰é¡ºåºç”Ÿæˆä¸´æ—¶id
                block_id = f"block-{idx}"
            # æ˜¾ç¤ºid
            output_lines.append(f"[id:{block_id}]")
            # æ·»åŠ å†…å®¹ï¼Œä¿æŒåŸæœ‰ç¼©è¿›ï¼Œå¹¶ä¸ºæ¯è¡Œæ·»åŠ è¡Œå·
            content = unit.get('content', '')
            if content:
                # è·å–å•å…ƒçš„èµ·å§‹è¡Œå·
                start_line = unit.get('start_line', 1)
                # å°†å†…å®¹æŒ‰è¡Œåˆ†å‰²
                content_lines = content.split('\n')
                # ä¸ºæ¯ä¸€è¡Œæ·»åŠ è¡Œå·ï¼ˆå³å¯¹é½ï¼Œ4ä½ï¼Œä¸è¶³è¡¥ç©ºæ ¼ï¼‰
                numbered_lines = []
                current_line = start_line
                for line in content_lines:
                    # è¡Œå·å³å¯¹é½ï¼Œå 4ä½
                    line_number_str = f"{current_line:4d}"
                    numbered_lines.append(f"{line_number_str}:{line}")
                    current_line += 1
                # å°†å¸¦è¡Œå·çš„å†…å®¹æ·»åŠ åˆ°è¾“å‡º
                output_lines.append('\n'.join(numbered_lines))
            # å—ç»“æŸåˆ†ç•Œç¬¦
            output_lines.append("-" * 80)
            output_lines.append("")  # å•å…ƒä¹‹é—´ç©ºè¡Œåˆ†éš”
        
        # æ–‡ä»¶ç»“æŸåˆ†ç•Œç¬¦
        output_lines.append("=" * 80)
        output_lines.append("")
        
        return '\n'.join(output_lines)
    
    def _get_file_cache(self, agent: Any, filepath: str) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶çš„ç¼“å­˜ä¿¡æ¯
        
        Args:
            agent: Agentå®ä¾‹
            filepath: æ–‡ä»¶è·¯å¾„
            
        Returns:
            ç¼“å­˜ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        if not agent:
            return None
        
        cache = agent.get_user_data("read_code_cache")
        if not cache:
            return None
        
        abs_path = os.path.abspath(filepath)
        return cache.get(abs_path)
    
    def _get_blocks_from_cache(self, cache_info: Dict[str, Any], start_line: int, end_line: int) -> List[Dict[str, Any]]:
        """ä»ç¼“å­˜ä¸­è·å–å¯¹åº”èŒƒå›´çš„blocks
        
        Args:
            cache_info: ç¼“å­˜ä¿¡æ¯
            start_line: èµ·å§‹è¡Œå·ï¼ˆ1-basedï¼‰
            end_line: ç»“æŸè¡Œå·ï¼ˆ1-basedï¼Œ-1è¡¨ç¤ºæ–‡ä»¶æœ«å°¾ï¼‰
            
        Returns:
            blocksåˆ—è¡¨ï¼Œæ¯ä¸ªblockåŒ…å«block_idå’Œcontent
        """
        if not cache_info or "id_list" not in cache_info or "blocks" not in cache_info:
            return []
        
        id_list = cache_info.get("id_list", [])
        blocks = cache_info.get("blocks", {})
        result = []
        
        # å¦‚æœend_lineæ˜¯-1ï¼Œè¡¨ç¤ºæ–‡ä»¶æœ«å°¾ï¼Œéœ€è¦å…ˆè®¡ç®—æ–‡ä»¶æ€»è¡Œæ•°
        if end_line == -1:
            # å…ˆéå†æ‰€æœ‰blocksè®¡ç®—æ€»è¡Œæ•°
            # æ³¨æ„ï¼šå—å†…å®¹ä¸åŒ…å«æœ«å°¾æ¢è¡Œç¬¦ï¼Œå—ä¹‹é—´éœ€è¦æ·»åŠ æ¢è¡Œç¬¦
            total_lines = 0
            for idx, block_id in enumerate(id_list):
                block_data = blocks.get(block_id)
                if block_data:
                    block_content = block_data.get("content", "")
                    if block_content:
                        # å—å†…å®¹ä¸­çš„æ¢è¡Œç¬¦æ•°é‡ + 1 = è¡Œæ•°
                        block_line_count = block_content.count('\n') + 1
                        total_lines += block_line_count
                        # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªå—ï¼Œå—ä¹‹é—´æœ‰ä¸€ä¸ªæ¢è¡Œç¬¦åˆ†éš”ï¼ˆå·²è®¡å…¥ä¸‹ä¸€ä¸ªå—çš„ç¬¬ä¸€è¡Œï¼‰
                        # æ‰€ä»¥ä¸éœ€è¦é¢å¤–æ·»åŠ 
            end_line = total_lines
        
        # é€šè¿‡å‰é¢blocksçš„å†…å®¹æ¨ç®—æ¯ä¸ªblockçš„è¡Œå·èŒƒå›´
        # æ³¨æ„ï¼šå—å†…å®¹ä¸åŒ…å«æœ«å°¾æ¢è¡Œç¬¦ï¼Œå—ä¹‹é—´éœ€è¦æ·»åŠ æ¢è¡Œç¬¦
        current_line = 1  # ä»ç¬¬1è¡Œå¼€å§‹
        
        for idx, block_id in enumerate(id_list):
            block_data = blocks.get(block_id)
            if not block_data:
                continue
            block_content = block_data.get("content", "")
            if not block_content:
                continue
            
            # è®¡ç®—è¿™ä¸ªblockçš„è¡Œæ•°
            # å—å†…å®¹ä¸­çš„æ¢è¡Œç¬¦æ•°é‡ + 1 = è¡Œæ•°ï¼ˆå› ä¸ºå—å†…å®¹ä¸åŒ…å«æœ«å°¾æ¢è¡Œç¬¦ï¼‰
            block_line_count = block_content.count('\n') + 1
            
            block_start_line = current_line
            block_end_line = current_line + block_line_count - 1
            
            # blockä¸è¯·æ±‚èŒƒå›´æœ‰é‡å å°±åŒ…å«
            if block_end_line >= start_line and block_start_line <= end_line:
                result.append({
                    "block_id": block_id,
                    "content": block_content,
                    "start_line": block_start_line,
                })
            
            # æ›´æ–°å½“å‰è¡Œå·
            # å—ä¹‹é—´æœ‰ä¸€ä¸ªæ¢è¡Œç¬¦åˆ†éš”ï¼Œæ‰€ä»¥ä¸‹ä¸€ä¸ªå—ä» block_end_line + 1 å¼€å§‹
            current_line = block_end_line + 1
            
            # å¦‚æœå·²ç»è¶…è¿‡è¯·æ±‚çš„ç»“æŸè¡Œï¼Œå¯ä»¥æå‰é€€å‡º
            if block_start_line > end_line:
                break
        
        return result
    
    def _convert_units_to_sequential_ids(self, units: List[Dict[str, Any]], full_content: str = None) -> Dict[str, Any]:
        """å°†å•å…ƒåˆ—è¡¨è½¬æ¢ä¸ºç¼“å­˜æ ¼å¼ï¼ˆid_listå’Œblockså­—å…¸ï¼‰
        
        æŒ‰ç…§è¡Œå·èŒƒå›´åˆ†å‰²æ–‡ä»¶ï¼Œä¸åŒºåˆ†è¯­æ³•å•å…ƒï¼Œç¡®ä¿å®Œç¾æ¢å¤ã€‚
        
        Args:
            units: ç»“æ„åŒ–å•å…ƒåˆ—è¡¨ï¼Œæ¯ä¸ªå•å…ƒåŒ…å« id, start_line, end_line, content
            full_content: å®Œæ•´çš„æ–‡ä»¶å†…å®¹ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºç¡®ä¿å—ä¹‹é—´çš„ç©ºç™½è¡Œä¹Ÿè¢«åŒ…å«
            
        Returns:
            åŒ…å« id_list å’Œ blocks çš„å­—å…¸ï¼š
            - id_list: æœ‰åºçš„idåˆ—è¡¨ï¼Œå¦‚ ["block-1", "block-2", "block-3"]
            - blocks: idåˆ°å—ä¿¡æ¯çš„å­—å…¸ï¼Œå¦‚ {"block-1": {"content": "..."}, ...}
        """
        if not full_content or not units:
            # æ²¡æœ‰å®Œæ•´å†…å®¹ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹çš„content
            sorted_original = sorted(units, key=lambda u: u.get('start_line', 0))
            id_list = []
            blocks = {}
            for unit in sorted_original:
                block_id = f"block-{len(id_list) + 1}"  # block-1, block-2, ...
                id_list.append(block_id)
                content = unit.get('content', '')
                # å»æ‰å—æœ«å°¾çš„æ¢è¡Œç¬¦
                if content.endswith('\n'):
                    content = content[:-1]
                blocks[block_id] = {
                    "content": content,
                }
            return {
                "id_list": id_list,
                "blocks": blocks,
                "file_ends_with_newline": False,  # æ— æ³•ç¡®å®šï¼Œé»˜è®¤False
            }
        
        # æ”¶é›†æ‰€æœ‰å•å…ƒçš„å¼€å§‹è¡Œå·ä½œä¸ºåˆ†å‰²ç‚¹
        # å…³é”®ï¼šç›´æ¥ä½¿ç”¨æ¯ä¸ªå•å…ƒçš„start_lineï¼Œä¸åˆå¹¶èŒƒå›´ï¼Œä¿ç•™è¯­æ³•å•å…ƒè¾¹ç•Œ
        split_points_set = {1}  # ä»ç¬¬1è¡Œå¼€å§‹
        for unit in units:
            start_line = unit.get('start_line', 1)
            if start_line > 0:
                split_points_set.add(start_line)
        
        if not split_points_set:
            # æ²¡æœ‰æœ‰æ•ˆçš„åˆ†å‰²ç‚¹ï¼Œè¿”å›ç©ºåˆ—è¡¨
            return {"id_list": [], "blocks": {}, "file_ends_with_newline": False}
        
        # æŒ‰ç…§æ¯ä¸ªå•å…ƒçš„å¼€å§‹è¡Œä½œä¸ºåˆ†å‰²ç‚¹ï¼Œè¿ç»­åˆ†å‰²æ–‡ä»¶å†…å®¹
        # æ¯ä¸ªå—åŒ…å«ä»å½“å‰åˆ†å‰²ç‚¹åˆ°ä¸‹ä¸€ä¸ªåˆ†å‰²ç‚¹ä¹‹å‰çš„æ‰€æœ‰å†…å®¹
        # å…³é”®ï¼šç›´æ¥æŒ‰è¡Œå·èŒƒå›´ä»åŸå§‹å†…å®¹ä¸­æå–ï¼Œç¡®ä¿å®Œç¾æ¢å¤ï¼ˆåŒ…æ‹¬æ–‡ä»¶æœ«å°¾çš„æ¢è¡Œç¬¦å’Œæ‰€æœ‰ç©ºç™½è¡Œï¼‰
        # ä½¿ç”¨ split('\n') åˆ†å‰²ï¼Œç„¶åæ‰‹åŠ¨ä¸ºæ¯è¡Œæ·»åŠ æ¢è¡Œç¬¦ï¼ˆé™¤äº†æœ€åä¸€è¡Œï¼Œæ ¹æ®åŸå§‹æ–‡ä»¶å†³å®šï¼‰
        lines = full_content.split('\n')
        result_units = []
        
        # æ’åºåˆ†å‰²ç‚¹
        split_points = sorted(split_points_set)
        split_points.append(len(lines) + 1)  # æ–‡ä»¶æœ«å°¾
        
        # æŒ‰ç…§åˆ†å‰²ç‚¹è¿ç»­åˆ†å‰²æ–‡ä»¶
        # æ³¨æ„ï¼šå¦‚æœæ–‡ä»¶ä»¥æ¢è¡Œç¬¦ç»“å°¾ï¼Œsplit('\n')ä¼šåœ¨æœ«å°¾äº§ç”Ÿä¸€ä¸ªç©ºå­—ç¬¦ä¸²
        # æˆ‘ä»¬éœ€è¦æ­£ç¡®å¤„ç†è¿™ç§æƒ…å†µ
        file_ends_with_newline = full_content.endswith('\n')
        
        for idx in range(len(split_points) - 1):
            start_line = split_points[idx]  # 1-based
            next_start_line = split_points[idx + 1]  # 1-based
            
            # æå–ä»å½“å‰åˆ†å‰²ç‚¹åˆ°ä¸‹ä¸€ä¸ªåˆ†å‰²ç‚¹ä¹‹å‰çš„æ‰€æœ‰å†…å®¹
            unit_start_idx = max(0, start_line - 1)  # 0-basedç´¢å¼•
            unit_end_idx = min(len(lines) - 1, next_start_line - 2)  # 0-basedç´¢å¼•ï¼Œä¸‹ä¸€ä¸ªåˆ†å‰²ç‚¹ä¹‹å‰
            
            # ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
            if unit_start_idx <= unit_end_idx:
                # æå–è¡Œå¹¶é‡æ–°ç»„åˆï¼Œç¡®ä¿ä¿ç•™æ‰€æœ‰æ¢è¡Œç¬¦
                extracted_lines = lines[unit_start_idx:unit_end_idx + 1]
                
                # é‡æ–°ç»„åˆï¼šæ¯è¡Œåé¢æ·»åŠ æ¢è¡Œç¬¦
                # å¯¹äºéæœ€åä¸€ä¸ªå—ï¼Œæœ€åä¸€è¡Œä¹Ÿéœ€è¦æ¢è¡Œç¬¦ï¼Œå› ä¸ºä¸‹ä¸€ä¸ªå—ä»ä¸‹ä¸€è¡Œå¼€å§‹
                # å¯¹äºæœ€åä¸€ä¸ªå—ï¼Œæ ¹æ®åŸå§‹æ–‡ä»¶æ˜¯å¦ä»¥æ¢è¡Œç¬¦ç»“å°¾æ¥å†³å®š
                full_unit_content_parts = []
                is_last_block = (idx == len(split_points) - 2)
                
                for i, line in enumerate(extracted_lines):
                    if i < len(extracted_lines) - 1:
                        # ä¸æ˜¯æœ€åä¸€è¡Œï¼Œæ·»åŠ æ¢è¡Œç¬¦
                        full_unit_content_parts.append(line + '\n')
                    else:
                        # æœ€åä¸€è¡Œ
                        if not is_last_block:
                            # éæœ€åä¸€ä¸ªå—ï¼šæœ€åä¸€è¡Œå¿…é¡»æ·»åŠ æ¢è¡Œç¬¦ï¼Œå› ä¸ºä¸‹ä¸€ä¸ªå—ä»ä¸‹ä¸€è¡Œå¼€å§‹
                            # è¿™æ ·å¯ä»¥ä¿ç•™å—ä¹‹é—´çš„ç©ºç™½è¡Œ
                            full_unit_content_parts.append(line + '\n')
                        else:
                            # æœ€åä¸€ä¸ªå—ï¼šéœ€è¦ç‰¹æ®Šå¤„ç†
                            # å¦‚æœæ–‡ä»¶ä»¥æ¢è¡Œç¬¦ç»“å°¾ï¼Œä¸”æœ€åä¸€è¡Œæ˜¯ç©ºå­—ç¬¦ä¸²ï¼ˆæ¥è‡ªsplit('\n')çš„å‰¯ä½œç”¨ï¼‰ï¼Œ
                            # ä¸”ä¸æ˜¯å”¯ä¸€çš„ä¸€è¡Œï¼Œé‚£ä¹ˆå‰é¢çš„è¡Œå·²ç»è¾“å‡ºäº†æ¢è¡Œç¬¦ï¼Œè¿™é‡Œä¸éœ€è¦å†è¾“å‡º
                            if file_ends_with_newline and line == '' and len(extracted_lines) > 1:
                                # æœ€åä¸€è¡Œæ˜¯ç©ºå­—ç¬¦ä¸²ä¸”æ¥è‡ªtrailing newlineï¼Œä¸”ä¸æ˜¯å”¯ä¸€çš„ä¸€è¡Œ
                                # å‰é¢çš„è¡Œå·²ç»è¾“å‡ºäº†æ¢è¡Œç¬¦ï¼Œæ‰€ä»¥è¿™é‡Œä¸éœ€è¦å†è¾“å‡ºä»»ä½•å†…å®¹
                                # ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºä¸è¾“å‡ºä»»ä½•å†…å®¹
                                full_unit_content_parts.append('')
                            elif file_ends_with_newline:
                                # æ–‡ä»¶ä»¥æ¢è¡Œç¬¦ç»“å°¾ï¼Œæœ€åä¸€è¡Œéœ€è¦æ¢è¡Œç¬¦
                                full_unit_content_parts.append(line + '\n')
                            else:
                                # æ–‡ä»¶ä¸ä»¥æ¢è¡Œç¬¦ç»“å°¾
                                full_unit_content_parts.append(line)
                
                full_unit_content = ''.join(full_unit_content_parts)
                
                # å»æ‰å—æœ«å°¾çš„æ¢è¡Œç¬¦ï¼ˆå­˜å‚¨æ—¶å»æ‰ï¼Œæ¢å¤æ—¶å†æ·»åŠ ï¼‰
                if full_unit_content.endswith('\n'):
                    full_unit_content = full_unit_content[:-1]
                
                block_id = f"block-{len(result_units) + 1}"  # block-1, block-2, ...
                result_units.append({
                    "id": block_id,
                    "content": full_unit_content,
                })
        
        # è½¬æ¢ä¸º id_list å’Œ blocks æ ¼å¼
        id_list = [unit["id"] for unit in result_units]
        blocks = {
            unit["id"]: {
                "content": unit["content"],
            }
            for unit in result_units
        }
        
        # ä¿å­˜æ–‡ä»¶æ˜¯å¦ä»¥æ¢è¡Œç¬¦ç»“å°¾çš„ä¿¡æ¯ï¼ˆç”¨äºæ¢å¤æ—¶æ­£ç¡®å¤„ç†ï¼‰
        file_ends_with_newline = full_content.endswith('\n')
        
        return {
            "id_list": id_list,
            "blocks": blocks,
            "file_ends_with_newline": file_ends_with_newline,
        }
    
    def _save_file_cache(
        self, agent: Any, filepath: str, units: List[Dict[str, Any]], 
        total_lines: int, file_mtime: float, full_content: str = None
    ) -> None:
        """ä¿å­˜æ–‡ä»¶çš„ç»“æ„åŒ–ä¿¡æ¯åˆ°ç¼“å­˜
        
        Args:
            agent: Agentå®ä¾‹
            filepath: æ–‡ä»¶è·¯å¾„
            units: ç»“æ„åŒ–å•å…ƒåˆ—è¡¨
            total_lines: æ–‡ä»¶æ€»è¡Œæ•°
            file_mtime: æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            full_content: å®Œæ•´çš„æ–‡ä»¶å†…å®¹ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºç¡®ä¿å—ä¹‹é—´çš„ç©ºç™½è¡Œä¹Ÿè¢«åŒ…å«
        """
        if not agent:
            return
        
        cache = agent.get_user_data("read_code_cache")
        if not cache:
            cache = {}
            agent.set_user_data("read_code_cache", cache)
        
        abs_path = os.path.abspath(filepath)
        
        # è½¬æ¢ä¸º id_list å’Œ blocks æ ¼å¼
        cache_data = self._convert_units_to_sequential_ids(units, full_content)
        
        cache[abs_path] = {
            "id_list": cache_data["id_list"],
            "blocks": cache_data["blocks"],
            "total_lines": total_lines,
            "read_time": time.time(),
            "file_mtime": file_mtime,
            "file_ends_with_newline": cache_data.get("file_ends_with_newline", False),
        }
        agent.set_user_data("read_code_cache", cache)
    
    def _is_cache_valid(self, cache_info: Dict[str, Any], filepath: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            cache_info: ç¼“å­˜ä¿¡æ¯å­—å…¸
            filepath: æ–‡ä»¶è·¯å¾„
            
        Returns:
            Trueè¡¨ç¤ºç¼“å­˜æœ‰æ•ˆï¼ŒFalseè¡¨ç¤ºç¼“å­˜æ— æ•ˆ
        """
        if not cache_info:
            return False
        
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(filepath):
                return False
            
            # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ˜¯å¦å˜åŒ–
            current_mtime = os.path.getmtime(filepath)
            cached_mtime = cache_info.get("file_mtime")
            
            if cached_mtime is None or abs(current_mtime - cached_mtime) > 0.1:  # å…è®¸0.1ç§’çš„è¯¯å·®
                return False
            
            # æ£€æŸ¥ç¼“å­˜æ•°æ®ç»“æ„æ˜¯å¦å®Œæ•´
            if "id_list" not in cache_info or "blocks" not in cache_info or "total_lines" not in cache_info:
                return False
            
            return True
        except Exception:
            return False
    
    def _restore_file_from_cache(self, cache_info: Dict[str, Any]) -> str:
        """ä»ç¼“å­˜æ¢å¤æ–‡ä»¶å†…å®¹
        
        Args:
            cache_info: ç¼“å­˜ä¿¡æ¯å­—å…¸
            
        Returns:
            æ¢å¤çš„æ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²ï¼ˆä¸åŸå§‹æ–‡ä»¶å†…å®¹å®Œå…¨ä¸€è‡´ï¼‰
        """
        if not cache_info:
            return ""
        
        # æŒ‰ç…§ id_list çš„é¡ºåºæ¢å¤
        id_list = cache_info.get("id_list", [])
        blocks = cache_info.get("blocks", {})
        file_ends_with_newline = cache_info.get("file_ends_with_newline", False)
        
        result = []
        for idx, block_id in enumerate(id_list):
            block = blocks.get(block_id)
            if block:
                content = block.get('content', '')
                if content:
                    result.append(content)
                    # åœ¨å—ä¹‹é—´æ·»åŠ æ¢è¡Œç¬¦ï¼ˆæœ€åä¸€ä¸ªå—åé¢æ ¹æ®æ–‡ä»¶æ˜¯å¦ä»¥æ¢è¡Œç¬¦ç»“å°¾å†³å®šï¼‰
                    is_last_block = (idx == len(id_list) - 1)
                    if is_last_block:
                        # æœ€åä¸€ä¸ªå—ï¼šå¦‚æœæ–‡ä»¶ä»¥æ¢è¡Œç¬¦ç»“å°¾ï¼Œæ·»åŠ æ¢è¡Œç¬¦
                        if file_ends_with_newline:
                            result.append('\n')
                    else:
                        # éæœ€åä¸€ä¸ªå—ï¼šåœ¨å—ä¹‹é—´æ·»åŠ æ¢è¡Œç¬¦
                        result.append('\n')
        
        return ''.join(result) if result else ""
    
    def _estimate_structured_tokens(
        self, filepath: str, content: str, start_line: int, end_line: int, total_lines: int, raw_mode: bool = False
    ) -> int:
        """ä¼°ç®—ç»“æ„åŒ–è¾“å‡ºçš„tokenæ•°
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            content: æ–‡ä»¶å†…å®¹
            start_line: èµ·å§‹è¡Œå·
            end_line: ç»“æŸè¡Œå·
            total_lines: æ–‡ä»¶æ€»è¡Œæ•°
            
        Returns:
            ä¼°ç®—çš„tokenæ•°
        """
        try:
            if raw_mode:
                # åŸå§‹æ¨¡å¼ï¼šæŒ‰æ¯20è¡Œåˆ†ç»„è®¡ç®—token
                line_groups = self._extract_line_groups(content, start_line, end_line, group_size=20)
                if line_groups:
                    import_units = self._extract_imports(filepath, content, start_line, end_line)
                    all_units = import_units + line_groups[:1]
                    # ç¡®ä¿idå”¯ä¸€
                    all_units = self._ensure_unique_ids(all_units)
                    # æŒ‰è¡Œå·æ’åº
                    all_units.sort(key=lambda u: u['start_line'])
                    sample_output = self._format_structured_output(filepath, all_units, total_lines)
                    if len(line_groups) > 1:
                        group_tokens = get_context_token_count(sample_output)
                        return group_tokens * len(line_groups)
                    else:
                        return get_context_token_count(sample_output)
            else:
                # å°è¯•æå–è¯­æ³•å•å…ƒï¼ˆç¡®ä¿æ¯ä¸ªå•å…ƒä¸è¶…è¿‡50è¡Œï¼‰
                syntax_units = self._extract_syntax_units_with_split(filepath, content, start_line, end_line)
                
                if syntax_units:
                    # ä½¿ç”¨è¯­æ³•å•å…ƒç»“æ„åŒ–è¾“å‡ºæ ¼å¼è®¡ç®—token
                    import_units = self._extract_imports(filepath, content, start_line, end_line)
                    all_units = import_units + syntax_units[:1]
                    # ç¡®ä¿idå”¯ä¸€
                    all_units = self._ensure_unique_ids(all_units)
                    # æŒ‰è¡Œå·æ’åº
                    all_units.sort(key=lambda u: u['start_line'])
                    sample_output = self._format_structured_output(filepath, all_units, total_lines)
                    if len(syntax_units) > 1:
                        unit_tokens = get_context_token_count(sample_output)
                        return unit_tokens * len(syntax_units)
                    else:
                        return get_context_token_count(sample_output)
                else:
                    # ä½¿ç”¨ç©ºç™½è¡Œåˆ†ç»„æ ¼å¼è®¡ç®—tokenï¼ˆä¸æ”¯æŒè¯­è¨€æ—¶ï¼‰
                    # å…ˆæŒ‰ç©ºè¡Œåˆ†å‰²ï¼Œç„¶åå¯¹è¶…è¿‡20è¡Œçš„å—å†æŒ‰æ¯20è¡Œåˆ†å‰²
                    line_groups = self._extract_blank_line_groups_with_split(content, start_line, end_line)
                    if line_groups:
                        import_units = self._extract_imports(filepath, content, start_line, end_line)
                        all_units = import_units + line_groups[:1]
                        # ç¡®ä¿idå”¯ä¸€
                        all_units = self._ensure_unique_ids(all_units)
                        # æŒ‰è¡Œå·æ’åº
                        all_units.sort(key=lambda u: u['start_line'])
                        sample_output = self._format_structured_output(filepath, all_units, total_lines)
                        if len(line_groups) > 1:
                            group_tokens = get_context_token_count(sample_output)
                            return group_tokens * len(line_groups)
                        else:
                            return get_context_token_count(sample_output)
                    else:
                        # å›é€€åˆ°åŸå§‹æ ¼å¼è®¡ç®—
                        lines = content.split('\n')
                        selected_lines = lines[start_line - 1:end_line]
                        numbered_content = "".join(f"{i:5d}:{line}\n" for i, line in enumerate(selected_lines, start=start_line))
                        return get_context_token_count(numbered_content)
        except Exception:
            # å¦‚æœä¼°ç®—å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„è¡Œå·æ ¼å¼ä¼°ç®—
            lines = content.split('\n')
            selected_lines = lines[start_line - 1:end_line]
            numbered_content = "".join(f"{i:5d}:{line}\n" for i, line in enumerate(selected_lines, start=start_line))
            return get_context_token_count(numbered_content)
    
    def _get_max_token_limit(self, agent: Any = None) -> int:
        """è·å–åŸºäºå‰©ä½™tokenæ•°é‡çš„tokené™åˆ¶
        
        Args:
            agent: Agentå®ä¾‹ï¼Œç”¨äºè·å–æ¨¡å‹å’Œå‰©ä½™tokenæ•°é‡
            
        Returns:
            int: å…è®¸çš„æœ€å¤§tokenæ•°ï¼ˆå‰©ä½™tokençš„2/3ï¼Œæˆ–è‡³å°‘ä¿ç•™1/3å‰©ä½™tokenï¼‰
        """
        try:
            # ä¼˜å…ˆä½¿ç”¨å‰©ä½™tokenæ•°é‡
            if agent and hasattr(agent, "model"):
                try:
                    remaining_tokens = agent.model.get_remaining_token_count()
                    # ä½¿ç”¨å‰©ä½™tokençš„2/3ä½œä¸ºé™åˆ¶ï¼Œä¿ç•™1/3ä½œä¸ºå®‰å…¨ä½™é‡
                    limit_tokens = int(remaining_tokens * 2 / 3)
                    # ç¡®ä¿è‡³å°‘è¿”å›ä¸€ä¸ªåˆç†çš„å€¼
                    if limit_tokens > 0:
                        return limit_tokens
                except Exception:
                    pass
            
            # å›é€€æ–¹æ¡ˆï¼šä½¿ç”¨è¾“å…¥çª—å£çš„2/3
            model_group = None
            if agent:
                model_group = getattr(agent, "model_group", None)
            
            max_input_tokens = get_max_input_token_count(model_group)
            # è®¡ç®—2/3é™åˆ¶çš„tokenæ•°
            limit_tokens = int(max_input_tokens * 2 / 3)
            return limit_tokens
        except Exception:
            # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆå‡è®¾32000 tokenï¼Œ2/3æ˜¯21333ï¼‰
            return 21333
    def _handle_single_file(
        self, filepath: str, start_line: int = 1, end_line: int = -1, agent: Any = None, raw_mode: bool = False
    ) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶çš„è¯»å–æ“ä½œ

        Args:
            filepath (str): æ–‡ä»¶è·¯å¾„
            start_line (int): èµ·å§‹è¡Œå·ï¼Œé»˜è®¤ä¸º1
            end_line (int): ç»“æŸè¡Œå·ï¼Œé»˜è®¤ä¸º-1è¡¨ç¤ºæ–‡ä»¶æœ«å°¾
            agent: Agentå®ä¾‹ï¼Œç”¨äºè·å–ä¸Šä¸‹æ–‡ç®¡ç†å™¨

        Returns:
            Dict[str, Any]: åŒ…å«æˆåŠŸçŠ¶æ€ã€è¾“å‡ºå†…å®¹å’Œé”™è¯¯ä¿¡æ¯çš„å­—å…¸
        """
        try:
            abs_path = os.path.abspath(filepath)

            # æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
            if not os.path.exists(abs_path):
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": f"æ–‡ä»¶ä¸å­˜åœ¨: {abs_path}",
                }

            # æ–‡ä»¶å¤§å°é™åˆ¶æ£€æŸ¥ï¼ˆ10MBï¼‰
            if os.path.getsize(abs_path) > 10 * 1024 * 1024:
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": "æ–‡ä»¶è¿‡å¤§ (>10MB)",
                }

            # è¯»å–æ–‡ä»¶å†…å®¹
            # ç¬¬ä¸€éæµå¼è¯»å–ï¼Œä»…ç»Ÿè®¡æ€»è¡Œæ•°ï¼Œé¿å…ä¸€æ¬¡æ€§è¯»å…¥å†…å­˜
            with open(abs_path, "r", encoding="utf-8", errors="ignore") as f:
                total_lines = sum(1 for _ in f)

            # å¤„ç†ç©ºæ–‡ä»¶æƒ…å†µ
            if total_lines == 0:
                return {
                    "success": True,
                    "stdout": f"\nğŸ” æ–‡ä»¶: {abs_path}\nğŸ“„ æ–‡ä»¶ä¸ºç©º (0è¡Œ)\n",
                    "stderr": "",
                }

            # å¤„ç†ç‰¹æ®Šå€¼-1è¡¨ç¤ºæ–‡ä»¶æœ«å°¾
            if end_line == -1:
                end_line = total_lines
            else:
                end_line = (
                    max(1, min(end_line, total_lines))
                    if end_line >= 0
                    else total_lines + end_line + 1
                )

            start_line = (
                max(1, min(start_line, total_lines))
                if start_line >= 0
                else total_lines + start_line + 1
            )

            if start_line > end_line:

                return {
                    "success": False,
                    "stdout": "",
                    "stderr": f"æ— æ•ˆçš„è¡ŒèŒƒå›´ [{start_line}-{end_line}] (æ€»è¡Œæ•°: {total_lines})",
                }

            # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            file_mtime = os.path.getmtime(abs_path)
            
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
            cache_info = self._get_file_cache(agent, abs_path)
            use_cache = self._is_cache_valid(cache_info, abs_path)

            # è¯»å–å®Œæ•´æ–‡ä»¶å†…å®¹ç”¨äºè¯­æ³•åˆ†æå’Œtokenè®¡ç®—
            if use_cache:
                # ä»ç¼“å­˜æ¢å¤æ–‡ä»¶å†…å®¹
                full_content = self._restore_file_from_cache(cache_info)
                # å¦‚æœæ¢å¤å¤±è´¥ï¼Œé‡æ–°è¯»å–æ–‡ä»¶
                if not full_content:
                    with open(abs_path, "r", encoding="utf-8", errors="ignore") as f:
                        full_content = f.read()
            else:
                # è¯»å–æ–‡ä»¶å†…å®¹
                with open(abs_path, "r", encoding="utf-8", errors="ignore") as f:
                    full_content = f.read()
            
            # è¯»å–è¦è¯»å–çš„è¡ŒèŒƒå›´å†…å®¹
            selected_content_lines = []
            lines = full_content.split('\n')
            for i in range(start_line - 1, min(end_line, len(lines))):
                selected_content_lines.append(lines[i])
            
            # ä¼°ç®—ç»“æ„åŒ–è¾“å‡ºçš„tokenæ•°
            content_tokens = self._estimate_structured_tokens(abs_path, full_content, start_line, end_line, total_lines, raw_mode)
            
            max_token_limit = self._get_max_token_limit(agent)
            
            # æ£€æŸ¥å•æ–‡ä»¶è¯»å–tokenæ•°æ˜¯å¦è¶…è¿‡2/3é™åˆ¶
            if content_tokens > max_token_limit:
                read_lines = end_line - start_line + 1
                
                # è®¡ç®—å®‰å…¨è¯»å–çš„è¡Œæ•° (æŒ‰æ¯”ä¾‹ç¼©å‡)
                safe_lines = int((max_token_limit / content_tokens) * read_lines)
                safe_lines = max(1, min(safe_lines, read_lines))
                safe_end_line = start_line + safe_lines - 1
                
                # è¯»å–å®‰å…¨èŒƒå›´å†…çš„å†…å®¹
                selected_content_lines = []
                for i in range(start_line - 1, min(safe_end_line, len(lines))):
                    selected_content_lines.append(lines[i])
                
                # æ„é€ éƒ¨åˆ†è¯»å–ç»“æœ
                partial_content = '\n'.join(selected_content_lines)
                
                return {
                    "success": True,
                    "stdout": (
                        f"âš ï¸ è­¦å‘Š: ä»…è¯»å–å‰{safe_lines}è¡Œ (å…±{read_lines}è¡Œ)ï¼Œå› ä¸ºå†…å®¹è¶…å‡ºé™åˆ¶\n"
                        f"ğŸ“Š å®é™…è¯»å–èŒƒå›´: {start_line}-{safe_end_line} (åŸè¯·æ±‚èŒƒå›´: {start_line}-{end_line})\n\n"
                        f"{partial_content}\n\n"
                        f"ğŸ’¡ å»ºè®®:\n"
                        f"   1. å¦‚éœ€ç»§ç»­è¯»å–ï¼Œè¯·ä½¿ç”¨:\n"
                        f"      start_line={safe_end_line + 1}&end_line={end_line}\n"
                        f"   2. éœ€è¦è¯»å–å…¨éƒ¨å†…å®¹? è¯·ç¼©å°è¡ŒèŒƒå›´æˆ–åˆ†æ‰¹è¯»å–"
                    ),
                    "stderr": (
                        f"åŸå§‹è¯·æ±‚èŒƒå›´ {start_line}-{end_line} è¶…è¿‡tokené™åˆ¶ "
                        f"({content_tokens}/{max_token_limit} tokens)"
                    ),
                }

            # ç”Ÿæˆæ•´ä¸ªæ–‡ä»¶çš„ç»“æ„åŒ–ä¿¡æ¯ï¼ˆç”¨äºç¼“å­˜ï¼‰
            # æå–æ•´ä¸ªæ–‡ä»¶çš„å¯¼å…¥/åŒ…å«è¯­å¥
            full_import_units = self._extract_imports(abs_path, full_content, 1, total_lines)
            
            # ç”Ÿæˆæ•´ä¸ªæ–‡ä»¶çš„ç»“æ„åŒ–å•å…ƒ
            full_structured_units = None
            
            if raw_mode:
                # åŸå§‹è¯»å–æ¨¡å¼ï¼šæŒ‰æ¯20è¡Œåˆ†ç»„ï¼ˆæ•´ä¸ªæ–‡ä»¶ï¼‰
                full_line_groups = self._extract_line_groups(full_content, 1, total_lines, group_size=20)
                # åˆå¹¶å¯¼å…¥å•å…ƒå’Œè¡Œå·åˆ†ç»„
                full_all_units = full_import_units + full_line_groups
                # ç¡®ä¿idå”¯ä¸€
                full_all_units = self._ensure_unique_ids(full_all_units)
                # æŒ‰è¡Œå·æ’åº
                full_all_units.sort(key=lambda u: u['start_line'])
                full_structured_units = full_all_units
            else:
                # å°è¯•æå–æ•´ä¸ªæ–‡ä»¶çš„è¯­æ³•å•å…ƒï¼ˆç¡®ä¿æ¯ä¸ªå•å…ƒä¸è¶…è¿‡50è¡Œï¼‰
                full_syntax_units = self._extract_syntax_units_with_split(abs_path, full_content, 1, total_lines)
                
                # æ£€æµ‹è¯­è¨€ç±»å‹
                if LANGUAGE_SUPPORT_AVAILABLE:
                    try:
                        detect_language(abs_path)
                    except Exception:
                        pass
                
                if full_syntax_units:
                    # åˆå¹¶å¯¼å…¥å•å…ƒå’Œè¯­æ³•å•å…ƒ
                    full_all_units = full_import_units + full_syntax_units
                    # ç¡®ä¿idå”¯ä¸€
                    full_all_units = self._ensure_unique_ids(full_all_units)
                    # æŒ‰è¡Œå·æ’åº
                    full_all_units.sort(key=lambda u: u['start_line'])
                    full_structured_units = full_all_units
                else:
                    # ä½¿ç”¨ç©ºç™½è¡Œåˆ†ç»„ç»“æ„åŒ–è¾“å‡ºï¼ˆä¸æ”¯æŒè¯­è¨€æ—¶ï¼‰
                    # å…ˆæŒ‰ç©ºè¡Œåˆ†å‰²ï¼Œç„¶åå¯¹è¶…è¿‡20è¡Œçš„å—å†æŒ‰æ¯20è¡Œåˆ†å‰²ï¼ˆæ•´ä¸ªæ–‡ä»¶ï¼‰
                    full_line_groups = self._extract_blank_line_groups_with_split(full_content, 1, total_lines)
                    # åˆå¹¶å¯¼å…¥å•å…ƒå’Œè¡Œå·åˆ†ç»„
                    full_all_units = full_import_units + full_line_groups
                    # ç¡®ä¿idå”¯ä¸€
                    full_all_units = self._ensure_unique_ids(full_all_units)
                    # æŒ‰è¡Œå·æ’åº
                    full_all_units.sort(key=lambda u: u['start_line'])
                    full_structured_units = full_all_units
            
            # ä¿å­˜æ•´ä¸ªæ–‡ä»¶çš„ç»“æ„åŒ–ä¿¡æ¯åˆ°ç¼“å­˜
            if full_structured_units is not None:
                self._save_file_cache(agent, abs_path, full_structured_units, total_lines, file_mtime, full_content)
            
            # å¦‚æœç¼“å­˜æœ‰æ•ˆï¼Œç›´æ¥ä½¿ç”¨ç¼“å­˜ä¸­çš„blocksè¾“å‡º
            if agent:
                cache_info = self._get_file_cache(agent, abs_path)
                if cache_info and self._is_cache_valid(cache_info, abs_path):
                    # ç›´æ¥ä»ç¼“å­˜ä¸­è·å–å¯¹åº”èŒƒå›´çš„blocks
                    cached_blocks = self._get_blocks_from_cache(cache_info, start_line, end_line)
                    if cached_blocks:
                        # è½¬æ¢ä¸ºunitsæ ¼å¼ï¼ˆç”¨äºè¾“å‡ºï¼‰
                        structured_units = []
                        for block in cached_blocks:
                            structured_units.append({
                                "block_id": block["block_id"],
                                "content": block["content"],
                            })
                        output = self._format_structured_output(abs_path, structured_units, total_lines, agent)
                    else:
                        output = ""
                else:
                    # ç¼“å­˜æ— æ•ˆï¼Œé‡æ–°æå–units
                    # æå–è¯·æ±‚èŒƒå›´çš„ç»“æ„åŒ–å•å…ƒï¼ˆç”¨äºè¾“å‡ºï¼‰
                    import_units = self._extract_imports(abs_path, full_content, start_line, end_line)
                    
                    # ç¡®å®šä½¿ç”¨çš„ç»“æ„åŒ–å•å…ƒï¼ˆè¯­æ³•å•å…ƒæˆ–è¡Œå·åˆ†ç»„ï¼‰
                    structured_units = None
                    
                    if raw_mode:
                        # åŸå§‹è¯»å–æ¨¡å¼ï¼šæŒ‰æ¯20è¡Œåˆ†ç»„
                        line_groups = self._extract_line_groups(full_content, start_line, end_line, group_size=20)
                        # åˆå¹¶å¯¼å…¥å•å…ƒå’Œè¡Œå·åˆ†ç»„
                        all_units = import_units + line_groups
                        # ç¡®ä¿idå”¯ä¸€
                        all_units = self._ensure_unique_ids(all_units)
                        # æŒ‰è¡Œå·æ’åºï¼Œæ‰€æœ‰å•å…ƒæŒ‰åœ¨æ–‡ä»¶ä¸­çš„å®é™…ä½ç½®æ’åº
                        all_units.sort(key=lambda u: u['start_line'])
                        structured_units = all_units
                    else:
                        # å°è¯•æå–è¯­æ³•å•å…ƒï¼ˆç»“æ„åŒ–è¯»å–ï¼Œfull_content å·²åœ¨ä¸Šé¢è¯»å–ï¼Œç¡®ä¿æ¯ä¸ªå•å…ƒä¸è¶…è¿‡50è¡Œï¼‰
                        syntax_units = self._extract_syntax_units_with_split(abs_path, full_content, start_line, end_line)
                        
                        if syntax_units:
                            # åˆå¹¶å¯¼å…¥å•å…ƒå’Œè¯­æ³•å•å…ƒ
                            all_units = import_units + syntax_units
                            # ç¡®ä¿idå”¯ä¸€
                            all_units = self._ensure_unique_ids(all_units)
                            # æŒ‰è¡Œå·æ’åºï¼Œæ‰€æœ‰å•å…ƒæŒ‰åœ¨æ–‡ä»¶ä¸­çš„å®é™…ä½ç½®æ’åº
                            all_units.sort(key=lambda u: u['start_line'])
                            structured_units = all_units
                        else:
                            # ä½¿ç”¨ç©ºç™½è¡Œåˆ†ç»„ç»“æ„åŒ–è¾“å‡ºï¼ˆä¸æ”¯æŒè¯­è¨€æ—¶ï¼‰
                            # å…ˆæŒ‰ç©ºè¡Œåˆ†å‰²ï¼Œç„¶åå¯¹è¶…è¿‡20è¡Œçš„å—å†æŒ‰æ¯20è¡Œåˆ†å‰²
                            line_groups = self._extract_blank_line_groups_with_split(full_content, start_line, end_line)
                            # åˆå¹¶å¯¼å…¥å•å…ƒå’Œè¡Œå·åˆ†ç»„
                            all_units = import_units + line_groups
                            # ç¡®ä¿idå”¯ä¸€
                            all_units = self._ensure_unique_ids(all_units)
                            # æŒ‰è¡Œå·æ’åºï¼Œæ‰€æœ‰å•å…ƒæŒ‰åœ¨æ–‡ä»¶ä¸­çš„å®é™…ä½ç½®æ’åº
                            all_units.sort(key=lambda u: u['start_line'])
                            structured_units = all_units
                    
                    if structured_units:
                        output = self._format_structured_output(abs_path, structured_units, total_lines, agent)
                    else:
                        output = ""
            else:
                # æ²¡æœ‰agentï¼Œæ— æ³•ä½¿ç”¨ç¼“å­˜ï¼Œé‡æ–°æå–units
                import_units = self._extract_imports(abs_path, full_content, start_line, end_line)
                
                if raw_mode:
                    line_groups = self._extract_line_groups(full_content, start_line, end_line, group_size=20)
                    all_units = import_units + line_groups
                    all_units = self._ensure_unique_ids(all_units)
                    all_units.sort(key=lambda u: u['start_line'])
                    structured_units = all_units
                else:
                    syntax_units = self._extract_syntax_units_with_split(abs_path, full_content, start_line, end_line)
                    if syntax_units:
                        all_units = import_units + syntax_units
                        all_units = self._ensure_unique_ids(all_units)
                        all_units.sort(key=lambda u: u['start_line'])
                        structured_units = all_units
                    else:
                        line_groups = self._extract_blank_line_groups_with_split(full_content, start_line, end_line)
                        all_units = import_units + line_groups
                        all_units = self._ensure_unique_ids(all_units)
                        all_units.sort(key=lambda u: u['start_line'])
                        structured_units = all_units
                
                if structured_units:
                    output = self._format_structured_output(abs_path, structured_units, total_lines, agent)
                else:
                    output = ""

            # å°è¯•è·å–å¹¶é™„åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
            context_info = self._get_file_context(abs_path, start_line, end_line, agent)
            if context_info:
                output += context_info

            if agent:
                files = agent.get_user_data("files")
                if files:
                    files.append(abs_path)
                else:
                    files = [abs_path]
                agent.set_user_data("files", files)

            return {"success": True, "stdout": output, "stderr": ""}

        except Exception as e:
            print(f"âŒ {str(e)}")
            return {"success": False, "stdout": "", "stderr": f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}"}

    def _handle_merged_ranges(
        self, filepath: str, requests: List[Dict], agent: Any = None
    ) -> Dict[str, Any]:
        """å¤„ç†åŒä¸€æ–‡ä»¶çš„å¤šä¸ªèŒƒå›´è¯·æ±‚ï¼Œåˆå¹¶åå»é‡
        
        Args:
            filepath: æ–‡ä»¶ç»å¯¹è·¯å¾„
            requests: èŒƒå›´è¯·æ±‚åˆ—è¡¨ï¼Œæ¯ä¸ªè¯·æ±‚åŒ…å« start_line, end_line, raw_mode
            agent: Agentå®ä¾‹
            
        Returns:
            Dict[str, Any]: åŒ…å«æˆåŠŸçŠ¶æ€ã€è¾“å‡ºå†…å®¹å’Œé”™è¯¯ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
            if not os.path.exists(filepath):
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}",
                }
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(filepath, "r", encoding="utf-8", errors="ignore") as f:
                full_content = f.read()
            
            total_lines = len(full_content.split('\n'))
            if total_lines == 0:
                return {
                    "success": True,
                    "stdout": f"\nğŸ” æ–‡ä»¶: {filepath}\nğŸ“„ æ–‡ä»¶ä¸ºç©º (0è¡Œ)\n",
                    "stderr": "",
                }
            
            # å…ˆç¡®ä¿ç¼“å­˜å­˜åœ¨ï¼ˆé€šè¿‡è¯»å–æ•´ä¸ªæ–‡ä»¶å»ºç«‹ç¼“å­˜ï¼‰
            first_request = requests[0]
            self._handle_single_file(
                filepath, 1, -1, agent, first_request.get("raw_mode", False)
            )
            
            # è·å–ç¼“å­˜
            cache_info = self._get_file_cache(agent, filepath)
            if not cache_info or not self._is_cache_valid(cache_info, filepath):
                # ç¼“å­˜æ— æ•ˆï¼Œä½¿ç”¨åˆå¹¶èŒƒå›´çš„æ–¹å¼å»é‡
                # åˆå¹¶æ‰€æœ‰èŒƒå›´ï¼Œè®¡ç®—æœ€å°èµ·å§‹è¡Œå’Œæœ€å¤§ç»“æŸè¡Œ
                min_start = float('inf')
                max_end = 0
                raw_mode = False
                for req in requests:
                    start_line = req.get("start_line", 1)
                    end_line = req.get("end_line", -1)
                    raw_mode = raw_mode or req.get("raw_mode", False)
                    
                    # å¤„ç†ç‰¹æ®Šå€¼
                    if end_line == -1:
                        end_line = total_lines
                    else:
                        end_line = max(1, min(end_line, total_lines)) if end_line >= 0 else total_lines + end_line + 1
                    start_line = max(1, min(start_line, total_lines)) if start_line >= 0 else total_lines + start_line + 1
                    
                    min_start = min(min_start, start_line)
                    max_end = max(max_end, end_line)
                
                # ç”¨åˆå¹¶åçš„èŒƒå›´è¯»å–ä¸€æ¬¡ï¼Œè‡ªç„¶å°±å»é‡äº†
                result = self._handle_single_file(
                    filepath, int(min_start), int(max_end), agent, raw_mode
                )
                return result
            
            # æ”¶é›†æ‰€æœ‰èŒƒå›´è¦†ç›–çš„å—IDï¼ˆå»é‡ï¼‰
            seen_block_ids = set()
            merged_blocks = []
            
            for req in requests:
                start_line = req.get("start_line", 1)
                end_line = req.get("end_line", -1)
                
                # å¤„ç†ç‰¹æ®Šå€¼
                if end_line == -1:
                    end_line = total_lines
                else:
                    end_line = max(1, min(end_line, total_lines)) if end_line >= 0 else total_lines + end_line + 1
                start_line = max(1, min(start_line, total_lines)) if start_line >= 0 else total_lines + start_line + 1
                
                # ä»ç¼“å­˜è·å–å¯¹åº”èŒƒå›´çš„å—
                cached_blocks = self._get_blocks_from_cache(cache_info, start_line, end_line)
                for block in cached_blocks:
                    block_id = block["block_id"]
                    if block_id not in seen_block_ids:
                        seen_block_ids.add(block_id)
                        merged_blocks.append(block)
            
            # æŒ‰block_idæ’åºï¼ˆblock-1, block-2, ...ï¼‰
            def extract_block_num(block):
                block_id = block.get("block_id", "block-0")
                try:
                    return int(block_id.split("-")[1])
                except (IndexError, ValueError):
                    return 0
            
            merged_blocks.sort(key=extract_block_num)
            
            # è½¬æ¢ä¸ºunitsæ ¼å¼å¹¶æ ¼å¼åŒ–è¾“å‡º
            structured_units = []
            for block in merged_blocks:
                structured_units.append({
                    "block_id": block["block_id"],
                    "content": block["content"],
                })
            
            output = self._format_structured_output(filepath, structured_units, total_lines, agent)
            
            # å°è¯•è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆä½¿ç”¨åˆå¹¶åçš„èŒƒå›´ï¼‰
            all_start_lines = [req.get("start_line", 1) for req in requests]
            all_end_lines = [req.get("end_line", total_lines) for req in requests]
            min_start = min(all_start_lines)
            max_end = max(all_end_lines)
            context_info = self._get_file_context(filepath, min_start, max_end, agent)
            if context_info:
                output += context_info
            
            return {"success": True, "stdout": output, "stderr": ""}
            
        except Exception as e:
            return {"success": False, "stdout": "", "stderr": f"åˆå¹¶èŒƒå›´è¯»å–å¤±è´¥: {str(e)}"}

    def _get_file_context(
        self, filepath: str, start_line: int, end_line: int, agent: Any = None
    ) -> str:
        """è·å–æ–‡ä»¶çš„ä¸Šä¸‹æ–‡ä¿¡æ¯

        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            start_line: èµ·å§‹è¡Œå·
            end_line: ç»“æŸè¡Œå·
            agent: Agentå®ä¾‹

        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å­—ç¬¦ä¸²ï¼Œå¦‚æœæ— æ³•è·å–åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            # å°è¯•ä»Agentè·å–CodeAgentå®ä¾‹
            if not agent:
                return ""

            # é€šè¿‡agentè·å–CodeAgentå®ä¾‹
            # CodeAgentåœ¨åˆå§‹åŒ–æ—¶ä¼šå°†è‡ªèº«å…³è”åˆ°agent
            code_agent = getattr(agent, "_code_agent", None)
            if not code_agent:
                return ""

            # è·å–ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            context_manager = getattr(code_agent, "context_manager", None)
            if not context_manager:
                return ""

            # è¾“å‡ºä¸Šä¸‹æ–‡æ„ŸçŸ¥æ—¥å¿—
            file_name = os.path.basename(filepath)
            if start_line == end_line:
                line_info = f"ç¬¬{start_line}è¡Œ"
            else:
                line_info = f"ç¬¬{start_line}-{end_line}è¡Œ"
            print(f"ğŸ§  æ­£åœ¨åˆ†æä»£ç ä¸Šä¸‹æ–‡ ({file_name}, {line_info})...")

            # ç¡®ä¿æ–‡ä»¶å·²æ›´æ–°åˆ°ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            # å¦‚æœæ–‡ä»¶å†…å®¹å·²ç¼“å­˜ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™è¯»å–å¹¶æ›´æ–°
            if not hasattr(context_manager, "_file_cache") or filepath not in context_manager._file_cache:
                try:
                    with open(filepath, "r", encoding="utf-8", errors="replace") as f:
                        content = f.read()
                    context_manager.update_context_for_file(filepath, content)
                except Exception:
                    # å¦‚æœè¯»å–å¤±è´¥ï¼Œå°è¯•è·å–å·²æœ‰ä¸Šä¸‹æ–‡
                    pass

            # è·å–ç¼–è¾‘ä¸Šä¸‹æ–‡
            edit_context = context_manager.get_edit_context(filepath, start_line, end_line)

            # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
            if not edit_context.context_summary or edit_context.context_summary == "No context available":
                return ""

            # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ä¿¡æ¯
            context_lines = ["\nğŸ“‹ ä»£ç ä¸Šä¸‹æ–‡ä¿¡æ¯:"]
            context_lines.append("â”€" * 60)

            if edit_context.current_scope:
                scope_info = f"ğŸ“ å½“å‰ä½œç”¨åŸŸ: {edit_context.current_scope.kind} `{edit_context.current_scope.name}`"
                if edit_context.current_scope.signature:
                    scope_info += f"\n   â””â”€ ç­¾å: {edit_context.current_scope.signature}"
                context_lines.append(scope_info)

            if edit_context.used_symbols:
                # å¯¹ç¬¦å·å»é‡ï¼ˆåŸºäº name + file_path + line_startï¼‰
                seen_symbols = set()
                unique_symbols = []
                for s in edit_context.used_symbols:
                    key = (s.name, getattr(s, 'file_path', ''), getattr(s, 'line_start', 0))
                    if key not in seen_symbols:
                        seen_symbols.add(key)
                        unique_symbols.append(s)
                
                # åŒºåˆ†å®šä¹‰å’Œè°ƒç”¨ï¼Œæ˜¾ç¤ºå®šä¹‰ä½ç½®ä¿¡æ¯
                definitions = []
                calls = []
                for symbol in unique_symbols[:10]:
                    is_def = getattr(symbol, 'is_definition', False)
                    if is_def:
                        definitions.append(symbol)
                    else:
                        calls.append(symbol)
                
                # æ˜¾ç¤ºå®šä¹‰
                if definitions:
                    def_names = [f"`{s.name}`" for s in definitions]
                    context_lines.append(f"ğŸ“ å®šä¹‰çš„ç¬¦å·: {', '.join(def_names)}")
                
                # æ˜¾ç¤ºè°ƒç”¨ï¼ˆå¸¦å®šä¹‰ä½ç½®ä¿¡æ¯ï¼‰
                if calls:
                    call_info = []
                    for symbol in calls:
                        def_loc = getattr(symbol, 'definition_location', None)
                        if def_loc:
                            def_file = os.path.basename(def_loc.file_path)
                            def_line = def_loc.line_start
                            call_info.append(f"`{symbol.name}` â†’ {def_file}:{def_line}")
                        else:
                            call_info.append(f"`{symbol.name}`")
                    context_lines.append(f"ğŸ”— è°ƒç”¨çš„ç¬¦å·: {', '.join(call_info)}")
                
                # å¦‚æœè¿˜æœ‰æ›´å¤šç¬¦å·
                more = len(edit_context.used_symbols) - 10
                if more > 0:
                    context_lines.append(f"   ... è¿˜æœ‰{more}ä¸ªç¬¦å·")

            # ä¸å†æ„ŸçŸ¥å¯¼å…¥ç¬¦å·

            if edit_context.relevant_files:
                # å¯¹ç›¸å…³æ–‡ä»¶å»é‡
                unique_files = list(dict.fromkeys(edit_context.relevant_files))
                rel_files = unique_files[:10]
                files_str = "\n   ".join(f"â€¢ {os.path.relpath(f, context_manager.project_root)}" for f in rel_files)
                more = len(unique_files) - 10
                if more > 0:
                    files_str += f"\n   ... è¿˜æœ‰{more}ä¸ªç›¸å…³æ–‡ä»¶"
                context_lines.append(f"ğŸ“ ç›¸å…³æ–‡ä»¶ ({len(unique_files)}ä¸ª):\n   {files_str}")

            context_lines.append("â”€" * 60)
            context_lines.append("")  # ç©ºè¡Œ

            # æ‰“å°ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç»“æœåˆ°æ§åˆ¶å°
            context_output = "\n".join(context_lines)
            print(f"ğŸ§  ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç»“æœ:\n{context_output}")
            
            return context_output

        except Exception:
            # é™é»˜å¤±è´¥ï¼Œä¸å½±å“æ–‡ä»¶è¯»å–
            return ""

    def execute(self, args: Dict) -> Dict[str, Any]:
        """æ‰§è¡Œä»£ç è¯»å–æ“ä½œ

        Args:
            args (Dict): åŒ…å«æ–‡ä»¶åˆ—è¡¨çš„å‚æ•°å­—å…¸

        Returns:
            Dict[str, Any]: åŒ…å«æˆåŠŸçŠ¶æ€ã€è¾“å‡ºå†…å®¹å’Œé”™è¯¯ä¿¡æ¯çš„å­—å…¸
        """
        try:
            agent = args.get("agent", None)
            if "files" not in args or not isinstance(args["files"], list):
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": "å‚æ•°ä¸­å¿…é¡»åŒ…å«æ–‡ä»¶åˆ—è¡¨",
                }
            
            if len(args["files"]) == 0:
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": "æ–‡ä»¶åˆ—è¡¨ä¸èƒ½ä¸ºç©º",
                }

            all_outputs = []
            overall_success = True
            status_lines = []
            total_tokens = 0  # ç´¯è®¡è¯»å–çš„tokenæ•°
            max_token_limit = self._get_max_token_limit(agent)

            # ç¬¬ä¸€éï¼šæ£€æŸ¥æ‰€æœ‰æ–‡ä»¶çš„ç´¯è®¡tokenæ•°æ˜¯å¦è¶…è¿‡é™åˆ¶
            file_read_info = []  # å­˜å‚¨æ¯ä¸ªæ–‡ä»¶è¦è¯»å–çš„ä¿¡æ¯
            for file_info in args["files"]:
                if not isinstance(file_info, dict) or "path" not in file_info:
                    continue
                
                filepath = file_info["path"].strip()
                start_line = file_info.get("start_line", 1)
                end_line = file_info.get("end_line", -1)
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶è®¡ç®—è¦è¯»å–çš„tokenæ•°
                abs_path = os.path.abspath(filepath)
                if not os.path.exists(abs_path):
                    continue
                
                try:
                    # ç»Ÿè®¡æ€»è¡Œæ•°
                    with open(abs_path, "r", encoding="utf-8", errors="ignore") as f:
                        total_lines = sum(1 for _ in f)
                    
                    if total_lines == 0:
                        continue
                    
                    # è®¡ç®—å®é™…è¦è¯»å–çš„è¡ŒèŒƒå›´
                    if end_line == -1:
                        actual_end_line = total_lines
                    else:
                        actual_end_line = (
                            max(1, min(end_line, total_lines))
                            if end_line >= 0
                            else total_lines + end_line + 1
                        )
                    
                    actual_start_line = (
                        max(1, min(start_line, total_lines))
                        if start_line >= 0
                        else total_lines + start_line + 1
                    )
                    
                    if actual_start_line <= actual_end_line:
                        # è¯»å–å®Œæ•´æ–‡ä»¶å†…å®¹ç”¨äºtokenä¼°ç®—
                        with open(abs_path, "r", encoding="utf-8", errors="ignore") as f:
                            file_content = f.read()
                        
                        # ä¼°ç®—ç»“æ„åŒ–è¾“å‡ºçš„tokenæ•°
                        raw_mode = file_info.get("raw_mode", False)
                        content_tokens = self._estimate_structured_tokens(
                            abs_path, file_content, actual_start_line, actual_end_line, total_lines, raw_mode
                        )
                        
                        file_read_info.append({
                            "filepath": filepath,
                            "start_line": actual_start_line,
                            "end_line": actual_end_line,
                            "read_lines": actual_end_line - actual_start_line + 1,
                            "tokens": content_tokens,
                            "file_info": file_info,
                        })
                        total_tokens += content_tokens
                except Exception:
                    continue

            # æ£€æŸ¥ç´¯è®¡tokenæ•°æ˜¯å¦è¶…è¿‡é™åˆ¶
            if total_tokens > max_token_limit:
                file_list = "\n   ".join(
                    f"â€¢ {info['filepath']}: {info['tokens']} tokens ({info['read_lines']} è¡Œ, èŒƒå›´: {info['start_line']}-{info['end_line']})"
                    for info in file_read_info[:10]
                )
                more_files = len(file_read_info) - 10
                if more_files > 0:
                    file_list += f"\n   ... è¿˜æœ‰ {more_files} ä¸ªæ–‡ä»¶"
                
                return {
                    "success": False,
                    "stdout": "",
                    "stderr": (
                        f"âš ï¸ ç´¯è®¡è¯»å–èŒƒå›´è¿‡å¤§: è¯·æ±‚ç´¯è®¡è¯»å–å†…å®¹çº¦ {total_tokens} tokensï¼Œè¶…è¿‡é™åˆ¶ ({max_token_limit} tokensï¼Œçº¦2/3æœ€å¤§çª—å£)\n"
                        f"ğŸ“‹ æ–‡ä»¶åˆ—è¡¨ ({len(file_read_info)} ä¸ªæ–‡ä»¶):\n   {file_list}\n"
                        f"ğŸ’¡ å»ºè®®ï¼š\n"
                        f"   1. åˆ†æ‰¹è¯»å–ï¼šå°†æ–‡ä»¶åˆ†æˆå¤šä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹ç´¯è®¡å†…å®¹ä¸è¶…è¿‡ {max_token_limit} tokens\n"
                        f"   2. å…ˆå®šä½ï¼šä½¿ç”¨æœç´¢æˆ–åˆ†æå·¥å…·å®šä½å…³é”®ä»£ç ä½ç½®ï¼Œå†è¯»å–å…·ä½“èŒƒå›´\n"
                        f"   3. ç¼©å°èŒƒå›´ï¼šä¸ºæ¯ä¸ªæ–‡ä»¶æŒ‡å®šæ›´ç²¾ç¡®çš„è¡Œå·èŒƒå›´"
                    ),
                }

            # ç¬¬äºŒéï¼šå®é™…è¯»å–æ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åˆ†ç»„ï¼Œåˆå¹¶åŒä¸€æ–‡ä»¶çš„å¤šä¸ªèŒƒå›´è¯·æ±‚ï¼Œé¿å…å—é‡å¤ï¼‰
            # æŒ‰æ–‡ä»¶è·¯å¾„åˆ†ç»„
            from collections import defaultdict
            file_requests = defaultdict(list)
            for file_info in args["files"]:
                if not isinstance(file_info, dict) or "path" not in file_info:
                    continue
                abs_path = os.path.abspath(file_info["path"].strip())
                file_requests[abs_path].append(file_info)
            
            # æŒ‰æ–‡ä»¶å¤„ç†ï¼Œåˆå¹¶åŒä¸€æ–‡ä»¶çš„å¤šä¸ªèŒƒå›´è¯·æ±‚
            for abs_path, requests in file_requests.items():
                if len(requests) == 1:
                    # å•ä¸ªèŒƒå›´è¯·æ±‚ï¼Œç›´æ¥å¤„ç†
                    file_info = requests[0]
                    result = self._handle_single_file(
                        file_info["path"].strip(),
                        file_info.get("start_line", 1),
                        file_info.get("end_line", -1),
                        agent,
                        file_info.get("raw_mode", False),
                    )
                    if result["success"]:
                        all_outputs.append(result["stdout"])
                        status_lines.append(f"âœ… {file_info['path']} æ–‡ä»¶è¯»å–æˆåŠŸ")
                    else:
                        all_outputs.append(f"âŒ {file_info['path']}: {result['stderr']}")
                        status_lines.append(f"âŒ {file_info['path']} æ–‡ä»¶è¯»å–å¤±è´¥")
                        overall_success = False
                else:
                    # å¤šä¸ªèŒƒå›´è¯·æ±‚ï¼Œåˆå¹¶å¤„ç†å¹¶å»é‡
                    merged_result = self._handle_merged_ranges(
                        abs_path, requests, agent
                    )
                    display_path = requests[0]["path"]
                    if merged_result["success"]:
                        all_outputs.append(merged_result["stdout"])
                        status_lines.append(f"âœ… {display_path} æ–‡ä»¶è¯»å–æˆåŠŸ (åˆå¹¶{len(requests)}ä¸ªèŒƒå›´è¯·æ±‚ï¼Œå·²å»é‡)")
                    else:
                        all_outputs.append(f"âŒ {display_path}: {merged_result['stderr']}")
                        status_lines.append(f"âŒ {display_path} æ–‡ä»¶è¯»å–å¤±è´¥")
                        overall_success = False

            stdout_text = "\n".join(all_outputs)
            # ä»…æ‰“å°æ¯ä¸ªæ–‡ä»¶çš„è¯»å–çŠ¶æ€ï¼Œä¸æ‰“å°å…·ä½“å†…å®¹
            try:
                if status_lines:
                    print("\n".join(status_lines), end="\n")
            except Exception:
                pass
            return {
                "success": overall_success,
                "stdout": stdout_text,
                "stderr": "",
            }

        except Exception as e:
            print(f"âŒ {str(e)}")
            return {"success": False, "stdout": "", "stderr": f"ä»£ç è¯»å–å¤±è´¥: {str(e)}"}


def main():
    """æµ‹è¯•ç»“æ„åŒ–è¯»å–åŠŸèƒ½"""
    import tempfile
    import os
    
    tool = ReadCodeTool()
    
    print("=" * 80)
    print("æµ‹è¯•ç»“æ„åŒ–è¯»å–åŠŸèƒ½")
    print("=" * 80)
    
    # æµ‹è¯•1: Cè¯­è¨€æ–‡ä»¶ï¼ˆtree-sitteræ”¯æŒï¼‰
    print("\nã€æµ‹è¯•1ã€‘Cè¯­è¨€æ–‡ä»¶ - è¯­æ³•å•å…ƒæå–")
    print("-" * 80)
    
    c_code = """#include <stdio.h>

void main() {
    printf("Hello, World!\\n");
}

int add(int a, int b) {
    return a + b;
}

int sub(int a, int b) {
    return a - b;
}

struct Point {
    int x;
    int y;
};
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.c', delete=False) as f:
        c_file = f.name
        f.write(c_code)
    
    try:
        result = tool.execute({
            "files": [{"path": c_file, "start_line": 1, "end_line": -1}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… Cè¯­è¨€æ–‡ä»¶è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹:")
            print(result["stdout"])
        else:
            print(f"âŒ Cè¯­è¨€æ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(c_file)
    
    # æµ‹è¯•2: Pythonæ–‡ä»¶ï¼ˆASTæ”¯æŒï¼‰
    print("\nã€æµ‹è¯•2ã€‘Pythonæ–‡ä»¶ - è¯­æ³•å•å…ƒæå–")
    print("-" * 80)
    
    python_code = """def main():
    print("Hello, World!")

def add(a, b):
    return a + b

def sub(a, b):
    return a - b

class Point:
    def __init__(self, x, y):
        self.x = x
        self.y = y
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        py_file = f.name
        f.write(python_code)
    
    try:
        result = tool.execute({
            "files": [{"path": py_file, "start_line": 1, "end_line": -1}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… Pythonæ–‡ä»¶è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹:")
            print(result["stdout"])
        else:
            print(f"âŒ Pythonæ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(py_file)
    
    # æµ‹è¯•3: ä¸æ”¯æŒçš„è¯­è¨€ - è¡Œå·åˆ†ç»„
    print("\nã€æµ‹è¯•3ã€‘ä¸æ”¯æŒçš„è¯­è¨€ - è¡Œå·åˆ†ç»„ï¼ˆ20è¡Œä¸€ç»„ï¼‰")
    print("-" * 80)
    
    text_content = "\n".join([f"è¿™æ˜¯ç¬¬ {i} è¡Œå†…å®¹" for i in range(1, 51)])
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        txt_file = f.name
        f.write(text_content)
    
    try:
        result = tool.execute({
            "files": [{"path": txt_file, "start_line": 1, "end_line": -1}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… æ–‡æœ¬æ–‡ä»¶è¯»å–æˆåŠŸï¼ˆä½¿ç”¨è¡Œå·åˆ†ç»„ï¼‰")
            print("\nè¾“å‡ºå†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰:")
            print(result["stdout"][:500] + "..." if len(result["stdout"]) > 500 else result["stdout"])
        else:
            print(f"âŒ æ–‡æœ¬æ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(txt_file)
    
    # æµ‹è¯•4: æŒ‡å®šè¡Œå·èŒƒå›´
    print("\nã€æµ‹è¯•4ã€‘æŒ‡å®šè¡Œå·èŒƒå›´è¯»å–")
    print("-" * 80)
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.c', delete=False) as f:
        c_file2 = f.name
        f.write(c_code)
    
    try:
        result = tool.execute({
            "files": [{"path": c_file2, "start_line": 1, "end_line": 10}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… æŒ‡å®šèŒƒå›´è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹:")
            print(result["stdout"])
        else:
            print(f"âŒ æŒ‡å®šèŒƒå›´è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(c_file2)
    
    # æµ‹è¯•5: è¾¹ç•Œæƒ…å†µ - è¿”å›è¾¹ç•Œä¸Šçš„è¯­æ³•å•å…ƒ
    print("\nã€æµ‹è¯•5ã€‘è¾¹ç•Œæƒ…å†µ - è¿”å›è¾¹ç•Œä¸Šçš„è¯­æ³•å•å…ƒ")
    print("-" * 80)
    
    boundary_test_code = """def func1():
    line1 = 1
    line2 = 2
    line3 = 3

def func2():
    line1 = 1
    line2 = 2

def func3():
    line1 = 1
    line2 = 2
    line3 = 3
    line4 = 4
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        boundary_file = f.name
        f.write(boundary_test_code)
    
    try:
        # è¯·æ±‚ç¬¬3-8è¡Œ
        # func1: 1-4è¡Œï¼ˆç»“æŸè¡Œ4åœ¨èŒƒå›´å†…ï¼Œåº”è¯¥è¿”å›å®Œæ•´func1ï¼‰
        # func2: 6-8è¡Œï¼ˆå¼€å§‹è¡Œ6åœ¨èŒƒå›´å†…ï¼Œåº”è¯¥è¿”å›å®Œæ•´func2ï¼‰
        # func3: 10-14è¡Œï¼ˆå®Œå…¨ä¸åœ¨èŒƒå›´å†…ï¼Œä¸åº”è¯¥è¿”å›ï¼‰
        result = tool.execute({
            "files": [{"path": boundary_file, "start_line": 3, "end_line": 8}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… è¾¹ç•Œæƒ…å†µæµ‹è¯•æˆåŠŸ")
            print("è¯·æ±‚èŒƒå›´: 3-8è¡Œ")
            print("é¢„æœŸç»“æœ:")
            print("  - func1 (1-4è¡Œ): ç»“æŸè¡Œ4åœ¨èŒƒå›´å†…ï¼Œåº”è¿”å›å®Œæ•´func1")
            print("  - func2 (6-8è¡Œ): å¼€å§‹è¡Œ6åœ¨èŒƒå›´å†…ï¼Œåº”è¿”å›å®Œæ•´func2")
            print("  - func3 (10-14è¡Œ): å®Œå…¨ä¸åœ¨èŒƒå›´å†…ï¼Œä¸åº”è¿”å›")
            print("\nå®é™…è¾“å‡º:")
            print(result["stdout"])
        else:
            print(f"âŒ è¾¹ç•Œæƒ…å†µæµ‹è¯•å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(boundary_file)
    
    # æµ‹è¯•6: å¤šä¸ªæ–‡ä»¶
    print("\nã€æµ‹è¯•6ã€‘å¤šä¸ªæ–‡ä»¶è¯»å–")
    print("-" * 80)
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.c', delete=False) as f1, \
         tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f2:
        c_file3 = f1.name
        py_file2 = f2.name
        f1.write(c_code)
        f2.write(python_code)
    
    try:
        result = tool.execute({
            "files": [
                {"path": c_file3, "start_line": 1, "end_line": -1},
                {"path": py_file2, "start_line": 1, "end_line": -1}
            ],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… å¤šæ–‡ä»¶è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹ï¼ˆå‰800å­—ç¬¦ï¼‰:")
            print(result["stdout"][:800] + "..." if len(result["stdout"]) > 800 else result["stdout"])
        else:
            print(f"âŒ å¤šæ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(c_file3)
        os.unlink(py_file2)
    
    # æµ‹è¯•7: åµŒå¥—ä½œç”¨åŸŸçš„è¾¹ç•Œæƒ…å†µ
    print("\nã€æµ‹è¯•7ã€‘åµŒå¥—ä½œç”¨åŸŸçš„è¾¹ç•Œæƒ…å†µ")
    print("-" * 80)
    
    nested_code = """class Outer:
    def method1(self):
        line1 = 1
        line2 = 2
    
    def method2(self):
        line1 = 1
        line2 = 2
        line3 = 3

def standalone_func():
    line1 = 1
    line2 = 2
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        nested_file = f.name
        f.write(nested_code)
    
    try:
        # è¯·æ±‚ç¬¬4-7è¡Œ
        # Outer.method1: 2-4è¡Œï¼ˆç»“æŸè¡Œ4åœ¨èŒƒå›´å†…ï¼Œåº”è¯¥è¿”å›å®Œæ•´method1ï¼‰
        # Outer.method2: 6-9è¡Œï¼ˆå¼€å§‹è¡Œ6åœ¨èŒƒå›´å†…ï¼Œåº”è¯¥è¿”å›å®Œæ•´method2ï¼‰
        # Outerç±»: 1-9è¡Œï¼ˆåŒ…å«method1å’Œmethod2ï¼Œåº”è¯¥è¿”å›ï¼‰
        # standalone_func: 11-13è¡Œï¼ˆå®Œå…¨ä¸åœ¨èŒƒå›´å†…ï¼Œä¸åº”è¿”å›ï¼‰
        result = tool.execute({
            "files": [{"path": nested_file, "start_line": 4, "end_line": 7}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… åµŒå¥—ä½œç”¨åŸŸè¾¹ç•Œæµ‹è¯•æˆåŠŸ")
            print("è¯·æ±‚èŒƒå›´: 4-7è¡Œ")
            print("é¢„æœŸç»“æœ:")
            print("  - Outerç±» (1-9è¡Œ): åŒ…å«method1å’Œmethod2ï¼Œåº”è¿”å›")
            print("  - Outer.method1 (2-4è¡Œ): ç»“æŸè¡Œ4åœ¨èŒƒå›´å†…ï¼Œåº”è¿”å›å®Œæ•´method1")
            print("  - Outer.method2 (6-9è¡Œ): å¼€å§‹è¡Œ6åœ¨èŒƒå›´å†…ï¼Œåº”è¿”å›å®Œæ•´method2")
            print("\nå®é™…è¾“å‡º:")
            print(result["stdout"])
        else:
            print(f"âŒ åµŒå¥—ä½œç”¨åŸŸè¾¹ç•Œæµ‹è¯•å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(nested_file)
    
    # æµ‹è¯•8: Javaæ–‡ä»¶ï¼ˆtree-sitteræ”¯æŒï¼‰
    print("\nã€æµ‹è¯•8ã€‘Javaæ–‡ä»¶ - è¯­æ³•å•å…ƒæå–")
    print("-" * 80)
    
    java_code = """public class Main {
    public static void main(String[] args) {
        System.out.println("Hello, World!");
    }
    
    public int add(int a, int b) {
        return a + b;
    }
    
    private int subtract(int a, int b) {
        return a - b;
    }
}

class Point {
    private int x;
    private int y;
    
    public Point(int x, int y) {
        this.x = x;
        this.y = y;
    }
}
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.java', delete=False) as f:
        java_file = f.name
        f.write(java_code)
    
    try:
        result = tool.execute({
            "files": [{"path": java_file, "start_line": 1, "end_line": -1}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… Javaæ–‡ä»¶è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹:")
            print(result["stdout"])
        else:
            print(f"âŒ Javaæ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(java_file)
    
    # æµ‹è¯•9: Rustæ–‡ä»¶ï¼ˆtree-sitteræ”¯æŒï¼‰
    print("\nã€æµ‹è¯•9ã€‘Rustæ–‡ä»¶ - è¯­æ³•å•å…ƒæå–")
    print("-" * 80)
    
    rust_code = """fn main() {
    println!("Hello, World!");
}

fn add(a: i32, b: i32) -> i32 {
    a + b
}

fn subtract(a: i32, b: i32) -> i32 {
    a - b
}

struct Point {
    x: i32,
    y: i32,
}

impl Point {
    fn new(x: i32, y: i32) -> Point {
        Point { x, y }
    }
}

enum Color {
    Red,
    Green,
    Blue,
}
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.rs', delete=False) as f:
        rust_file = f.name
        f.write(rust_code)
    
    try:
        result = tool.execute({
            "files": [{"path": rust_file, "start_line": 1, "end_line": -1}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… Rustæ–‡ä»¶è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹:")
            print(result["stdout"])
        else:
            print(f"âŒ Rustæ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(rust_file)
    
    # æµ‹è¯•10: Goæ–‡ä»¶ï¼ˆtree-sitteræ”¯æŒï¼‰
    print("\nã€æµ‹è¯•10ã€‘Goæ–‡ä»¶ - è¯­æ³•å•å…ƒæå–")
    print("-" * 80)
    
    go_code = """package main

import "fmt"

func main() {
    fmt.Println("Hello, World!")
}

func add(a int, b int) int {
    return a + b
}

func subtract(a int, b int) int {
    return a - b
}

type Point struct {
    x int
    y int
}

func (p *Point) New(x int, y int) {
    p.x = x
    p.y = y
}

type Color int

const (
    Red Color = iota
    Green
    Blue
)

type Shape interface {
    Area() float64
    Perimeter() float64
}

type Drawable interface {
    Draw()
}
"""
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.go', delete=False) as f:
        go_file = f.name
        f.write(go_code)
    
    try:
        result = tool.execute({
            "files": [{"path": go_file, "start_line": 1, "end_line": -1}],
            "agent": None
        })
        
        if result["success"]:
            print("âœ… Goæ–‡ä»¶è¯»å–æˆåŠŸ")
            print("\nè¾“å‡ºå†…å®¹:")
            print(result["stdout"])
        else:
            print(f"âŒ Goæ–‡ä»¶è¯»å–å¤±è´¥: {result['stderr']}")
    finally:
        os.unlink(go_file)
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 80)


if __name__ == "__main__":
    main()
