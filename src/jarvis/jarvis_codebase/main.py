import hashlib
import os
import numpy as np
import faiss
from typing import List, Tuple, Optional, Dict

from jarvis.jarvis_platform.registry import PlatformRegistry
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
import argparse
import pickle
import lzma  # æ·»åŠ  lzma å¯¼å…¥
from tqdm import tqdm
import re

from jarvis.jarvis_utils.config import get_max_token_count, get_thread_count
from jarvis.jarvis_utils.embedding import get_embedding, load_embedding_model, get_context_token_count
from jarvis.jarvis_utils.git_utils import find_git_root
from jarvis.jarvis_utils.output import OutputType, PrettyOutput
from jarvis.jarvis_utils.utils import  get_file_md5, init_env, user_confirm

class CodeBase:
    def __init__(self, root_dir: str):
        init_env()
        self.root_dir = root_dir
        os.chdir(self.root_dir)
        self.thread_count = get_thread_count()
        self.max_token_count = get_max_token_count()
        self.index = None
            
        # åˆå§‹åŒ–æ•°æ®ç›®å½•
        self.data_dir = os.path.join(self.root_dir, ".jarvis/codebase")
        self.cache_dir = os.path.join(self.data_dir, "cache")
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)
            
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        try:
            self.embedding_model = load_embedding_model()
            test_text = """This is a test text"""
            self.embedding_model.encode([test_text], 
                                     convert_to_tensor=True,
                                     normalize_embeddings=True)
            PrettyOutput.print("æ¨¡å‹åŠ è½½æˆåŠŸ", output_type=OutputType.SUCCESS)
        except Exception as e:
            PrettyOutput.print(f"åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}", output_type=OutputType.ERROR)
            raise
            
        self.vector_dim = self.embedding_model.get_sentence_embedding_dimension()
        self.git_file_list = self.get_git_file_list()
        self.platform_registry = PlatformRegistry.get_global_platform_registry()
        
        # åˆå§‹åŒ–ç¼“å­˜å’Œç´¢å¼•
        self.vector_cache = {}
        self.file_paths = []
        
        # åŠ è½½æ‰€æœ‰ç¼“å­˜æ–‡ä»¶
        self._load_all_cache()

    def get_git_file_list(self):
        """Get the list of files in the git repository, excluding the .jarvis-codebase directory"""
        files = os.popen("git ls-files").read().splitlines()
        # Filter out files in the .jarvis-codebase directory
        return [f for f in files if not f.startswith(".jarvis")]

    def is_text_file(self, file_path: str):
        try:
            open(file_path, "r", encoding="utf-8").read()
            return True
        except Exception:
            return False

    def make_description(self, file_path: str, content: str) -> str:
        model = PlatformRegistry.get_global_platform_registry().get_cheap_platform()
        if self.thread_count > 1:
            model.set_suppress_output(True)
        else:
            PrettyOutput.print(f"ä¸º {file_path} ç”Ÿæˆæè¿° ...", output_type=OutputType.PROGRESS)
        prompt = f"""è¯·åˆ†æä»¥ä¸‹ä»£ç æ–‡ä»¶å¹¶ç”Ÿæˆè¯¦ç»†æè¿°ã€‚æè¿°åº”åŒ…å«ï¼š
1. æ–‡ä»¶æ•´ä½“åŠŸèƒ½æè¿°
2. å¯¹æ¯ä¸ªå…¨å±€å˜é‡ã€å‡½æ•°ã€ç±»å‹å®šä¹‰ã€ç±»ã€æ–¹æ³•å’Œå…¶ä»–ä»£ç å…ƒç´ çš„æè¿°

è¯·ä½¿ç”¨ç®€æ´ä¸“ä¸šçš„è¯­è¨€ï¼Œå¼ºè°ƒæŠ€æœ¯åŠŸèƒ½ï¼Œä»¥ä¾¿äºåç»­ä»£ç æ£€ç´¢ã€‚
æ–‡ä»¶è·¯å¾„: {file_path}
ä»£ç å†…å®¹:
{content}
"""
        response = model.chat_until_success(prompt)
        return response

    def export(self):
        """Export the current index data to standard output"""
        for file_path, data in self.vector_cache.items():
            print(f"## {file_path}")
            print(f"- path: {file_path}")
            print(f"- description: {data['description']}")
    
    def _get_cache_path(self, file_path: str) -> str:
        """Get cache file path for a source file
        
        Args:
            file_path: Source file path
            
        Returns:
            str: Cache file path
        """
        # å¤„ç†æ–‡ä»¶è·¯å¾„ï¼š
        # 1. ç§»é™¤å¼€å¤´çš„ ./ æˆ– /
        # 2. å°† / æ›¿æ¢ä¸º --
        # 3. æ·»åŠ  .cache åç¼€
        clean_path = file_path.lstrip('./').lstrip('/')
        cache_name = clean_path.replace('/', '--') + '.cache'
        return os.path.join(self.cache_dir, cache_name)

    def _load_all_cache(self):
        """Load all cache files"""
        try:
            # æ¸…ç©ºç°æœ‰ç¼“å­˜å’Œæ–‡ä»¶è·¯å¾„
            self.vector_cache = {}
            self.file_paths = []
            vectors = []
            
            for cache_file in os.listdir(self.cache_dir):
                if not cache_file.endswith('.cache'):
                    continue
                    
                cache_path = os.path.join(self.cache_dir, cache_file)
                try:
                    with lzma.open(cache_path, 'rb') as f:
                        cache_data = pickle.load(f)
                        file_path = cache_data["path"]
                        self.vector_cache[file_path] = cache_data
                        self.file_paths.append(file_path)
                        vectors.append(cache_data["vector"])
                except Exception as e:
                    PrettyOutput.print(f"åŠ è½½ç¼“å­˜æ–‡ä»¶ {cache_file} å¤±è´¥: {str(e)}", 
                                     output_type=OutputType.WARNING)
                    continue
            
            if vectors:
                # é‡å»ºç´¢å¼•
                vectors_array = np.vstack(vectors)
                hnsw_index = faiss.IndexHNSWFlat(self.vector_dim, 16)
                hnsw_index.hnsw.efConstruction = 40
                hnsw_index.hnsw.efSearch = 16
                self.index = faiss.IndexIDMap(hnsw_index)
                self.index.add_with_ids(vectors_array, np.array(range(len(vectors)))) # type: ignore
                
                PrettyOutput.print(f"åŠ è½½ {len(self.vector_cache)} ä¸ªå‘é‡ç¼“å­˜å¹¶é‡å»ºç´¢å¼•", 
                                 output_type=OutputType.INFO)
            else:
                self.index = None
                PrettyOutput.print("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ç¼“å­˜æ–‡ä»¶", output_type=OutputType.WARNING)
                
        except Exception as e:
            PrettyOutput.print(f"åŠ è½½ç¼“å­˜ç›®å½•å¤±è´¥: {str(e)}", 
                             output_type=OutputType.WARNING)
            self.vector_cache = {}
            self.file_paths = []
            self.index = None

    def cache_vector(self, file_path: str, vector: np.ndarray, description: str):
        """Cache the vector representation of a file"""
        try:
            with open(file_path, "rb") as f:
                file_md5 = hashlib.md5(f.read()).hexdigest()
        except Exception as e:
            PrettyOutput.print(f"è®¡ç®— {file_path} çš„MD5å¤±è´¥: {str(e)}", 
                              output_type=OutputType.ERROR)
            file_md5 = ""
        
        # å‡†å¤‡ç¼“å­˜æ•°æ®
        cache_data = {
            "path": file_path,  # ä¿å­˜æ–‡ä»¶è·¯å¾„
            "md5": file_md5,    # ä¿å­˜æ–‡ä»¶MD5
            "description": description,  # ä¿å­˜æ–‡ä»¶æè¿°
            "vector": vector    # ä¿å­˜å‘é‡
        }
        
        # æ›´æ–°å†…å­˜ç¼“å­˜
        self.vector_cache[file_path] = cache_data
        
        # ä¿å­˜åˆ°å•ç‹¬çš„ç¼“å­˜æ–‡ä»¶
        cache_path = self._get_cache_path(file_path)
        try:
            with lzma.open(cache_path, 'wb') as f:
                pickle.dump(cache_data, f, protocol=pickle.HIGHEST_PROTOCOL)
        except Exception as e:
            PrettyOutput.print(f"ä¿å­˜ {file_path} çš„ç¼“å­˜å¤±è´¥: {str(e)}", 
                             output_type=OutputType.ERROR)

    def get_cached_vector(self, file_path: str, description: str) -> Optional[np.ndarray]:
        """Get the vector representation of a file from the cache"""
        if file_path not in self.vector_cache:
            return None
        
        # Check if the file has been modified
        try:
            with open(file_path, "rb") as f:
                current_md5 = hashlib.md5(f.read()).hexdigest()
        except Exception as e:
            PrettyOutput.print(f"è®¡ç®— {file_path} çš„MD5å¤±è´¥: {str(e)}", 
                              output_type=OutputType.ERROR)
            return None
        
        cached_data = self.vector_cache[file_path]
        if cached_data["md5"] != current_md5:
            return None
        
        # Check if the description has changed
        if cached_data["description"] != description:
            return None
        
        return cached_data["vector"]

    def vectorize_file(self, file_path: str, description: str) -> np.ndarray:
        """Vectorize the file content and description"""
        try:
            # Try to get the vector from the cache first
            cached_vector = self.get_cached_vector(file_path, description)
            if cached_vector is not None:
                return cached_vector
                
            # Read the file content and combine information
            content = open(file_path, "r", encoding="utf-8").read()[:self.max_token_count]  # Limit the file content length
            
            # Combine file information, including file content
            combined_text = f"""
File path: {file_path}
Description: {description}
Content: {content}
"""
            vector = get_embedding(self.embedding_model, combined_text)
            
            # Save to cache
            self.cache_vector(file_path, vector, description)
            return vector
        except Exception as e:
            PrettyOutput.print(f"å‘é‡åŒ– {file_path} å¤±è´¥: {str(e)}", 
                             output_type=OutputType.ERROR)
            return np.zeros(self.vector_dim, dtype=np.float32) # type: ignore

    def clean_cache(self) -> bool:
        """Clean expired cache records"""
        try:
            files_to_delete = []
            for file_path in list(self.vector_cache.keys()):
                if not os.path.exists(file_path):
                    files_to_delete.append(file_path)
                    cache_path = self._get_cache_path(file_path)
                    try:
                        os.remove(cache_path)
                    except Exception:
                        pass
                        
            for file_path in files_to_delete:
                del self.vector_cache[file_path]
                if file_path in self.file_paths:
                    self.file_paths.remove(file_path)
                    
            return bool(files_to_delete)
            
        except Exception as e:
            PrettyOutput.print(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {str(e)}", 
                             output_type=OutputType.ERROR)
            return False

    def process_file(self, file_path: str):
        """Process a single file"""
        try:
            # Skip non-existent files
            if not os.path.exists(file_path):
                return None
                
            if not self.is_text_file(file_path):
                return None
            
            md5 = get_file_md5(file_path)

            content = open(file_path, "r", encoding="utf-8").read()
            
            # Check if the file has already been processed and the content has not changed
            if file_path in self.vector_cache:
                if self.vector_cache[file_path].get("md5") == md5:
                    return None
                    
            description = self.make_description(file_path, content)  # Pass the truncated content
            vector = self.vectorize_file(file_path, description)
            
            # Save to cache, using the actual file path as the key
            self.vector_cache[file_path] = {
                "vector": vector,
                "description": description,
                "md5": md5
            }
            
            return file_path
            
        except Exception as e:
            PrettyOutput.print(f"å¤„ç† {file_path} å¤±è´¥: {str(e)}", 
                             output_type=OutputType.ERROR)
            return None

    def build_index(self):
        """Build a faiss index from the vector cache"""
        try:
            if not self.vector_cache:
                self.index = None
                return

            # Create the underlying HNSW index
            hnsw_index = faiss.IndexHNSWFlat(self.vector_dim, 16)
            hnsw_index.hnsw.efConstruction = 40
            hnsw_index.hnsw.efSearch = 16
            
            # Wrap the HNSW index with IndexIDMap
            self.index = faiss.IndexIDMap(hnsw_index)
            
            vectors = []
            ids = []
            self.file_paths = []  # Reset the file path list
            
            for i, ( file_path, data) in enumerate(self.vector_cache.items()):
                if "vector" not in data:
                    PrettyOutput.print(f"æ— æ•ˆçš„ç¼“å­˜æ•°æ® {file_path}: ç¼ºå°‘å‘é‡", 
                                     output_type=OutputType.WARNING)
                    continue
                    
                vector = data["vector"]
                if not isinstance(vector, np.ndarray):
                    PrettyOutput.print(f"æ— æ•ˆçš„å‘é‡ç±»å‹ {file_path}: {type(vector)}", 
                                     output_type=OutputType.WARNING)
                    continue
                    
                vectors.append(vector.reshape(1, -1))
                ids.append(i)
                self.file_paths.append(file_path)
                
            if vectors:
                vectors = np.vstack(vectors)
                if len(vectors) != len(ids):
                    PrettyOutput.print(f"å‘é‡æ•°é‡ä¸åŒ¹é…: {len(vectors)} ä¸ªå‘é‡ vs {len(ids)} ä¸ªID", 
                                     output_type=OutputType.WARNING)
                    self.index = None
                    return
                    
                try:
                    self.index.add_with_ids(vectors, np.array(ids)) # type: ignore
                    PrettyOutput.print(f"æˆåŠŸæ„å»ºåŒ…å« {len(vectors)} ä¸ªå‘é‡çš„ç´¢å¼•", 
                                     output_type=OutputType.SUCCESS)
                except Exception as e:
                    PrettyOutput.print(f"æ·»åŠ å‘é‡åˆ°ç´¢å¼•å¤±è´¥: {str(e)}", 
                                     output_type=OutputType.ERROR)
                    self.index = None
            else:
                PrettyOutput.print("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å‘é‡, ç´¢å¼•æœªæ„å»º", 
                                 output_type=OutputType.WARNING)
                self.index = None
                
        except Exception as e:
            PrettyOutput.print(f"æ„å»ºç´¢å¼•å¤±è´¥: {str(e)}", 
                             output_type=OutputType.ERROR)
            self.index = None

    def gen_vector_db_from_cache(self):
        """Generate a vector database from the cache"""
        self.build_index()
        self._load_all_cache()


    def generate_codebase(self, force: bool = False):
        """Generate the codebase index
        Args:
            force: Whether to force rebuild the index, without asking the user
        """
        try:
            # Clean up cache for non-existent files
            files_to_delete = []
            for cached_file in list(self.vector_cache.keys()):
                if not os.path.exists(cached_file) or not self.is_text_file(cached_file):
                    files_to_delete.append(cached_file)
                    cache_path = self._get_cache_path(cached_file)
                    try:
                        os.remove(cache_path)
                    except Exception as e:
                        PrettyOutput.print(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶ {cached_file} å¤±è´¥: {str(e)}", 
                                         output_type=OutputType.WARNING)
            
            if files_to_delete:
                for file_path in files_to_delete:
                    del self.vector_cache[file_path]
                PrettyOutput.print(f"æ¸…ç†äº† {len(files_to_delete)} ä¸ªä¸å­˜åœ¨çš„æ–‡ä»¶çš„ç¼“å­˜", 
                                 output_type=OutputType.INFO)
            
            # Update the git file list
            self.git_file_list = self.get_git_file_list()
            
            # Check file changes
            PrettyOutput.print("æ£€æŸ¥æ–‡ä»¶å˜åŒ–...", output_type=OutputType.INFO)
            changes_detected = False
            new_files = []
            modified_files = []
            deleted_files = []
            
            # Check deleted files
            files_to_delete = []
            for file_path in list(self.vector_cache.keys()):
                if file_path not in self.git_file_list:
                    deleted_files.append(file_path)
                    files_to_delete.append(file_path)
                    changes_detected = True
            # Check new and modified files
            from rich.progress import Progress
            with Progress() as progress:
                task = progress.add_task("Check file status", total=len(self.git_file_list))
                for file_path in self.git_file_list:
                    if not os.path.exists(file_path) or not self.is_text_file(file_path):
                        progress.advance(task)
                        continue
                    
                    try:
                        current_md5 = get_file_md5(file_path)
                        
                        if file_path not in self.vector_cache:
                            new_files.append(file_path)
                            changes_detected = True
                        elif self.vector_cache[file_path].get("md5") != current_md5:
                            modified_files.append(file_path)
                            changes_detected = True
                    except Exception as e:
                        PrettyOutput.print(f"æ£€æŸ¥ {file_path} å¤±è´¥: {str(e)}", 
                                         output_type=OutputType.ERROR)
                    progress.advance(task)
            
            # If changes are detected, display changes and ask the user
            if changes_detected:
                output_lines = ["æ£€æµ‹åˆ°ä»¥ä¸‹å˜åŒ–:"]
                if new_files:
                    output_lines.append("æ–°æ–‡ä»¶:")
                    output_lines.extend(f"  {f}" for f in new_files)
                if modified_files:
                    output_lines.append("ä¿®æ”¹çš„æ–‡ä»¶:")
                    output_lines.extend(f"  {f}" for f in modified_files)
                if deleted_files:
                    output_lines.append("åˆ é™¤çš„æ–‡ä»¶:")
                    output_lines.extend(f"  {f}" for f in deleted_files)
                
                PrettyOutput.print("\n".join(output_lines), output_type=OutputType.INFO)

                # If force is True, continue directly
                if not force:
                    if not user_confirm("é‡å»ºç´¢å¼•?", False):
                        PrettyOutput.print("å–æ¶ˆé‡å»ºç´¢å¼•", output_type=OutputType.INFO)
                        return
                
                # Clean deleted files
                for file_path in files_to_delete:
                    del self.vector_cache[file_path]
                if files_to_delete:
                    PrettyOutput.print(f"æ¸…ç†äº† {len(files_to_delete)} ä¸ªæ–‡ä»¶çš„ç¼“å­˜", 
                                     output_type=OutputType.INFO)
                
                # Process new and modified files
                files_to_process = new_files + modified_files
                processed_files = []
                
                with tqdm(total=len(files_to_process), desc="Processing files") as pbar:
                    # Use a thread pool to process files
                    with ThreadPoolExecutor(max_workers=self.thread_count) as executor:
                        # Submit all tasks
                        future_to_file = {
                            executor.submit(self.process_file, file): file 
                            for file in files_to_process
                        }
                        
                        # Process completed tasks
                        for future in concurrent.futures.as_completed(future_to_file):
                            file = future_to_file[future]
                            try:
                                result = future.result()
                                if result:
                                    processed_files.append(result)
                            except Exception as e:
                                PrettyOutput.print(f"Failed to process file {file}: {str(e)}", 
                                                output_type=OutputType.ERROR)
                            pbar.update(1)

                if processed_files:
                    PrettyOutput.print("é‡å»ºå‘é‡æ•°æ®åº“...", output_type=OutputType.INFO)
                    self.gen_vector_db_from_cache()
                    PrettyOutput.print(f"æˆåŠŸç”Ÿæˆäº† {len(processed_files)} ä¸ªæ–‡ä»¶çš„ç´¢å¼•", 
                                    output_type=OutputType.SUCCESS)
            else:
                PrettyOutput.print("æ²¡æœ‰æ£€æµ‹åˆ°æ–‡ä»¶å˜åŒ–, ä¸éœ€è¦é‡å»ºç´¢å¼•", output_type=OutputType.INFO)
                
        except Exception as e:
            # Try to save the cache when an exception occurs
            try:
                self._load_all_cache()
            except Exception as save_error:
                PrettyOutput.print(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {str(save_error)}", 
                                output_type=OutputType.ERROR)
            raise e  # Re-raise the original exception


    def _text_search_score(self, content: str, keywords: List[str]) -> float:
        """Calculate the matching score between the text content and the keywords
        
        Args:
            content: Text content
            keywords: List of keywords
            
        Returns:
            float: Matching score (0-1)
        """
        if not keywords:
            return 0.0
            
        content = content.lower()
        matched_keywords = set()
        
        for keyword in keywords:
            keyword = keyword.lower()
            if keyword in content:
                matched_keywords.add(keyword)
                
        # Calculate the matching score
        score = len(matched_keywords) / len(keywords)
        return score

    def pick_results(self, query: List[str], initial_results: List[str]) -> List[Dict[str,str]]:
        """Use a large model to pick the search results
        
        Args:
            query: Search query
            initial_results: Initial results list of file paths
            
        Returns:
            List[str]: The picked results list, each item is a file path
        """
        if not initial_results:
            return []
            
        try:
            PrettyOutput.print(f"Picking results ...", output_type=OutputType.INFO)
            
            # Maximum content length per batch
            max_batch_length = self.max_token_count - 1000  # Reserve space for prompt
            max_file_length = max_batch_length // 3  # Limit individual file size
            
            # Process files in batches
            all_selected_files = []
            current_batch = []
            current_token_count = 0
            
            for path in initial_results:
                try:
                    content = open(path, "r", encoding="utf-8").read()
                    # Truncate large files
                    if get_context_token_count(content) > max_file_length:
                        PrettyOutput.print(f"Truncating large file: {path}", OutputType.WARNING)
                        content = content[:max_file_length] + "\n... (content truncated)"
                    
                    file_info = f"File: {path}\nContent: {content}\n\n"
                    tokens_count = get_context_token_count(file_info)
                    
                    # If adding this file would exceed batch limit
                    if current_token_count + tokens_count > max_batch_length:
                        # Process current batch
                        if current_batch:
                            selected = self._process_batch('\n'.join(query), current_batch)
                            all_selected_files.extend(selected)
                        # Start new batch
                        current_batch = [file_info]
                        current_token_count = tokens_count
                    else:
                        current_batch.append(file_info)
                        current_token_count += tokens_count
                        
                except Exception as e:
                    PrettyOutput.print(f"è¯»å– {path} å¤±è´¥: {str(e)}", OutputType.ERROR)
                    continue
            
            # Process final batch
            if current_batch:
                selected = self._process_batch('\n'.join(query), current_batch)
                all_selected_files.extend(selected)
            
            # Convert set to list and maintain original order
            return all_selected_files

        except Exception as e:
            PrettyOutput.print(f"é€‰æ‹©å¤±è´¥: {str(e)}", OutputType.ERROR)
            return [{"file": f, "reason": "" } for f in initial_results]
            
    def _process_batch(self, query: str, files_info: List[str]) -> List[Dict[str, str]]:
        """Process a batch of files"""
        prompt = f"""ä½œä¸ºä¸€åä»£ç åˆ†æä¸“å®¶ï¼Œè¯·ä½¿ç”¨é“¾å¼æ€ç»´æ¨ç†å¸®åŠ©è¯†åˆ«ä¸ç»™å®šæŸ¥è¯¢æœ€ç›¸å…³çš„æ–‡ä»¶ã€‚

æŸ¥è¯¢: {query}

å¯ç”¨æ–‡ä»¶:
{''.join(files_info)}

è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ€è€ƒï¼š
1. é¦–å…ˆï¼Œåˆ†ææŸ¥è¯¢ä»¥è¯†åˆ«å…³é”®éœ€æ±‚å’ŒæŠ€æœ¯æ¦‚å¿µ
2. å¯¹äºæ¯ä¸ªæ–‡ä»¶ï¼š
   - æ£€æŸ¥å…¶è·¯å¾„å’Œå†…å®¹
   - è¯„ä¼°å…¶ä¸æŸ¥è¯¢éœ€æ±‚çš„å…³ç³»
   - è€ƒè™‘ç›´æ¥å’Œé—´æ¥å…³ç³»
   - è¯„ä¼°å…¶ç›¸å…³æ€§ï¼ˆé«˜/ä¸­/ä½ï¼‰
3. ä»…é€‰æ‹©ä¸æŸ¥è¯¢æ˜ç¡®ç›¸å…³çš„æ–‡ä»¶
4. æŒ‰ç›¸å…³æ€§æ’åºï¼Œæœ€ç›¸å…³çš„æ–‡ä»¶åœ¨å‰

è¯·ä»¥YAMLæ ¼å¼è¾“å‡ºæ‚¨çš„é€‰æ‹©ï¼š
<FILES>
- file: path/to/most/relevant.py
  reason: xxxxxxxxxx
- path/to/next/relevant.py
  reason: yyyyyyyyyy
</FILES>

é‡è¦æç¤ºï¼š
- ä»…åŒ…å«çœŸæ­£ç›¸å…³çš„æ–‡ä»¶
- æ’é™¤è¿æ¥ä¸æ˜ç¡®æˆ–è¾ƒå¼±çš„æ–‡ä»¶
- é‡ç‚¹å…³æ³¨å®ç°æ–‡ä»¶è€Œéæµ‹è¯•æ–‡ä»¶
- åŒæ—¶è€ƒè™‘æ–‡ä»¶è·¯å¾„å’Œå†…å®¹
- ä»…è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡æœ¬
"""

        # Use a large model to evaluate
        model = PlatformRegistry.get_global_platform_registry().get_normal_platform()
        model.set_suppress_output(True)
        response = model.chat_until_success(prompt)

        # Parse the response
        import yaml
        files_match = re.search(r'<FILES>\n(.*?)</FILES>', response, re.DOTALL)
        if not files_match:
            return []

        try:
            selected_files = yaml.safe_load(files_match.group(1))
            return selected_files if selected_files else []
        except Exception as e:
            PrettyOutput.print(f"è§£æå“åº”å¤±è´¥: {str(e)}", OutputType.ERROR)
            return []

    def _generate_query_variants(self, query: str) -> List[str]:
        """Generate different expressions of the query optimized for vector search
        
        Args:
            query: Original query
            
        Returns:
            List[str]: The query variants list
        """
        model = PlatformRegistry.get_global_platform_registry().get_normal_platform()
        model.set_suppress_output(True)
        prompt = f"""è¯·åŸºäºä»¥ä¸‹æŸ¥è¯¢ç”Ÿæˆ10ä¸ªé’ˆå¯¹å‘é‡æœç´¢ä¼˜åŒ–çš„ä¸åŒè¡¨è¾¾ã€‚æ¯ä¸ªè¡¨è¾¾åº”æ»¡è¶³ï¼š
1. èšç„¦å…³é”®æŠ€æœ¯æ¦‚å¿µå’Œæœ¯è¯­
2. ä½¿ç”¨æ¸…æ™°æ˜ç¡®çš„è¯­è¨€
3. åŒ…å«é‡è¦çš„ä¸Šä¸‹æ–‡æœ¯è¯­
4. é¿å…ä½¿ç”¨é€šç”¨æˆ–æ¨¡ç³Šçš„è¯è¯­
5. ä¿æŒä¸åŸå§‹æŸ¥è¯¢çš„è¯­ä¹‰ç›¸ä¼¼æ€§
6. é€‚åˆåŸºäºåµŒå…¥çš„æœç´¢

åŸå§‹æŸ¥è¯¢: 
{query}

ç¤ºä¾‹è½¬æ¢ï¼š
æŸ¥è¯¢: "å¦‚ä½•å¤„ç†ç”¨æˆ·ç™»å½•ï¼Ÿ"
è¾“å‡ºæ ¼å¼:
<QUESTION>
- ç”¨æˆ·è®¤è¯çš„å®ç°ä¸æµç¨‹
- ç™»å½•ç³»ç»Ÿæ¶æ„ä¸ç»„ä»¶
- å‡­è¯éªŒè¯ä¸ä¼šè¯ç®¡ç†
- ...
</QUESTION>

è¯·ä»¥æŒ‡å®šæ ¼å¼æä¾›10ä¸ªæœç´¢ä¼˜åŒ–çš„è¡¨è¾¾ã€‚
"""
        response = model.chat_until_success(prompt)
        
        # Parse the response using YAML format
        import yaml
        variants = []
        question_match = re.search(r'<QUESTION>\n(.*?)</QUESTION>', response, re.DOTALL)
        if question_match:
            try:
                variants = yaml.safe_load(question_match.group(1))
                if not isinstance(variants, list):
                    variants = [str(variants)]
            except Exception as e:
                PrettyOutput.print(f"è§£æå˜ä½“å¤±è´¥: {str(e)}", OutputType.ERROR)
        
        # Add original query
        variants.append(query)
        return variants if variants else [query]

    def _vector_search(self, query_variants: List[str], top_k: int) -> Dict[str, Tuple[str, float, str]]:
        """Use vector search to find related files
        
        Args:
            query_variants: The query variants list
            top_k: The number of results to return
            
        Returns:
            Dict[str, Tuple[str, float, str]]: The mapping from file path to (file path, score, description)
        """
        results = {}
        for query in query_variants:
            query_vector = get_embedding(self.embedding_model, query)
            query_vector = query_vector.reshape(1, -1)
            
            distances, indices = self.index.search(query_vector, top_k) # type: ignore
            
            for i, distance in zip(indices[0], distances[0]):
                if i == -1:
                    continue
                    
                similarity = 1.0 / (1.0 + float(distance))
                file_path = self.file_paths[i]
                # Use the highest similarity score
                if file_path not in results:
                    if similarity > 0.5:
                        data = self.vector_cache[file_path]
                        results[file_path] = (file_path, similarity, data["description"])
        
        return results


    def search_similar(self, query: str, top_k: int = 30) -> List[Dict[str, str]]:
        """Search related files with optimized retrieval"""
        try:
            self.generate_codebase()
            if self.index is None:
                return []
                
            # Generate query variants for better coverage
            query_variants = self._generate_query_variants(query)
            
            # Collect results from all variants
            all_results = []
            seen_files = set()
            
            for variant in query_variants:
                # Get vector for each variant
                query_vector = get_embedding(self.embedding_model, variant)
                query_vector = query_vector.reshape(1, -1)
                
                # Search with current variant
                initial_k = min(top_k * 2, len(self.file_paths))
                distances, indices = self.index.search(query_vector, initial_k) # type: ignore
                
                # Process results
                for idx, dist in zip(indices[0], distances[0]):
                    if idx != -1:
                        file_path = self.file_paths[idx]
                        if file_path not in seen_files:
                            similarity = 1.0 / (1.0 + float(dist))
                            if similarity > 0.3:  # Lower threshold for better recall
                                seen_files.add(file_path)
                                all_results.append((file_path, similarity, self.vector_cache[file_path]["description"]))
            
            if not all_results:
                return []
                
            # Sort by similarity and take top_k
            all_results.sort(key=lambda x: x[1], reverse=True)
            results = all_results[:top_k]

            results = self.pick_results(query_variants, [path for path, _, _ in results])

            output = "Found related files:\n"
            for file in results:
                output += f'''- {file['file']} ({file['reason']})\n'''
            PrettyOutput.print(output, output_type=OutputType.INFO, lang="markdown")

            
            return results
            
        except Exception as e:
            PrettyOutput.print(f"æœç´¢å¤±è´¥: {str(e)}", output_type=OutputType.ERROR)
            return []

    def ask_codebase(self, query: str, top_k: int=20) -> Tuple[List[Dict[str, str]], str]:
        """Query the codebase with enhanced context building"""
        files_from_codebase = self.search_similar(query, top_k)
        
        if not files_from_codebase:
            PrettyOutput.print("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡ä»¶", output_type=OutputType.WARNING)
            return [], ""
        
        prompt = f"""
# ğŸ¤– è§’è‰²å®šä¹‰
æ‚¨æ˜¯ä¸€ä½ä»£ç åˆ†æä¸“å®¶ï¼Œèƒ½å¤Ÿæä¾›å…³äºä»£ç åº“çš„å…¨é¢ä¸”å‡†ç¡®çš„å›ç­”ã€‚

# ğŸ¯ æ ¸å¿ƒèŒè´£
- æ·±å…¥åˆ†æä»£ç æ–‡ä»¶
- æ¸…æ™°è§£é‡ŠæŠ€æœ¯æ¦‚å¿µ
- æä¾›ç›¸å…³ä»£ç ç¤ºä¾‹
- è¯†åˆ«ç¼ºå¤±çš„ä¿¡æ¯
- ä½¿ç”¨ç”¨æˆ·çš„è¯­è¨€è¿›è¡Œå›ç­”

# ğŸ“‹ å›ç­”è¦æ±‚
## å†…å®¹è´¨é‡
- å…³æ³¨å®ç°ç»†èŠ‚
- ä¿æŒæŠ€æœ¯å‡†ç¡®æ€§
- åŒ…å«ç›¸å…³ä»£ç ç‰‡æ®µ
- æŒ‡å‡ºä»»ä½•ç¼ºå¤±çš„ä¿¡æ¯
- ä½¿ç”¨ä¸“ä¸šæœ¯è¯­

## å›ç­”æ ¼å¼
- question: [é‡è¿°é—®é¢˜]
  answer: |
    [è¯¦ç»†çš„æŠ€æœ¯å›ç­”ï¼ŒåŒ…å«ï¼š
    - å®ç°ç»†èŠ‚
    - ä»£ç ç¤ºä¾‹ï¼ˆå¦‚æœç›¸å…³ï¼‰
    - ç¼ºå¤±çš„ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    - ç›¸å…³æŠ€æœ¯æ¦‚å¿µ]

- question: [å¦‚æœéœ€è¦ï¼Œæå‡ºåç»­é—®é¢˜]
  answer: |
    [é¢å¤–çš„æŠ€æœ¯ç»†èŠ‚]

# ğŸ” åˆ†æä¸Šä¸‹æ–‡
é—®é¢˜: {query}

ç›¸å…³ä»£ç æ–‡ä»¶ï¼ˆæŒ‰ç›¸å…³æ€§æ’åºï¼‰:
"""

        # æ·»åŠ ä¸Šä¸‹æ–‡ï¼Œæ§åˆ¶é•¿åº¦
        available_count = self.max_token_count - get_context_token_count(prompt) - 1000  # ä¸ºå›ç­”é¢„ç•™ç©ºé—´
        current_count = 0
        
        for path in files_from_codebase:
            try:
                content = open(path["file"], "r", encoding="utf-8").read()
                file_content = f"""
## æ–‡ä»¶: {path["file"]}
```
{content}
```
---
"""
                if current_count + get_context_token_count(file_content) > available_count:
                    PrettyOutput.print(
                        "ç”±äºä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶, ä¸€äº›æ–‡ä»¶è¢«çœç•¥", 
                        output_type=OutputType.WARNING
                    )
                    break
                    
                prompt += file_content
                current_count += get_context_token_count(file_content)
                
            except Exception as e:
                PrettyOutput.print(f"è¯»å– {path} å¤±è´¥: {str(e)}", 
                                output_type=OutputType.ERROR)
                continue

        prompt += """
# â— é‡è¦è§„åˆ™
1. å§‹ç»ˆåŸºäºæä¾›çš„ä»£ç è¿›è¡Œå›ç­”
2. ä¿æŒæŠ€æœ¯å‡†ç¡®æ€§
3. åœ¨ç›¸å…³æ—¶åŒ…å«ä»£ç ç¤ºä¾‹
4. æŒ‡å‡ºä»»ä½•ç¼ºå¤±çš„ä¿¡æ¯
5. ä¿æŒä¸“ä¸šè¯­è¨€
6. ä½¿ç”¨ç”¨æˆ·çš„è¯­è¨€è¿›è¡Œå›ç­”
"""

        model = PlatformRegistry.get_global_platform_registry().get_thinking_platform()

        return files_from_codebase, model.chat_until_success(prompt)

    def is_index_generated(self) -> bool:
        """Check if the index has been generated"""
        try:
            # 1. æ£€æŸ¥åŸºæœ¬æ¡ä»¶
            if not self.vector_cache or not self.file_paths:
                return False
                
            if not hasattr(self, 'index') or self.index is None:
                return False
                
            # 2. æ£€æŸ¥ç´¢å¼•æ˜¯å¦å¯ç”¨
            # åˆ›å»ºæµ‹è¯•å‘é‡
            test_vector = np.zeros((1, self.vector_dim), dtype=np.float32) # type: ignore
            try:
                self.index.search(test_vector, 1) # type: ignore
            except Exception:
                return False
                
            # 3. éªŒè¯å‘é‡ç¼“å­˜å’Œæ–‡ä»¶è·¯å¾„çš„ä¸€è‡´æ€§
            if len(self.vector_cache) != len(self.file_paths):
                return False
                
            # 4. éªŒè¯æ‰€æœ‰ç¼“å­˜æ–‡ä»¶
            for file_path in self.file_paths:
                if file_path not in self.vector_cache:
                    return False
                    
                cache_path = self._get_cache_path(file_path)
                if not os.path.exists(cache_path):
                    return False
                    
                cache_data = self.vector_cache[file_path]
                if not isinstance(cache_data.get("vector"), np.ndarray):
                    return False
            
            return True
            
        except Exception as e:
            PrettyOutput.print(f"æ£€æŸ¥ç´¢å¼•çŠ¶æ€å¤±è´¥: {str(e)}", 
                             output_type=OutputType.ERROR)
            return False





def main():

    parser = argparse.ArgumentParser(description='Codebase management and search tool')
    subparsers = parser.add_subparsers(dest='command', help='Available commands')

    # Generate command
    generate_parser = subparsers.add_parser('generate', help='Generate codebase index')
    generate_parser.add_argument('--force', action='store_true', help='Force rebuild index')

    # Search command
    search_parser = subparsers.add_parser('search', help='Search similar code files')
    search_parser.add_argument('query', type=str, help='Search query')
    search_parser.add_argument('--top-k', type=int, default=20, help='Number of results to return (default: 20)')

    # Ask command
    ask_parser = subparsers.add_parser('ask', help='Ask a question about the codebase')
    ask_parser.add_argument('question', type=str, help='Question to ask')
    ask_parser.add_argument('--top-k', type=int, default=20, help='Number of results to use (default: 20)')

    export_parser = subparsers.add_parser('export', help='Export current index data')
    args = parser.parse_args()
    
    current_dir = find_git_root()
    codebase = CodeBase(current_dir)

    if args.command == 'export':
        codebase.export()
        return

    # å¦‚æœæ²¡æœ‰ç”Ÿæˆç´¢å¼•ï¼Œä¸”ä¸æ˜¯ç”Ÿæˆå‘½ä»¤ï¼Œæç¤ºç”¨æˆ·å…ˆç”Ÿæˆç´¢å¼•
    if not codebase.is_index_generated() and args.command != 'generate':
        PrettyOutput.print("ç´¢å¼•å°šæœªç”Ÿæˆï¼Œè¯·å…ˆè¿è¡Œ 'generate' å‘½ä»¤ç”Ÿæˆç´¢å¼•", output_type=OutputType.WARNING)
        return

    if args.command == 'generate':
        try:
            codebase.generate_codebase(force=args.force)
            PrettyOutput.print("ä»£ç åº“ç”Ÿæˆå®Œæˆ", output_type=OutputType.SUCCESS)
        except Exception as e:
            PrettyOutput.print(f"ä»£ç åº“ç”Ÿæˆå¤±è´¥: {str(e)}", output_type=OutputType.ERROR)
    
    elif args.command == 'search':
        results = codebase.search_similar(args.query, args.top_k)
        if not results:
            PrettyOutput.print("æ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼çš„æ–‡ä»¶", output_type=OutputType.WARNING)
            return
            
        output = "æœç´¢ç»“æœ:\n"
        for path in results:
            output += f"""- {path}\n"""
        PrettyOutput.print(output, output_type=OutputType.INFO, lang="markdown")

    elif args.command == 'ask':            
        response = codebase.ask_codebase(args.question, args.top_k)
        output = f"""{response}"""
        PrettyOutput.print(output, output_type=OutputType.INFO)

    else:
        parser.print_help()


if __name__ == "__main__":
    exit(main())