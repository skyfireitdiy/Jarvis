# -*- coding: utf-8 -*-
import os
import re
from typing import Any
from typing import Callable
from typing import Optional
from typing import Tuple
from typing import Union
from typing import Dict

from jarvis.jarvis_utils.embedding import get_context_token_count
from jarvis.jarvis_utils.config import calculate_token_limit, get_max_input_token_count

# è¯­è¨€æå–å™¨æ³¨å†Œè¡¨ï¼ˆå¯¼å‡ºä¾›å…¶ä»–æ¨¡å—ä½¿ç”¨ï¼‰
_LANGUAGE_EXTRACTORS: dict[str, Callable[[], Optional[Any]]] = {}


def is_text_file(filepath: str) -> bool:
    """
    Check if a file is a text file.
    """
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            f.read(1024)  # Try to read a small chunk
        return True
    except (UnicodeDecodeError, IOError):
        return False


def count_lines(filepath: str) -> int:
    """
    Count the number of lines in a file.
    """
    try:
        with open(filepath, "r", encoding="utf-8", errors="ignore") as f:
            return sum(1 for _ in f)
    except IOError:
        return 0


def register_language_extractor(
    extensions: Union[str, list[str]],
    extractor_factory: Optional[Callable[[], Optional[Any]]] = None,
) -> Optional[Callable[[Callable[[], Optional[Any]]], Callable[[], Optional[Any]]]]:
    """
    Register a symbol extractor for one or more file extensions.

    Can be used as a decorator or as a regular function.

    Args:
        extensions: List of file extensions (e.g., ['.py', '.pyw']) or single extension string.
                   If used as decorator, this is the first argument.
        extractor_factory: A callable that returns an extractor instance or None if unavailable.
                          The extractor must have an extract_symbols(file_path: str, content: str) method
                          that returns a list of Symbol objects.
                          If used as decorator, this is the decorated function.

    Examples:
        # As decorator:
        @register_language_extractor(['.py', '.pyw'])
        def create_python_extractor():
            from jarvis.jarvis_code_agent.code_analyzer.languages.python_language import PythonSymbolExtractor
            return PythonSymbolExtractor()

        # As regular function:
        def create_java_extractor():
            # ... create extractor ...
            return JavaExtractor()

        register_language_extractor('.java', create_java_extractor)
    """
    # Support both decorator and function call syntax
    if extractor_factory is None:
        # Used as decorator: @register_language_extractor(['.ext'])
        def decorator(func: Callable[[], Optional[Any]]) -> Callable[[], Optional[Any]]:
            if isinstance(extensions, str):
                exts = [extensions]
            else:
                exts = extensions

            for ext in exts:
                ext_lower = ext.lower()
                if not ext_lower.startswith("."):
                    ext_lower = "." + ext_lower
                _LANGUAGE_EXTRACTORS[ext_lower] = func

            return func

        return decorator
    else:
        # Used as regular function: register_language_extractor(['.ext'], factory)
        if isinstance(extensions, str):
            extensions = [extensions]

        for ext in extensions:
            ext_lower = ext.lower()
            if not ext_lower.startswith("."):
                ext_lower = "." + ext_lower
            _LANGUAGE_EXTRACTORS[ext_lower] = extractor_factory
        return None


def _get_symbol_extractor(filepath: str) -> Optional[Any]:
    """Get appropriate symbol extractor for the file based on extension"""
    ext = os.path.splitext(filepath)[1].lower()

    # Check registered extractors
    if ext in _LANGUAGE_EXTRACTORS:
        try:
            return _LANGUAGE_EXTRACTORS[ext]()
        except Exception:
            return None

    return None


# Initialize built-in extractors on module load
# Import language_extractors module to trigger automatic registration
try:
    import jarvis.jarvis_agent.language_extractors  # noqa: F401
except (ImportError, Exception):
    pass


def extract_symbols_from_file(filepath: str) -> list[dict[str, Any]]:
    """Extract symbols from a file using tree-sitter or AST"""
    extractor = _get_symbol_extractor(filepath)
    if not extractor:
        return []

    try:
        with open(filepath, "r", encoding="utf-8", errors="ignore") as f:
            content = f.read()

        symbols = extractor.extract_symbols(filepath, content)

        # Convert Symbol objects to dict format
        result = []
        for symbol in symbols:
            result.append(
                {
                    "name": symbol.name,
                    "type": symbol.kind,
                    "line": symbol.line_start,
                    "signature": symbol.signature or f"{symbol.kind} {symbol.name}",
                }
            )

        return result
    except Exception:
        return []


def format_symbols_output(filepath: str, symbols: list[dict[str, Any]]) -> str:
    """Format symbols list as output string"""
    if not symbols:
        return ""

    # Group symbols by type
    by_type: dict[str, list[dict[str, Any]]] = {}
    for symbol in symbols:
        symbol_type = symbol["type"]
        if symbol_type not in by_type:
            by_type[symbol_type] = []
        by_type[symbol_type].append(symbol)

    # Sort symbols within each type by line number
    for symbol_type in by_type:
        by_type[symbol_type].sort(key=lambda x: x["line"])

    output_lines = [f"\nğŸ“‹ æ–‡ä»¶ç¬¦å·: {filepath}"]
    output_lines.append("â”€" * 60)

    # Type names in Chinese
    type_names = {
        "function": "å‡½æ•°",
        "async_function": "å¼‚æ­¥å‡½æ•°",
        "class": "ç±»",
        "struct": "ç»“æ„ä½“",
        "enum": "æšä¸¾",
        "interface": "æ¥å£",
        "trait": "ç‰¹å¾",
        "variable": "å˜é‡",
        "constant": "å¸¸é‡",
    }

    for symbol_type, type_symbols in sorted(by_type.items()):
        type_name = type_names.get(symbol_type, symbol_type)
        output_lines.append(f"\n{type_name} ({len(type_symbols)} ä¸ª):")
        for symbol in type_symbols:
            line_info = f"  è¡Œ {symbol['line']:4d}: {symbol['name']}"
            if "signature" in symbol and symbol["signature"]:
                sig = symbol["signature"].strip()
                if len(sig) > 50:
                    sig = sig[:47] + "..."
                line_info += f" - {sig}"
            output_lines.append(line_info)

    output_lines.append("â”€" * 60)
    output_lines.append("")

    return "\n".join(output_lines)


def _parse_quoted_reference(ref: str) -> Dict[str, Any]:
    """
    è§£æå•å¼•å·å†…çš„å¼•ç”¨ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
    - 'file.py' - å®Œæ•´æ–‡ä»¶å¼•ç”¨ï¼ˆæå–ç¬¦å·ï¼‰
    - 'file.py:100-200' - è¡Œå·èŒƒå›´å¼•ç”¨
    - 'file.py:summary' - æ‘˜è¦æ¨¡å¼ï¼ˆåªæ˜¾ç¤ºç¬¦å·ä¿¡æ¯ï¼‰
    - 'folder/' - ç›®å½•å¼•ç”¨

    Args:
        ref: å¼•ç”¨å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "file.py:100-200"

    Returns:
        DictåŒ…å«:
            - filepath: æ–‡ä»¶è·¯å¾„
            - start_line: èµ·å§‹è¡Œå·ï¼ˆå¯é€‰ï¼‰
            - end_line: ç»“æŸè¡Œå·ï¼ˆå¯é€‰ï¼‰
            - mode: 'symbols', 'range', 'summary', 'directory'
    """
    ref = ref.strip()

    # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®å½•å¼•ç”¨ï¼ˆä»¥ / ç»“å°¾ï¼‰
    if ref.endswith("/") or (os.path.exists(ref) and os.path.isdir(ref)):
        return {
            "filepath": ref.rstrip("/"),
            "mode": "directory",
        }

    # æ£€æŸ¥æ˜¯å¦æœ‰è¡Œå·èŒƒå›´æˆ–æ‘˜è¦æ¨¡å¼
    if ":" in ref:
        filepath, spec = ref.split(":", 1)
        filepath = filepath.strip()

        # æ£€æŸ¥æ˜¯å¦æ˜¯æ‘˜è¦æ¨¡å¼
        if spec.strip().lower() == "summary":
            return {
                "filepath": filepath,
                "mode": "summary",
            }

        # è§£æè¡Œå·èŒƒå›´
        if "-" in spec:
            try:
                start_str, end_str = spec.split("-", 1)
                start_line = int(start_str.strip())
                end_line = int(end_str.strip())
                return {
                    "filepath": filepath,
                    "start_line": start_line,
                    "end_line": end_line,
                    "mode": "range",
                }
            except ValueError:
                pass

    # é»˜è®¤ç¬¦å·æå–æ¨¡å¼ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
    return {
        "filepath": ref,
        "mode": "symbols",
    }


def _get_max_token_limit(agent: Optional[Any] = None) -> int:
    """è·å–åŸºäºå‰©ä½™tokenæ•°é‡çš„tokené™åˆ¶"""
    try:
        # ä¼˜å…ˆä½¿ç”¨å‰©ä½™tokenæ•°é‡
        if agent and hasattr(agent, "model"):
            try:
                remaining_tokens = agent.model.get_remaining_token_count()
                # ä½¿ç”¨å‰©ä½™tokençš„2/3æˆ–64kçš„æœ€å°å€¼
                limit_tokens = calculate_token_limit(remaining_tokens)
                if limit_tokens > 0:
                    return limit_tokens
            except Exception:
                pass

        # å›é€€æ–¹æ¡ˆï¼šä½¿ç”¨è¾“å…¥çª—å£çš„1/2
        max_input_tokens = get_max_input_token_count()
        return int(max_input_tokens * 0.5)
    except Exception:
        # é»˜è®¤å€¼
        return 20000


def _read_file_content(
    filepath: str,
    start_line: Optional[int] = None,
    end_line: Optional[int] = None,
    agent: Optional[Any] = None,
) -> Tuple[str, bool, str]:
    """
    è¯»å–æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒè¡Œå·èŒƒå›´

    Args:
        filepath: æ–‡ä»¶è·¯å¾„
        start_line: èµ·å§‹è¡Œå·ï¼ˆå¯é€‰ï¼‰
        end_line: ç»“æŸè¡Œå·ï¼ˆå¯é€‰ï¼‰
        agent: Agentå®ä¾‹ï¼Œç”¨äºè·å–tokené™åˆ¶

    Returns:
        Tuple[content, success, error_msg]
    """
    try:
        expanded_path = os.path.expanduser(filepath)
        abs_path = os.path.abspath(expanded_path)

        # æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
        if not os.path.exists(abs_path):
            return "", False, f"æ–‡ä»¶ä¸å­˜åœ¨: {abs_path}"

        # æ–‡ä»¶å¤§å°é™åˆ¶æ£€æŸ¥ï¼ˆ10MBï¼‰
        if os.path.getsize(abs_path) > 10 * 1024 * 1024:
            return (
                "",
                False,
                f"æ–‡ä»¶è¿‡å¤§ (>10MB): {abs_path}ï¼Œè¯·ä½¿ç”¨è¡Œå·èŒƒå›´å¼•ç”¨ï¼ˆå¦‚ '{filepath}:100-200'ï¼‰æˆ–æ‘˜è¦æ¨¡å¼ï¼ˆå¦‚ '{filepath}:summary'ï¼‰",
            )

        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(abs_path, "r", encoding="utf-8", errors="ignore") as f:
            lines = f.readlines()

        total_lines = len(lines)

        # å¤„ç†ç©ºæ–‡ä»¶
        if total_lines == 0:
            return f"\nğŸ“„ æ–‡ä»¶: {abs_path}\næ–‡ä»¶ä¸ºç©º (0è¡Œ)\n", True, ""

        # å¤„ç†è¡Œå·èŒƒå›´
        if start_line is not None and end_line is not None:
            # è§„èŒƒåŒ–è¡Œå·
            start_line = max(1, min(start_line, total_lines))
            end_line = max(1, min(end_line, total_lines))
            if start_line > end_line:
                start_line, end_line = end_line, start_line

            selected_lines = lines[start_line - 1 : end_line]
            content = "".join(selected_lines)

            # æ£€æŸ¥tokené™åˆ¶
            content_tokens = get_context_token_count(content)
            max_tokens = _get_max_token_limit(agent)

            if content_tokens > max_tokens:
                # è‡ªåŠ¨æˆªæ–­
                safe_ratio = max_tokens / content_tokens
                safe_lines = max(1, int(len(selected_lines) * safe_ratio * 0.9))
                safe_end = start_line + safe_lines - 1
                truncated_lines = lines[start_line - 1 : safe_end]
                truncated_content = "".join(truncated_lines)

                warning = (
                    f"\nâš ï¸ è­¦å‘Š: å†…å®¹è¶…å‡ºtokené™åˆ¶ï¼Œä»…æ˜¾ç¤ºå‰ {safe_lines} è¡Œ "
                    f"(è¯·æ±‚èŒƒå›´: {start_line}-{end_line}, å…± {end_line - start_line + 1} è¡Œ)\n"
                    f"ğŸ’¡ å¦‚éœ€ç»§ç»­è¯»å–ï¼Œè¯·ä½¿ç”¨: '{filepath}:{safe_end + 1}-{end_line}'\n"
                )
                return (
                    f"\nğŸ“„ æ–‡ä»¶: {abs_path} (è¡Œ {start_line}-{safe_end})\n"
                    f"{warning}\n"
                    f"{truncated_content}\n",
                    True,
                    "",
                )

            # ä¸ºæ¯è¡Œæ·»åŠ è¡Œå·
            numbered_lines = []
            for i, line in enumerate(selected_lines, start=start_line):
                line_number_str = f"{i:4d}"
                line_content = line.rstrip("\n\r")
                numbered_lines.append(f"{line_number_str}:{line_content}")

            numbered_content = "\n".join(numbered_lines)

            return (
                f"\nğŸ“„ æ–‡ä»¶: {abs_path} (è¡Œ {start_line}-{end_line})\n"
                f"{'=' * 80}\n"
                f"{numbered_content}\n"
                f"{'=' * 80}\n",
                True,
                "",
            )
        else:
            # å®Œæ•´æ–‡ä»¶
            content = "".join(lines)

            # æ£€æŸ¥tokené™åˆ¶
            content_tokens = get_context_token_count(content)
            max_tokens = _get_max_token_limit(agent)

            if content_tokens > max_tokens:
                return (
                    "",
                    False,
                    f"æ–‡ä»¶å†…å®¹è¿‡å¤§ ({content_tokens} tokens > {max_tokens} tokens): {abs_path}ï¼Œ"
                    f"è¯·ä½¿ç”¨è¡Œå·èŒƒå›´å¼•ç”¨ï¼ˆå¦‚ '{filepath}:1-100'ï¼‰æˆ–æ‘˜è¦æ¨¡å¼ï¼ˆå¦‚ '{filepath}:summary'ï¼‰",
                )

            # ä¸ºæ¯è¡Œæ·»åŠ è¡Œå·
            numbered_lines = []
            for i, line in enumerate(lines, start=1):
                line_number_str = f"{i:4d}"
                line_content = line.rstrip("\n\r")
                numbered_lines.append(f"{line_number_str}:{line_content}")

            numbered_content = "\n".join(numbered_lines)

            return (
                f"\nğŸ“„ æ–‡ä»¶: {abs_path}\n"
                f"ğŸ“Š æ€»è¡Œæ•°: {total_lines}\n"
                f"{'=' * 80}\n"
                f"{numbered_content}\n"
                f"{'=' * 80}\n",
                True,
                "",
            )

    except Exception as e:
        return "", False, f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"


def _format_summary_output(filepath: str, symbols: list[dict[str, Any]]) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶æ‘˜è¦è¾“å‡º"""
    output_lines = [f"\nğŸ“‹ æ–‡ä»¶æ‘˜è¦: {filepath}"]

    if symbols:
        output_lines.append(format_symbols_output(filepath, symbols))
    else:
        # å¦‚æœæ²¡æœ‰ç¬¦å·ï¼Œè‡³å°‘æ˜¾ç¤ºæ–‡ä»¶åŸºæœ¬ä¿¡æ¯
        try:
            line_count = count_lines(filepath)
            file_size = os.path.getsize(filepath)
            output_lines.append(f"ğŸ“Š æ–‡ä»¶ä¿¡æ¯:")
            output_lines.append(f"   - æ€»è¡Œæ•°: {line_count}")
            output_lines.append(f"   - æ–‡ä»¶å¤§å°: {file_size / 1024:.2f} KB")
            output_lines.append(f"   - æ— æ³•æå–ç¬¦å·ä¿¡æ¯ï¼ˆå¯èƒ½ä¸æ˜¯æ”¯æŒçš„ä»£ç æ–‡ä»¶ï¼‰")
        except Exception:
            pass

    return "\n".join(output_lines) + "\n"


def _format_directory_output(dirpath: str) -> str:
    """æ ¼å¼åŒ–ç›®å½•å¼•ç”¨è¾“å‡º"""
    try:
        abs_dir = os.path.abspath(os.path.expanduser(dirpath))
        if not os.path.isdir(abs_dir):
            return f"\nâš ï¸ ç›®å½•ä¸å­˜åœ¨: {abs_dir}\n"

        output_lines = [f"\nğŸ“ ç›®å½•: {abs_dir}"]
        output_lines.append("â”€" * 60)

        # åˆ—å‡ºæ–‡ä»¶
        files = []
        dirs = []
        for item in sorted(os.listdir(abs_dir)):
            item_path = os.path.join(abs_dir, item)
            if os.path.isfile(item_path) and is_text_file(item_path):
                files.append(item)
            elif os.path.isdir(item_path):
                dirs.append(item)

        if dirs:
            output_lines.append(f"\nç›®å½• ({len(dirs)} ä¸ª):")
            for d in dirs[:20]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                output_lines.append(f"  ğŸ“ {d}/")
            if len(dirs) > 20:
                output_lines.append(f"  ... è¿˜æœ‰ {len(dirs) - 20} ä¸ªç›®å½•")

        if files:
            output_lines.append(f"\næ–‡ä»¶ ({len(files)} ä¸ª):")
            for f in files[:30]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                try:
                    line_count = count_lines(os.path.join(abs_dir, f))
                    output_lines.append(f"  ğŸ“„ {f} ({line_count} è¡Œ)")
                except Exception:
                    output_lines.append(f"  ğŸ“„ {f}")
            if len(files) > 30:
                output_lines.append(f"  ... è¿˜æœ‰ {len(files) - 30} ä¸ªæ–‡ä»¶")

        output_lines.append("â”€" * 60)
        output_lines.append("")

        return "\n".join(output_lines)
    except Exception as e:
        return f"\nâš ï¸ è¯»å–ç›®å½•å¤±è´¥: {str(e)}\n"


def file_context_handler(user_input: str, agent_: Any) -> Tuple[str, bool]:
    """
    å¤„ç†ç”¨æˆ·è¾“å…¥ä¸­çš„æ–‡ä»¶/ç›®å½•å¼•ç”¨ï¼Œæ”¯æŒä»¥ä¸‹è¯­æ³•ï¼ˆä½¿ç”¨å•å¼•å·ï¼‰ï¼š
    - 'filename' - å®Œæ•´æ–‡ä»¶å¼•ç”¨ï¼ˆæå–ç¬¦å·ï¼ŒåŸæœ‰åŠŸèƒ½ï¼‰
    - 'file.py:100-200' - è¡Œå·èŒƒå›´å¼•ç”¨ï¼ˆè¯»å–æŒ‡å®šè¡ŒèŒƒå›´ï¼‰
    - 'file.py:summary' - æ‘˜è¦æ¨¡å¼ï¼ˆåªæ˜¾ç¤ºç¬¦å·ä¿¡æ¯ï¼‰
    - 'folder/' - ç›®å½•å¼•ç”¨ï¼ˆåˆ—å‡ºç›®å½•å†…å®¹ï¼‰

    Args:
        user_input: The user's input string.
        agent_: The agent instance.

    Returns:
        A tuple containing the modified user input and a boolean indicating if
        further processing should be skipped.
    """
    # Regex to find paths in single quotes
    raw_paths = re.findall(r"'([^']+)'", user_input)

    if not raw_paths:
        return user_input, False

    added_context = ""

    for raw_path in raw_paths:
        parsed = _parse_quoted_reference(raw_path)

        if parsed["mode"] == "directory":
            # ç›®å½•å¼•ç”¨
            dir_output = _format_directory_output(parsed["filepath"])
            added_context += dir_output
        elif parsed["mode"] == "summary":
            # æ‘˜è¦æ¨¡å¼
            filepath = parsed["filepath"]
            abs_path = os.path.abspath(os.path.expanduser(filepath))

            if os.path.isfile(abs_path) and is_text_file(abs_path):
                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                if os.path.getsize(abs_path) > 10 * 1024 * 1024:
                    added_context += (
                        f"\nâš ï¸ æ–‡ä»¶è¿‡å¤§ (>10MB): {abs_path}ï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦\n"
                    )
                else:
                    symbols = extract_symbols_from_file(abs_path)
                    added_context += _format_summary_output(abs_path, symbols)
            else:
                added_context += f"\nâš ï¸ æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯æ–‡æœ¬æ–‡ä»¶: {filepath}\n"
        elif parsed["mode"] == "range":
            # è¡Œå·èŒƒå›´å¼•ç”¨
            filepath = parsed["filepath"]
            start_line = parsed.get("start_line")
            end_line = parsed.get("end_line")
            content, success, error_msg = _read_file_content(
                filepath, start_line, end_line, agent_
            )
            if success:
                added_context += content
            else:
                added_context += f"\nâš ï¸ {error_msg}\n"
        else:
            # ç¬¦å·æå–æ¨¡å¼ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
            filepath = parsed["filepath"]
            abs_path = os.path.abspath(os.path.expanduser(filepath))

            if os.path.isfile(abs_path) and is_text_file(abs_path):
                # Extract symbols from the file (åŸæœ‰åŠŸèƒ½)
                symbols = extract_symbols_from_file(abs_path)
                if symbols:
                    added_context += format_symbols_output(abs_path, symbols)

    if added_context:
        user_input = user_input.strip() + added_context

    return user_input, False


# ============================================================================
# å¦‚ä½•æ·»åŠ æ–°è¯­è¨€æ”¯æŒ
# ============================================================================
#
# æ¨èæ–¹å¼ï¼šåœ¨ language_extractors/ ç›®å½•ä¸‹åˆ›å»ºæ–°æ–‡ä»¶
#
# 1. åˆ›å»ºæ–°æ–‡ä»¶ï¼šjarvis_agent/language_extractors/java_extractor.py
#
#    # -*- coding: utf-8 -*-
#    """Java language symbol extractor."""
#
#    from typing import Optional, Any, List
#    from jarvis.jarvis_agent.file_context_handler import register_language_extractor
#    from jarvis.jarvis_code_agent.code_analyzer.symbol_extractor import Symbol
#
#    def create_java_extractor() -> Optional[Any]:
#        try:
#            from tree_sitter import Language, Parser
#            import tree_sitter_java
#
#            JAVA_LANGUAGE = tree_sitter_java.language()
#            JAVA_SYMBOL_QUERY = """
#            (method_declaration
#              name: (identifier) @method.name)
#
#            (class_declaration
#              name: (identifier) @class.name)
#            """
#
#            class JavaSymbolExtractor:
#                def __init__(self):
#                    self.language = JAVA_LANGUAGE
#                    self.parser = Parser()
#                    self.parser.set_language(self.language)
#                    self.symbol_query = JAVA_SYMBOL_QUERY
#
#                def extract_symbols(self, file_path: str, content: str) -> List[Any]:
#                    try:
#                        tree = self.parser.parse(bytes(content, "utf8"))
#                        query = self.language.query(self.symbol_query)
#                        captures = query.captures(tree.root_node)
#
#                        symbols = []
#                        for node, name in captures:
#                            kind_map = {
#                                "method.name": "method",
#                                "class.name": "class",
#                            }
#                            symbol_kind = kind_map.get(name)
#                            if symbol_kind:
#                                symbols.append(Symbol(
#                                    name=node.text.decode('utf8'),
#                                    kind=symbol_kind,
#                                    file_path=file_path,
#                                    line_start=node.start_point[0] + 1,
#                                    line_end=node.end_point[0] + 1,
#                                ))
#                        return symbols
#                    except Exception:
#                        return []
#
#            return JavaSymbolExtractor()
#        except (ImportError, Exception):
#            return None
#
#    def register_java_extractor() -> None:
#        register_language_extractor(['.java', '.jav'], create_java_extractor)
#
#
# 2. åœ¨ language_extractors/__init__.py ä¸­æ·»åŠ å¯¼å…¥å’Œæ³¨å†Œï¼š
#
#    try:
#        from .java_extractor import register_java_extractor
#        register_java_extractor()
#    except (ImportError, Exception):
#        pass
#
#
# æ–¹æ³•2: åœ¨è¿è¡Œæ—¶åŠ¨æ€æ³¨å†Œï¼ˆä¸æ¨èï¼Œä½†å¯ç”¨ï¼‰
#
# from jarvis.jarvis_agent.file_context_handler import register_language_extractor
#
# def create_ruby_extractor():
#     # ... å®ç°æå–å™¨ ...
#     return RubyExtractor()
#
# register_language_extractor('.rb', create_ruby_extractor)
#
# ============================================================================
