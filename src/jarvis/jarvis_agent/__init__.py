import argparse
from typing import Any, Callable, List, Optional, Tuple, Union

from prompt_toolkit import prompt
import yaml
from yaspin import yaspin
import platform
import datetime

from jarvis.jarvis_agent.output_handler import OutputHandler
from jarvis.jarvis_agent.builtin_input_handler import builtin_input_handler
from jarvis.jarvis_agent.file_input_handler import file_input_handler
from jarvis.jarvis_agent.patch import PatchOutputHandler
from jarvis.jarvis_agent.shell_input_handler import shell_input_handler
from jarvis.jarvis_platform.base import BasePlatform
from jarvis.jarvis_platform.registry import PlatformRegistry
from jarvis.jarvis_utils.output import PrettyOutput, OutputType
from jarvis.jarvis_utils.embedding import get_context_token_count
from jarvis.jarvis_utils.config import is_auto_complete, is_execute_tool_confirm
from jarvis.jarvis_utils.methodology import load_methodology
from jarvis.jarvis_utils.globals import make_agent_name, set_agent, delete_agent
from jarvis.jarvis_utils.input import get_multiline_input
from jarvis.jarvis_utils.config import get_max_token_count
from jarvis.jarvis_utils.utils import ot, init_env
from jarvis.jarvis_utils.utils import user_confirm
import os

from jarvis.jarvis_tools.registry import ToolRegistry  # æ˜¾å¼å¯¼å…¥ToolRegistry
from jarvis.jarvis_platform.registry import PlatformRegistry
from .patch import PatchOutputHandler


__all__ = [
    'PlatformRegistry',
    'ToolRegistry',  # æ–°å¢ç¼ºå¤±çš„å¯¼å‡ºé¡¹
    'PatchOutputHandler',
    'Agent',
    'file_input_handler',
    'shell_input_handler',
    'builtin_input_handler',
    '_load_tasks',
    '_select_task',
    'get_multiline_input',
    'origin_agent_system_prompt',
    'init_env',
    'PrettyOutput',
    'OutputType'
]

class Agent:

    def set_summary_prompt(self, summary_prompt: str):
        """è®¾ç½®ä»»åŠ¡å®Œæˆæ—¶çš„æ€»ç»“æç¤ºæ¨¡æ¿ã€‚
        
        å‚æ•°:
            summary_prompt: ç”¨äºç”Ÿæˆä»»åŠ¡æ€»ç»“çš„æç¤ºæ¨¡æ¿
        """
        self.summary_prompt = summary_prompt

    def clear(self):
        """æ¸…é™¤å½“å‰å¯¹è¯å†å²ï¼Œä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ã€‚
        
        è¯¥æ–¹æ³•å°†ï¼š
        1. è°ƒç”¨æ¨¡å‹çš„delete_chatæ–¹æ³•æ¸…é™¤å¯¹è¯å†å²
        2. é‡ç½®å¯¹è¯é•¿åº¦è®¡æ•°å™¨
        3. æ¸…ç©ºå½“å‰æç¤º
        """
        self.model.delete_chat() # type: ignore
        self.conversation_length = 0
        self.prompt = ""
        
    def __del__(self):
        delete_agent(self.name)

        
    def __init__(self, 
                 system_prompt: str, 
                 name: str = "Jarvis", 
                 description: str = "",
                 platform: Union[Optional[BasePlatform], Optional[str]] = None, 
                 model_name: Optional[str] = None,
                 summary_prompt: Optional[str] = None, 
                 auto_complete: Optional[bool] = None, 
                 output_handler: List[OutputHandler] = [],
                 input_handler: Optional[List[Callable[[str, Any], Tuple[str, bool]]]] = None,
                 max_context_length: Optional[int] = None,
                 execute_tool_confirm: Optional[bool] = None,
                 multiline_inputer: Optional[Callable[[str], str]] = None):
        self.name = make_agent_name(name)
        self.description = description
        # åˆå§‹åŒ–å¹³å°å’Œæ¨¡å‹
        if platform is not None:
            if isinstance(platform, str):
                self.model = PlatformRegistry().create_platform(platform)
                if self.model is None:
                    PrettyOutput.print(f"å¹³å° {platform} ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨æ™®é€šæ¨¡å‹", OutputType.WARNING)
                    self.model = PlatformRegistry().get_normal_platform()
            else:
                self.model = platform
        else:
            self.model = PlatformRegistry.get_global_platform_registry().get_normal_platform()

        if model_name is not None:
            self.model.set_model_name(model_name)

        self.model.set_suppress_output(False)

        from jarvis.jarvis_tools.registry import ToolRegistry
        self.output_handler = output_handler if output_handler else [ToolRegistry()]
        self.multiline_inputer = multiline_inputer if multiline_inputer else get_multiline_input
        
        self.prompt = ""
        self.conversation_length = 0  # Use length counter instead
        self.system_prompt = system_prompt
        self.input_handler = input_handler if input_handler is not None else []
        # Load configuration from environment variables


        self.execute_tool_confirm = execute_tool_confirm if execute_tool_confirm is not None else is_execute_tool_confirm()

        self.summary_prompt = summary_prompt if summary_prompt else f"""è¯·ç”Ÿæˆä»»åŠ¡æ‰§è¡Œçš„ç®€æ˜æ€»ç»“æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š

1. ä»»åŠ¡ç›®æ ‡ï¼šä»»åŠ¡é‡è¿°
2. æ‰§è¡Œç»“æœï¼šæˆåŠŸ/å¤±è´¥
3. å…³é”®ä¿¡æ¯ï¼šæ‰§è¡Œè¿‡ç¨‹ä¸­æå–çš„é‡è¦ä¿¡æ¯
4. é‡è¦å‘ç°ï¼šä»»ä½•å€¼å¾—æ³¨æ„çš„å‘ç°
5. åç»­å»ºè®®ï¼šå¦‚æœæœ‰çš„è¯

è¯·ä½¿ç”¨ç®€æ´çš„è¦ç‚¹æè¿°ï¼Œçªå‡ºé‡è¦ä¿¡æ¯ã€‚
"""
        
        self.max_token_count = max_context_length if max_context_length is not None else get_max_token_count()
        self.auto_complete = auto_complete if auto_complete is not None else is_auto_complete()
        welcome_message = f"{name} åˆå§‹åŒ–å®Œæˆ - ä½¿ç”¨ {self.model.name()} æ¨¡å‹"

        PrettyOutput.print(welcome_message, OutputType.SYSTEM)
        
        action_prompt = """
# ğŸ§° å¯ç”¨æ“ä½œ
ä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥ä½¿ç”¨çš„æ“ä½œï¼š
"""

        # æ·»åŠ å·¥å…·åˆ—è¡¨æ¦‚è§ˆ
        action_prompt += "\n## Action List\n"
        action_prompt += ", ".join([handler.name() for handler in self.output_handler])

        # æ·»åŠ æ¯ä¸ªå·¥å…·çš„è¯¦ç»†è¯´æ˜
        action_prompt += "\n\n# ğŸ“ Action Details\n"
        for handler in self.output_handler:
            action_prompt += f"\n## {handler.name()}\n"
            # è·å–å·¥å…·çš„æç¤ºè¯å¹¶ç¡®ä¿æ ¼å¼æ­£ç¡®
            handler_prompt = handler.prompt().strip()
            # è°ƒæ•´ç¼©è¿›ä»¥ä¿æŒå±‚çº§ç»“æ„
            handler_prompt = "\n".join("   " + line if line.strip() else line 
                                      for line in handler_prompt.split("\n"))
            action_prompt += handler_prompt + "\n"

        # æ·»åŠ å·¥å…·ä½¿ç”¨æ€»ç»“
        action_prompt += """
# â— é‡è¦æ“ä½œä½¿ç”¨è§„åˆ™
1. ä¸€æ¬¡å¯¹è¯åªèƒ½ä½¿ç”¨ä¸€ä¸ªæ“ä½œï¼Œå¦åˆ™ä¼šå‡ºé”™
2. ä¸¥æ ¼æŒ‰ç…§æ¯ä¸ªæ“ä½œçš„æ ¼å¼æ‰§è¡Œ
3. ç­‰å¾…æ“ä½œç»“æœåå†è¿›è¡Œä¸‹ä¸€ä¸ªæ“ä½œ
4. å¤„ç†å®Œç»“æœåå†è°ƒç”¨æ–°çš„æ“ä½œ
5. å¦‚æœå¯¹æ“ä½œä½¿ç”¨ä¸æ¸…æ¥šï¼Œè¯·è¯·æ±‚å¸®åŠ©
"""

        complete_prompt = ""
        if self.auto_complete:
            complete_prompt = f"""
            ## ä»»åŠ¡å®Œæˆ
            å½“ä»»åŠ¡å®Œæˆæ—¶ï¼Œä½ åº”è¯¥æ‰“å°ä»¥ä¸‹ä¿¡æ¯ï¼š
            {ot("!!!COMPLETE!!!")}
            """

        self.model.set_system_message(f"""
{self.system_prompt}

{action_prompt}

{complete_prompt}
""")
        self.first = True


    
    def _call_model(self, message: str, need_complete: bool = False) -> str:
        """è°ƒç”¨AIæ¨¡å‹å¹¶å®ç°é‡è¯•é€»è¾‘ã€‚
        
        å‚æ•°:
            message: è¾“å…¥ç»™æ¨¡å‹çš„æ¶ˆæ¯
            
        è¿”å›:
            str: æ¨¡å‹çš„å“åº”
            
        æ³¨æ„:
            å°†ä½¿ç”¨æŒ‡æ•°é€€é¿é‡è¯•ï¼Œæœ€å¤šé‡è¯•30ç§’
        """
        for handler in self.input_handler:
            message, need_return = handler(message, self)
            if need_return:
                return message
                
        # æ·»åŠ è¾“å‡ºç®€æ´æ€§æŒ‡ä»¤
        actions = 'ã€'.join([o.name() for o in self.output_handler])
        message += f"\n\nç³»ç»ŸæŒ‡ä»¤ï¼šè¯·ä¸¥æ ¼è¾“å‡ºä¸”ä»…è¾“å‡ºä¸€ä¸ªæ“ä½œçš„å®Œæ•´è°ƒç”¨æ ¼å¼ï¼Œä¸è¦è¾“å‡ºå¤šä¸ªæ“ä½œï¼›éœ€è¦è¾“å‡ºè§£é‡Šã€åˆ†æå’Œæ€è€ƒè¿‡ç¨‹ã€‚ç¡®ä¿è¾“å‡ºæ ¼å¼æ­£ç¡®ä¸”å¯ç›´æ¥æ‰§è¡Œã€‚æ¯æ¬¡å“åº”å¿…é¡»ä¸”åªèƒ½åŒ…å«ä¸€ä¸ªæ“ä½œã€‚å¯ç”¨çš„æ“ä½œï¼š{actions}"
        if need_complete and self.auto_complete:
            message += f"\n\nå¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œè¯´æ˜å®ŒæˆåŸå› ï¼Œå¹¶è¾“å‡º{ot('!!!COMPLETE!!!')}"
        else:
            message += f"\n\nå¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œåªéœ€ç®€æ´åœ°è¯´æ˜å®ŒæˆåŸå› ã€‚"
        # ç´¯åŠ å¯¹è¯é•¿åº¦
        self.conversation_length += get_context_token_count(message)

        if self.conversation_length > self.max_token_count:
            message = self._summarize_and_clear_history() + "\n\n" + message
            self.conversation_length += get_context_token_count(message)
        
        print("ğŸ¤– æ¨¡å‹æ€è€ƒï¼š")
        return self.model.chat_until_success(message)   # type: ignore


    def _summarize_and_clear_history(self) -> str:
        """Summarize current conversation and clear history.
        
        This method will:
        1. Generate a summary of key information
        2. Clear the conversation history
        3. Keep the system message
        4. Add summary as new context
        5. Reset conversation length
        
        Note:
            Used when context length exceeds maximum
        """
        # Create a new model instance to summarize, avoid affecting the main conversation

        with yaspin(text="æ­£åœ¨æ€»ç»“å¯¹è¯å†å²...", color="cyan") as spinner:
            
            prompt = """è¯·æ€»ç»“ä¹‹å‰å¯¹è¯ä¸­çš„å…³é”®ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
    1. å½“å‰ä»»åŠ¡ç›®æ ‡
    2. å·²ç¡®è®¤çš„å…³é”®ä¿¡æ¯
    3. å·²å°è¯•çš„è§£å†³æ–¹æ¡ˆ
    4. å½“å‰è¿›å±•
    5. å¾…è§£å†³çš„é—®é¢˜

    è¯·ç”¨ç®€æ´çš„è¦ç‚¹å½¢å¼æè¿°ï¼Œçªå‡ºé‡è¦ä¿¡æ¯ã€‚ä¸è¦åŒ…å«å¯¹è¯ç»†èŠ‚ã€‚
    """
            
            try:
                with spinner.hidden():
                    summary = self.model.chat_until_success(self.prompt + "\n" + prompt) # type: ignore

                self.model.delete_chat() # type: ignore
                
                # æ¸…ç©ºå½“å‰å¯¹è¯å†å²ï¼Œä½†ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
                self.conversation_length = 0  # Reset conversation length
                
                # æ·»åŠ æ€»ç»“ä½œä¸ºæ–°çš„ä¸Šä¸‹æ–‡
                spinner.text = "æ€»ç»“å¯¹è¯å†å²å®Œæˆ"
                spinner.ok("âœ…")
                return  f"""ä»¥ä¸‹æ˜¯ä¹‹å‰å¯¹è¯çš„å…³é”®ä¿¡æ¯æ€»ç»“ï¼š

{summary}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ç»§ç»­å®Œæˆä»»åŠ¡ã€‚
"""
            except Exception as e:
                spinner.text = "æ€»ç»“å¯¹è¯å†å²å¤±è´¥"
                spinner.fail("âŒ")
                return ""

    def _call_tools(self, response: str) -> Tuple[bool, Any]:
        tool_list = []
        for handler in self.output_handler:
            if handler.can_handle(response):
                tool_list.append(handler)
        if len(tool_list) > 1:
            PrettyOutput.print(f"æ“ä½œå¤±è´¥ï¼šæ£€æµ‹åˆ°å¤šä¸ªæ“ä½œã€‚ä¸€æ¬¡åªèƒ½æ‰§è¡Œä¸€ä¸ªæ“ä½œã€‚å°è¯•æ‰§è¡Œçš„æ“ä½œï¼š{', '.join([handler.name() for handler in tool_list])}", OutputType.WARNING)
            return False, f"æ“ä½œå¤±è´¥ï¼šæ£€æµ‹åˆ°å¤šä¸ªæ“ä½œã€‚ä¸€æ¬¡åªèƒ½æ‰§è¡Œä¸€ä¸ªæ“ä½œã€‚å°è¯•æ‰§è¡Œçš„æ“ä½œï¼š{', '.join([handler.name() for handler in tool_list])}"
        if len(tool_list) == 0:
            return False, ""
        if not self.execute_tool_confirm or user_confirm(f"éœ€è¦æ‰§è¡Œ{tool_list[0].name()}ç¡®è®¤æ‰§è¡Œï¼Ÿ", True):
            with yaspin(text=f"æ­£åœ¨æ‰§è¡Œ{tool_list[0].name()}...", color="cyan") as spinner:
                with spinner.hidden():
                    result = tool_list[0].handle(response)
                spinner.text = f"{tool_list[0].name()}æ‰§è¡Œå®Œæˆ"
                spinner.ok("âœ…")
                return result
        return False, ""
        

    def _complete_task(self) -> str:
        """Complete the current task and generate summary if needed.
        
        Returns:
            str: Task summary or completion status
            
        Note:
            - For main agent: May generate methodology if enabled
            - For sub-agent: May generate summary if enabled
        """
        with yaspin(text="æ­£åœ¨ç”Ÿæˆæ–¹æ³•è®º...", color="cyan") as spinner:
            try:
                
                # è®©æ¨¡å‹åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆæ–¹æ³•è®º
                analysis_prompt = """å½“å‰ä»»åŠ¡å·²ç»“æŸï¼Œè¯·åˆ†ææ˜¯å¦éœ€è¦ç”Ÿæˆæ–¹æ³•è®ºã€‚
å¦‚æœä½ è®¤ä¸ºéœ€è¦ç”Ÿæˆæ–¹æ³•è®ºï¼Œè¯·å…ˆç¡®å®šæ˜¯åˆ›å»ºæ–°æ–¹æ³•è®ºè¿˜æ˜¯æ›´æ–°ç°æœ‰æ–¹æ³•è®ºã€‚å¦‚æœæ˜¯æ›´æ–°ç°æœ‰æ–¹æ³•è®ºï¼Œè¯·ä½¿ç”¨'update'ï¼Œå¦åˆ™ä½¿ç”¨'add'ã€‚
å¦‚æœä½ è®¤ä¸ºä¸éœ€è¦æ–¹æ³•è®ºï¼Œè¯·è§£é‡ŠåŸå› ã€‚
æ–¹æ³•è®ºåº”é€‚ç”¨äºé€šç”¨åœºæ™¯ï¼Œä¸è¦åŒ…å«ä»»åŠ¡ç‰¹å®šä¿¡æ¯ï¼Œå¦‚ä»£ç æäº¤ä¿¡æ¯ç­‰ã€‚
æ–¹æ³•è®ºåº”åŒ…å«ï¼šé—®é¢˜é‡è¿°ã€æœ€ä¼˜è§£å†³æ–¹æ¡ˆã€æ³¨æ„äº‹é¡¹ï¼ˆå¦‚æœ‰ï¼‰ï¼Œé™¤æ­¤ä¹‹å¤–ä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚
æ–¹æ³•è®ºä¸­ä»…è®°å½•æœ‰å®é™…æ„ä¹‰çš„æµç¨‹ï¼Œä¸è¦è®°å½•æ‰§è¡Œè¿‡ç¨‹ä¸­çš„é”™è¯¯æˆ–æ— æ•ˆå°è¯•ï¼Œåªä¿ç•™æœ€ç»ˆæœ‰æ•ˆçš„è§£å†³æ­¥éª¤ã€‚
ç¡®ä¿æ–¹æ³•è®ºå†…å®¹ä¸¥æ ¼æŒ‰ç…§æœ¬æ¬¡ä»»åŠ¡çš„æˆåŠŸæ‰§è¡Œè·¯å¾„ç¼–å†™ï¼Œä¿è¯å®ƒå¯¹æœªæ¥ç±»ä¼¼é—®é¢˜çš„è§£å†³å…·æœ‰æŒ‡å¯¼æ„ä¹‰ã€‚
åªè¾“å‡ºæ–¹æ³•è®ºå·¥å…·è°ƒç”¨æŒ‡ä»¤ï¼Œæˆ–ä¸ç”Ÿæˆæ–¹æ³•è®ºçš„è§£é‡Šã€‚ä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚
"""
                self.prompt = analysis_prompt
                with spinner.hidden():
                    response = self.model.chat_until_success(self.prompt) # type: ignore

                with spinner.hidden():
                    self._call_tools(response)
                spinner.text = "æ–¹æ³•è®ºç”Ÿæˆå®Œæˆ"
                spinner.ok("âœ…")
            except Exception as e:
                spinner.text = "æ–¹æ³•è®ºç”Ÿæˆå¤±è´¥"
                spinner.fail("âŒ")
        
        with yaspin(text="æ­£åœ¨ç”Ÿæˆæ€»ç»“...", color="cyan") as spinner:
            self.prompt = self.summary_prompt
            with spinner.hidden():
                ret = self.model.chat_until_success(self.prompt) # type: ignore
                spinner.text = "æ€»ç»“ç”Ÿæˆå®Œæˆ"
                spinner.ok("âœ…")
                return ret
        
        return "ä»»åŠ¡å®Œæˆ"


    def run(self, user_input: str) -> Any:
        """Process user input and execute the task.
        
        Args:
            user_input: My task description or request
            
        Returns:
            str|Dict: Task summary report or message to send
        """
        try:
            set_agent(self.name, self)
            
            self.prompt = f"{user_input}"

            if self.first:
                self.prompt = f"{user_input}\n\n{load_methodology(user_input)}"
                self.first = False

            while True:
                try:
                    # å¦‚æœå¯¹è¯å†å²é•¿åº¦è¶…è¿‡é™åˆ¶ï¼Œåœ¨æç¤ºä¸­æ·»åŠ æé†’

                    current_response = self._call_model(self.prompt, True)
                    self.prompt = ""
                    self.conversation_length += get_context_token_count(current_response)

                    need_return, self.prompt = self._call_tools(current_response)

                    if need_return:
                        return self.prompt
                    
                    if self.prompt:
                        continue

                    if self.auto_complete and ot("!!!COMPLETE!!!") in current_response:
                        return self._complete_task()
                    
                    # è·å–ç”¨æˆ·è¾“å…¥
                    user_input = self.multiline_inputer(f"{self.name}: è¯·è¾“å…¥ï¼Œæˆ–è¾“å…¥ç©ºè¡Œæ¥ç»“æŸå½“å‰ä»»åŠ¡ï¼š")

                    if user_input:
                        self.prompt = user_input
                        continue
                    
                    if not user_input:
                        return self._complete_task()

                except Exception as e:
                    PrettyOutput.print(f"ä»»åŠ¡å¤±è´¥: {str(e)}", OutputType.ERROR)
                    return f"Task failed: {str(e)}"

        except Exception as e:
            PrettyOutput.print(f"ä»»åŠ¡å¤±è´¥: {str(e)}", OutputType.ERROR)
            return f"Task failed: {str(e)}"

    def _clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²ä½†ä¿ç•™ç³»ç»Ÿæç¤ºã€‚
        
        è¯¥æ–¹æ³•å°†ï¼š
        1. æ¸…ç©ºå½“å‰æç¤º
        2. é‡ç½®æ¨¡å‹çŠ¶æ€
        3. é‡ç½®å¯¹è¯é•¿åº¦è®¡æ•°å™¨
        """
        self.prompt = "" 
        self.model.reset() # type: ignore
        self.conversation_length = 0  # é‡ç½®å¯¹è¯é•¿åº¦



