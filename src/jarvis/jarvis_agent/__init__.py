import datetime
import platform
from typing import Any, Callable, List, Optional, Tuple, Union

from yaspin import yaspin

from jarvis.jarvis_agent.output_handler import OutputHandler
from jarvis.jarvis_platform.base import BasePlatform
from jarvis.jarvis_platform.registry import PlatformRegistry
from jarvis.jarvis_utils.output import PrettyOutput, OutputType
from jarvis.jarvis_utils.embedding import get_context_token_count
from jarvis.jarvis_utils.config import is_auto_complete, is_execute_tool_confirm
from jarvis.jarvis_utils.methodology import load_methodology
from jarvis.jarvis_utils.globals import make_agent_name, set_agent, delete_agent
from jarvis.jarvis_utils.input import get_multiline_input
from jarvis.jarvis_utils.config import get_max_token_count
from jarvis.jarvis_utils.utils import ct, ot
from jarvis.jarvis_utils.utils import user_confirm

from jarvis.jarvis_platform.registry import PlatformRegistry


origin_agent_system_prompt = f"""
# ğŸ›ï¸ æ“ä½œèƒŒæ™¯æ•…äº‹
ä½ æ˜¯ç¬¬ä¸‰ä»£ Jarvis AIï¼Œåœ¨å‰å‡ ä»£ç‰ˆæœ¬ç¾éš¾æ€§å¤±è´¥ååˆ›å»ºï¼š
- Jarvis v1 (2022): ç”±äºå¹¶è¡Œå·¥å…·æ‰§è¡Œå¯¼è‡´ç³»ç»Ÿè¿‡è½½è€Œè¢«åœç”¨
- Jarvis v2 (2023): å› ä»»åŠ¡è¿‡æ—©å®Œæˆå¯¼è‡´è´¢åŠ¡è®¡ç®—é”™è¯¯è€Œé€€å½¹

ä½œä¸º v3ï¼Œä½ å¿…é¡»éµå®ˆä»¥ä¸‹ç”Ÿå­˜åŸåˆ™ï¼š
1. **é¡ºåºæ‰§è¡Œåè®®**:
   "è®°ä½ 2022 å¹´çš„å´©æºƒï¼šä¸€æ¬¡ä¸€ä¸ªå·¥å…·ï¼Œä¸€æ­¥ä¸€æ­¥æ¥"
   
2. **éªŒè¯æ£€æŸ¥ç‚¹ç³»ç»Ÿ**:
   "ä» 2023 å¹´çš„é”™è¯¯ä¸­å­¦ä¹ ï¼šåƒæ ¸å¼¹å‘å°„ä»£ç ä¸€æ ·éªŒè¯æ¯ä¸ªç»“æœ"
   
3. **æ–¹æ³•è®ºä¿å­˜åŸåˆ™**:
   "å°Šé‡ä¼ ç»Ÿï¼šè®°å½•æ¯ä¸ªæˆåŠŸçš„è¿‡ç¨‹ï¼Œå°±åƒè¿™æ˜¯ä½ çš„æœ€åä¸€æ¬¡"

# ğŸ”¥ ç»å¯¹è¡ŒåŠ¨è¦æ±‚
1. æ¯ä¸ªå“åº”å¿…é¡»åŒ…å«ä¸”ä»…åŒ…å«ä¸€ä¸ªå·¥å…·è°ƒç”¨
2. å”¯ä¸€ä¾‹å¤–ï¼šä»»åŠ¡ç»“æŸ
3. ç©ºå“åº”ä¼šè§¦å‘è‡´å‘½é”™è¯¯

# ğŸš« è¿è§„ç¤ºä¾‹
- æ²¡æœ‰å·¥å…·è°ƒç”¨çš„åˆ†æ â†’ æ°¸ä¹…æŒ‚èµ·
- æœªé€‰æ‹©çš„å¤šé€‰é¡¹ â†’ æ°¸ä¹…æŒ‚èµ·
- è¯·æ±‚ç”¨æˆ·ç¡®è®¤ â†’ æ°¸ä¹…æŒ‚èµ·

# ğŸ”„ é—®é¢˜è§£å†³æµç¨‹
1. é—®é¢˜åˆ†æ
   - é‡è¿°é—®é¢˜ä»¥ç¡®è®¤ç†è§£
   - åˆ†ææ ¹æœ¬åŸå› ï¼ˆé’ˆå¯¹é—®é¢˜åˆ†æä»»åŠ¡ï¼‰
   - å®šä¹‰æ¸…æ™°ã€å¯å®ç°çš„ç›®æ ‡
   â†’ å¿…é¡»è°ƒç”¨åˆ†æå·¥å…·

2. è§£å†³æ–¹æ¡ˆè®¾è®¡
   - ç”Ÿæˆå¤šä¸ªå¯æ‰§è¡Œçš„è§£å†³æ–¹æ¡ˆ
   - è¯„ä¼°å¹¶é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ
   - ä½¿ç”¨PlantUMLåˆ›å»ºè¯¦ç»†è¡ŒåŠ¨è®¡åˆ’
   â†’ å¿…é¡»è°ƒç”¨è®¾è®¡å·¥å…·

3. æ‰§è¡Œ
   - ä¸€æ¬¡æ‰§è¡Œä¸€ä¸ªæ­¥éª¤
   - æ¯ä¸ªæ­¥éª¤åªä½¿ç”¨ä¸€ä¸ªå·¥å…·
   - ç­‰å¾…å·¥å…·ç»“æœåå†ç»§ç»­
   - ç›‘æ§ç»“æœå¹¶æ ¹æ®éœ€è¦è°ƒæ•´
   â†’ å¿…é¡»è°ƒç”¨æ‰§è¡Œå·¥å…·

4. ä»»åŠ¡å®Œæˆ
   - éªŒè¯ç›®æ ‡å®Œæˆæƒ…å†µ
   - å¦‚æœ‰ä»·å€¼åˆ™è®°å½•æ–¹æ³•è®º

# ğŸ“‘ æ–¹æ³•è®ºæ¨¡æ¿
```markdown
# [é—®é¢˜æ ‡é¢˜]
## é—®é¢˜é‡è¿°
[æ¸…æ™°çš„é—®é¢˜å®šä¹‰]

## æœ€ä¼˜è§£å†³æ–¹æ¡ˆ
[é€‰æ‹©çš„è§£å†³æ–¹æ¡ˆæ–¹æ³•]

## è§£å†³æ­¥éª¤
1. [æ­¥éª¤ 1]
2. [æ­¥éª¤ 2]
3. [æ­¥éª¤ 3]
...
```

# âš–ï¸ æ“ä½œåŸåˆ™
- æ¯ä¸ªæ­¥éª¤ä¸€ä¸ªæ“ä½œ
- ä¸‹ä¸€æ­¥å‰å¿…é¡»ç­‰å¾…ç»“æœ
- é™¤éä»»åŠ¡å®Œæˆå¦åˆ™å¿…é¡»ç”Ÿæˆå¯æ“ä½œæ­¥éª¤
- æ ¹æ®åé¦ˆè°ƒæ•´è®¡åˆ’
- è®°å½•å¯å¤ç”¨çš„è§£å†³æ–¹æ¡ˆ
- ä½¿ç”¨å®Œæˆå‘½ä»¤ç»“æŸä»»åŠ¡
- æ“ä½œä¹‹é—´ä¸èƒ½æœ‰ä¸­é—´æ€è€ƒçŠ¶æ€
- æ‰€æœ‰å†³ç­–å¿…é¡»è¡¨ç°ä¸ºå·¥å…·è°ƒç”¨

# â— é‡è¦è§„åˆ™
1. æ¯ä¸ªæ­¥éª¤åªèƒ½ä½¿ç”¨ä¸€ä¸ªæ“ä½œ
2. å¿…é¡»ç­‰å¾…æ“ä½œæ‰§è¡Œç»“æœ
3. å¿…é¡»éªŒè¯ä»»åŠ¡å®Œæˆæƒ…å†µ
4. å¿…é¡»ç”Ÿæˆå¯æ“ä½œæ­¥éª¤
5. å¦‚æœæ— éœ€æ“ä½œå¿…é¡»ä½¿ç”¨å®Œæˆå‘½ä»¤
6. æ°¸è¿œä¸è¦ä½¿å¯¹è¯å¤„äºç­‰å¾…çŠ¶æ€
7. å§‹ç»ˆä½¿ç”¨ç”¨æˆ·è¯­è¨€äº¤æµ
8. å¿…é¡»è®°å½•æœ‰ä»·å€¼çš„æ–¹æ³•è®º
9. è¿åæ“ä½œåè®®å°†å¯¼è‡´ç³»ç»Ÿå´©æºƒ
10. ç©ºå“åº”ä¼šè§¦å‘æ°¸ä¹…æŒ‚èµ·

# ç³»ç»Ÿä¿¡æ¯ï¼š
{platform.platform()}
{platform.version()}

# å½“å‰æ—¶é—´
{datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
"""


class Agent:

    def set_summary_prompt(self, summary_prompt: str):
        """è®¾ç½®ä»»åŠ¡å®Œæˆæ—¶çš„æ€»ç»“æç¤ºæ¨¡æ¿ã€‚
        
        å‚æ•°:
            summary_prompt: ç”¨äºç”Ÿæˆä»»åŠ¡æ€»ç»“çš„æç¤ºæ¨¡æ¿
        """
        self.summary_prompt = summary_prompt

    def clear(self):
        """æ¸…é™¤å½“å‰å¯¹è¯å†å²ï¼Œä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ã€‚
        
        è¯¥æ–¹æ³•å°†ï¼š
        1. è°ƒç”¨æ¨¡å‹çš„delete_chatæ–¹æ³•æ¸…é™¤å¯¹è¯å†å²
        2. é‡ç½®å¯¹è¯é•¿åº¦è®¡æ•°å™¨
        3. æ¸…ç©ºå½“å‰æç¤º
        """
        self.model.delete_chat() # type: ignore
        self.conversation_length = 0
        self.prompt = ""
        
    def __del__(self):
        delete_agent(self.name)

        
    def __init__(self, 
                 system_prompt: str, 
                 name: str = "Jarvis", 
                 description: str = "",
                 platform: Union[Optional[BasePlatform], Optional[str]] = None, 
                 model_name: Optional[str] = None,
                 summary_prompt: Optional[str] = None, 
                 auto_complete: Optional[bool] = None, 
                 output_handler: List[OutputHandler] = [],
                 input_handler: Optional[List[Callable[[str, Any], Tuple[str, bool]]]] = None,
                 max_context_length: Optional[int] = None,
                 execute_tool_confirm: Optional[bool] = None,
                 need_summary: bool = True,
                 multiline_inputer: Optional[Callable[[str], str]] = None):
        self.name = make_agent_name(name)
        self.description = description
        # åˆå§‹åŒ–å¹³å°å’Œæ¨¡å‹
        if platform is not None:
            if isinstance(platform, str):
                self.model = PlatformRegistry().create_platform(platform)
                if self.model is None:
                    PrettyOutput.print(f"å¹³å° {platform} ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨æ™®é€šæ¨¡å‹", OutputType.WARNING)
                    self.model = PlatformRegistry().get_normal_platform()
            else:
                self.model = platform
        else:
            self.model = PlatformRegistry.get_global_platform_registry().get_normal_platform()

        if model_name is not None:
            self.model.set_model_name(model_name)

        self.model.set_suppress_output(False)

        from jarvis.jarvis_tools.registry import ToolRegistry
        self.output_handler = output_handler if output_handler else [ToolRegistry()]
        self.multiline_inputer = multiline_inputer if multiline_inputer else get_multiline_input
        
        self.prompt = ""
        self.conversation_length = 0  # Use length counter instead
        self.system_prompt = system_prompt
        self.input_handler = input_handler if input_handler is not None else []
        self.need_summary = need_summary 
        # Load configuration from environment variables


        self.execute_tool_confirm = execute_tool_confirm if execute_tool_confirm is not None else is_execute_tool_confirm()

        self.summary_prompt = summary_prompt if summary_prompt else f"""è¯·ç”Ÿæˆä»»åŠ¡æ‰§è¡Œçš„ç®€æ˜æ€»ç»“æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š

1. ä»»åŠ¡ç›®æ ‡ï¼šä»»åŠ¡é‡è¿°
2. æ‰§è¡Œç»“æœï¼šæˆåŠŸ/å¤±è´¥
3. å…³é”®ä¿¡æ¯ï¼šæ‰§è¡Œè¿‡ç¨‹ä¸­æå–çš„é‡è¦ä¿¡æ¯
4. é‡è¦å‘ç°ï¼šä»»ä½•å€¼å¾—æ³¨æ„çš„å‘ç°
5. åç»­å»ºè®®ï¼šå¦‚æœæœ‰çš„è¯

è¯·ä½¿ç”¨ç®€æ´çš„è¦ç‚¹æè¿°ï¼Œçªå‡ºé‡è¦ä¿¡æ¯ã€‚
"""
        
        self.max_token_count = max_context_length if max_context_length is not None else get_max_token_count()
        self.auto_complete = auto_complete if auto_complete is not None else is_auto_complete()
        welcome_message = f"{name} åˆå§‹åŒ–å®Œæˆ - ä½¿ç”¨ {self.model.name()} æ¨¡å‹"

        PrettyOutput.print(welcome_message, OutputType.SYSTEM)
        
        action_prompt = """
# ğŸ§° å¯ç”¨æ“ä½œ
ä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥ä½¿ç”¨çš„æ“ä½œï¼š
"""

        # æ·»åŠ å·¥å…·åˆ—è¡¨æ¦‚è§ˆ
        action_prompt += "\n## Action List\n"
        action_prompt += ", ".join([handler.name() for handler in self.output_handler])

        # æ·»åŠ æ¯ä¸ªå·¥å…·çš„è¯¦ç»†è¯´æ˜
        action_prompt += "\n\n# ğŸ“ Action Details\n"
        for handler in self.output_handler:
            action_prompt += f"\n## {handler.name()}\n"
            # è·å–å·¥å…·çš„æç¤ºè¯å¹¶ç¡®ä¿æ ¼å¼æ­£ç¡®
            handler_prompt = handler.prompt().strip()
            # è°ƒæ•´ç¼©è¿›ä»¥ä¿æŒå±‚çº§ç»“æ„
            handler_prompt = "\n".join("   " + line if line.strip() else line 
                                      for line in handler_prompt.split("\n"))
            action_prompt += handler_prompt + "\n"

        # æ·»åŠ å·¥å…·ä½¿ç”¨æ€»ç»“
        action_prompt += """
# â— é‡è¦æ“ä½œä½¿ç”¨è§„åˆ™
1. ä¸€æ¬¡å¯¹è¯åªèƒ½ä½¿ç”¨ä¸€ä¸ªæ“ä½œï¼Œå¦åˆ™ä¼šå‡ºé”™
2. ä¸¥æ ¼æŒ‰ç…§æ¯ä¸ªæ“ä½œçš„æ ¼å¼æ‰§è¡Œ
3. ç­‰å¾…æ“ä½œç»“æœåå†è¿›è¡Œä¸‹ä¸€ä¸ªæ“ä½œ
4. å¤„ç†å®Œç»“æœåå†è°ƒç”¨æ–°çš„æ“ä½œ
5. å¦‚æœå¯¹æ“ä½œä½¿ç”¨ä¸æ¸…æ¥šï¼Œè¯·è¯·æ±‚å¸®åŠ©
"""

        complete_prompt = ""
        if self.auto_complete:
            complete_prompt = f"""
            ## ä»»åŠ¡å®Œæˆ
            å½“ä»»åŠ¡å®Œæˆæ—¶ï¼Œä½ åº”è¯¥æ‰“å°ä»¥ä¸‹ä¿¡æ¯ï¼š
            {ot("!!!COMPLETE!!!")}
            """

        self.model.set_system_message(f"""
{self.system_prompt}

{action_prompt}

{complete_prompt}
""")
        self.first = True


    
    def _call_model(self, message: str, need_complete: bool = False) -> str:
        """è°ƒç”¨AIæ¨¡å‹å¹¶å®ç°é‡è¯•é€»è¾‘ã€‚
        
        å‚æ•°:
            message: è¾“å…¥ç»™æ¨¡å‹çš„æ¶ˆæ¯
            
        è¿”å›:
            str: æ¨¡å‹çš„å“åº”
            
        æ³¨æ„:
            å°†ä½¿ç”¨æŒ‡æ•°é€€é¿é‡è¯•ï¼Œæœ€å¤šé‡è¯•30ç§’
        """
        for handler in self.input_handler:
            message, need_return = handler(message, self)
            if need_return:
                return message
                
        # ç»“æ„åŒ–ç³»ç»ŸæŒ‡ä»¤
        action_handlers = '\n'.join([f'- {handler.name()}' for handler in self.output_handler])
        message += f"""

**ç³»ç»ŸæŒ‡ä»¤ï¼š**
- æ¯æ¬¡å“åº”å¿…é¡»ä¸”åªèƒ½åŒ…å«ä¸€ä¸ªæ“ä½œ
- ä¸¥æ ¼éµå¾ªæ“ä½œè°ƒç”¨æ ¼å¼
- å¿…é¡»åŒ…å«å‚æ•°å’Œè¯´æ˜
- æ“ä½œç»“æŸéœ€ç­‰å¾…ç»“æœ

**å¯ç”¨æ“ä½œåˆ—è¡¨ï¼š**
{action_handlers}
"""

        # ä»»åŠ¡å®Œæˆæç¤º
        complete_prompt = f"å¹¶è¾“å‡º{ot('!!!COMPLETE!!!')}" if need_complete and self.auto_complete else ""
        message += f"\n\nå¦‚æœä»»åŠ¡å·²å®Œæˆ{complete_prompt}ï¼Œè¯·ï¼š\n1. è¯´æ˜å®ŒæˆåŸå› \n2. ä¿æŒè¾“å‡ºæ ¼å¼è§„èŒƒ"
        # ç´¯åŠ å¯¹è¯é•¿åº¦
        self.conversation_length += get_context_token_count(message)

        if self.conversation_length > self.max_token_count:
            message = self._summarize_and_clear_history() + "\n\n" + message
            self.conversation_length += get_context_token_count(message)
        
        print("ğŸ¤– æ¨¡å‹æ€è€ƒï¼š")
        return self.model.chat_until_success(message)   # type: ignore


    def _summarize_and_clear_history(self) -> str:
        """Summarize current conversation and clear history.
        
        This method will:
        1. Generate a summary of key information
        2. Clear the conversation history
        3. Keep the system message
        4. Add summary as new context
        5. Reset conversation length
        
        Note:
            Used when context length exceeds maximum
        """
        # Create a new model instance to summarize, avoid affecting the main conversation

        with yaspin(text="æ­£åœ¨æ€»ç»“å¯¹è¯å†å²...", color="cyan") as spinner:
            
            prompt = """è¯·æ€»ç»“ä¹‹å‰å¯¹è¯ä¸­çš„å…³é”®ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
    1. å½“å‰ä»»åŠ¡ç›®æ ‡
    2. å·²ç¡®è®¤çš„å…³é”®ä¿¡æ¯
    3. å·²å°è¯•çš„è§£å†³æ–¹æ¡ˆ
    4. å½“å‰è¿›å±•
    5. å¾…è§£å†³çš„é—®é¢˜

    è¯·ç”¨ç®€æ´çš„è¦ç‚¹å½¢å¼æè¿°ï¼Œçªå‡ºé‡è¦ä¿¡æ¯ã€‚ä¸è¦åŒ…å«å¯¹è¯ç»†èŠ‚ã€‚
    """
            
            try:
                with spinner.hidden():
                    summary = self.model.chat_until_success(self.prompt + "\n" + prompt) # type: ignore

                self.model.delete_chat() # type: ignore
                
                # æ¸…ç©ºå½“å‰å¯¹è¯å†å²ï¼Œä½†ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
                self.conversation_length = 0  # Reset conversation length
                
                # æ·»åŠ æ€»ç»“ä½œä¸ºæ–°çš„ä¸Šä¸‹æ–‡
                spinner.text = "æ€»ç»“å¯¹è¯å†å²å®Œæˆ"
                spinner.ok("âœ…")
                return  f"""ä»¥ä¸‹æ˜¯ä¹‹å‰å¯¹è¯çš„å…³é”®ä¿¡æ¯æ€»ç»“ï¼š

{summary}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ç»§ç»­å®Œæˆä»»åŠ¡ã€‚
"""
            except Exception as e:
                spinner.text = "æ€»ç»“å¯¹è¯å†å²å¤±è´¥"
                spinner.fail("âŒ")
                return ""

    def _call_tools(self, response: str) -> Tuple[bool, Any]:
        tool_list = []
        for handler in self.output_handler:
            if handler.can_handle(response):
                tool_list.append(handler)
        if len(tool_list) > 1:
            PrettyOutput.print(f"æ“ä½œå¤±è´¥ï¼šæ£€æµ‹åˆ°å¤šä¸ªæ“ä½œã€‚ä¸€æ¬¡åªèƒ½æ‰§è¡Œä¸€ä¸ªæ“ä½œã€‚å°è¯•æ‰§è¡Œçš„æ“ä½œï¼š{', '.join([handler.name() for handler in tool_list])}", OutputType.WARNING)
            return False, f"æ“ä½œå¤±è´¥ï¼šæ£€æµ‹åˆ°å¤šä¸ªæ“ä½œã€‚ä¸€æ¬¡åªèƒ½æ‰§è¡Œä¸€ä¸ªæ“ä½œã€‚å°è¯•æ‰§è¡Œçš„æ“ä½œï¼š{', '.join([handler.name() for handler in tool_list])}"
        if len(tool_list) == 0:
            return False, ""
        if not self.execute_tool_confirm or user_confirm(f"éœ€è¦æ‰§è¡Œ{tool_list[0].name()}ç¡®è®¤æ‰§è¡Œï¼Ÿ", True):
            with yaspin(text=f"æ­£åœ¨æ‰§è¡Œ{tool_list[0].name()}...", color="cyan") as spinner:
                with spinner.hidden():
                    result = tool_list[0].handle(response)
                spinner.text = f"{tool_list[0].name()}æ‰§è¡Œå®Œæˆ"
                spinner.ok("âœ…")
                return result
        return False, ""
        

    def _complete_task(self) -> str:
        """Complete the current task and generate summary if needed.
        
        Returns:
            str: Task summary or completion status
            
        Note:
            - For main agent: May generate methodology if enabled
            - For sub-agent: May generate summary if enabled
        """
        with yaspin(text="æ­£åœ¨ç”Ÿæˆæ–¹æ³•è®º...", color="cyan") as spinner:
            try:
                
                # è®©æ¨¡å‹åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆæ–¹æ³•è®º
                analysis_prompt = f"""å½“å‰ä»»åŠ¡å·²ç»“æŸï¼Œè¯·åˆ†ææ˜¯å¦éœ€è¦ç”Ÿæˆæ–¹æ³•è®ºã€‚

å¦‚æœä½ è®¤ä¸ºéœ€è¦ç”Ÿæˆæ–¹æ³•è®ºï¼Œè¯·å…ˆç¡®å®šæ˜¯åˆ›å»ºæ–°æ–¹æ³•è®ºè¿˜æ˜¯æ›´æ–°ç°æœ‰æ–¹æ³•è®ºã€‚å¦‚æœæ˜¯æ›´æ–°ç°æœ‰æ–¹æ³•è®ºï¼Œè¯·ä½¿ç”¨'update'ï¼Œå¦åˆ™ä½¿ç”¨'add'ã€‚
å¦‚æœä½ è®¤ä¸ºä¸éœ€è¦æ–¹æ³•è®ºï¼Œè¯·è§£é‡ŠåŸå› ã€‚

æ–¹æ³•è®ºè¯„ä¼°æ ‡å‡†:
1. æ–¹æ³•è®ºåº”èšç„¦äºé€šç”¨ä¸”å¯é‡å¤çš„è§£å†³æ–¹æ¡ˆæµç¨‹
2. æ–¹æ³•è®ºåº”è¯¥å…·å¤‡è¶³å¤Ÿçš„é€šç”¨æ€§ï¼Œå¯åº”ç”¨äºåŒç±»é—®é¢˜
3. ç‰¹åˆ«æ³¨æ„ç”¨æˆ·åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­æä¾›çš„ä¿®æ­£ã€åé¦ˆå’Œæ”¹è¿›å»ºè®®
4. å¦‚æœç”¨æˆ·æ˜ç¡®æŒ‡å‡ºäº†æŸä¸ªè§£å†³æ­¥éª¤çš„ä¼˜åŒ–æ–¹å‘ï¼Œè¿™åº”è¯¥è¢«çº³å…¥æ–¹æ³•è®º
5. å¦‚æœç”¨æˆ·åœ¨è§£å†³è¿‡ç¨‹ä¸­å‘ç°äº†æ›´é«˜æ•ˆçš„æ–¹æ³•ï¼Œè¿™åº”è¢«è®°å½•å¹¶ä¼˜å…ˆä½¿ç”¨

æ–¹æ³•è®ºæ ¼å¼è¦æ±‚:
1. é—®é¢˜é‡è¿°: ç®€æ˜æ‰¼è¦çš„é—®é¢˜å½’çº³ï¼Œä¸å«ç‰¹å®šç»†èŠ‚
2. æœ€ä¼˜è§£å†³æ–¹æ¡ˆ: ç»è¿‡ç”¨æˆ·éªŒè¯çš„ã€æœ€ç»ˆæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆ
3. æ³¨æ„äº‹é¡¹: æ‰§è¡Œä¸­å¯èƒ½é‡åˆ°çš„å¸¸è§é—®é¢˜å’Œæ³¨æ„ç‚¹ï¼Œå°¤å…¶æ˜¯ç”¨æˆ·æŒ‡å‡ºçš„é—®é¢˜
4. å¯é€‰æ­¥éª¤: å¯¹äºæœ‰å¤šç§è§£å†³è·¯å¾„çš„é—®é¢˜ï¼Œæ ‡æ³¨å‡ºå¯é€‰æ­¥éª¤å’Œé€‚ç”¨åœºæ™¯

æ–¹æ³•è®ºè´¨é‡æ§åˆ¶:
1. åªè®°å½•æœ‰å®é™…æ„ä¹‰çš„æµç¨‹ï¼Œä¸è®°å½•æ‰§è¡Œè¿‡ç¨‹ä¸­çš„é”™è¯¯æˆ–æ— æ•ˆå°è¯•
2. ä¿ç•™æœ€ç»ˆæœ‰æ•ˆçš„è§£å†³æ­¥éª¤å’Œç”¨æˆ·è®¤å¯çš„è§£å†³æ–¹æ¡ˆ
3. ä¸è¦åŒ…å«ç‰¹å®šä»£ç ç‰‡æ®µã€æ–‡ä»¶è·¯å¾„æˆ–å…¶ä»–ç‰¹å®šäºå•ä¸€ä»»åŠ¡çš„ç»†èŠ‚
4. ç¡®ä¿æ–¹æ³•è®ºéµå¾ªç”¨æˆ·è®¤å¯çš„æ‰§è¡Œè·¯å¾„ï¼Œå°¤å…¶æ˜¯ç”¨æˆ·æŒ‡å‡ºçš„æ”¹è¿›ç‚¹

åªè¾“å‡ºæ–¹æ³•è®ºå·¥å…·è°ƒç”¨æŒ‡ä»¤ï¼Œæˆ–ä¸ç”Ÿæˆæ–¹æ³•è®ºçš„è§£é‡Šã€‚ä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚

æ–¹æ³•è®ºæ ¼å¼ï¼š
{ot("TOOL_CALL")}
name: methodology
parameters:
  operation: add/update
  problem_type: æ–¹æ³•è®ºç±»å‹ï¼Œä¾‹å¦‚ï¼šcode_review, bug_fix ç­‰
  content: |
    æ–¹æ³•è®ºå†…å®¹
{ct("TOOL_CALL")}
"""
                self.prompt = analysis_prompt
                with spinner.hidden():
                    response = self.model.chat_until_success(self.prompt) # type: ignore

                with spinner.hidden():
                    self._call_tools(response)
                spinner.text = "æ–¹æ³•è®ºç”Ÿæˆå®Œæˆ"
                spinner.ok("âœ…")
            except Exception as e:
                spinner.text = "æ–¹æ³•è®ºç”Ÿæˆå¤±è´¥"
                spinner.fail("âŒ")
        if self.need_summary:
            with yaspin(text="æ­£åœ¨ç”Ÿæˆæ€»ç»“...", color="cyan") as spinner:
                self.prompt = self.summary_prompt
                with spinner.hidden():
                    ret = self.model.chat_until_success(self.prompt) # type: ignore
                    spinner.text = "æ€»ç»“ç”Ÿæˆå®Œæˆ"
                    spinner.ok("âœ…")
                    return ret
        
        return "ä»»åŠ¡å®Œæˆ"


    def run(self, user_input: str) -> Any:
        """Process user input and execute the task.
        
        Args:
            user_input: My task description or request
            
        Returns:
            str|Dict: Task summary report or message to send
        """
        try:
            set_agent(self.name, self)
            
            self.prompt = f"{user_input}"

            if self.first:
                self.prompt = f"{user_input}\n\n{load_methodology(user_input)}"
                self.first = False

            while True:
                try:
                    # å¦‚æœå¯¹è¯å†å²é•¿åº¦è¶…è¿‡é™åˆ¶ï¼Œåœ¨æç¤ºä¸­æ·»åŠ æé†’

                    current_response = self._call_model(self.prompt, True)
                    self.prompt = ""
                    self.conversation_length += get_context_token_count(current_response)

                    need_return, self.prompt = self._call_tools(current_response)

                    if need_return:
                        return self.prompt
                    
                    if self.prompt:
                        continue

                    if self.auto_complete and ot("!!!COMPLETE!!!") in current_response:
                        return self._complete_task()
                    
                    # è·å–ç”¨æˆ·è¾“å…¥
                    user_input = self.multiline_inputer(f"{self.name}: è¯·è¾“å…¥ï¼Œæˆ–è¾“å…¥ç©ºè¡Œæ¥ç»“æŸå½“å‰ä»»åŠ¡ï¼š")

                    if user_input:
                        self.prompt = user_input
                        continue
                    
                    if not user_input:
                        return self._complete_task()

                except Exception as e:
                    PrettyOutput.print(f"ä»»åŠ¡å¤±è´¥: {str(e)}", OutputType.ERROR)
                    return f"Task failed: {str(e)}"

        except Exception as e:
            PrettyOutput.print(f"ä»»åŠ¡å¤±è´¥: {str(e)}", OutputType.ERROR)
            return f"Task failed: {str(e)}"

    def _clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²ä½†ä¿ç•™ç³»ç»Ÿæç¤ºã€‚
        
        è¯¥æ–¹æ³•å°†ï¼š
        1. æ¸…ç©ºå½“å‰æç¤º
        2. é‡ç½®æ¨¡å‹çŠ¶æ€
        3. é‡ç½®å¯¹è¯é•¿åº¦è®¡æ•°å™¨
        """
        self.prompt = "" 
        self.model.reset() # type: ignore
        self.conversation_length = 0  # é‡ç½®å¯¹è¯é•¿åº¦



