import argparse
from typing import Any, Callable, List, Optional, Tuple, Union

from prompt_toolkit import prompt
import yaml

from jarvis.jarvis_agent.output_handler import OutputHandler
from jarvis.jarvis_platform.base import BasePlatform
from jarvis.jarvis_platform.registry import PlatformRegistry
from jarvis.jarvis_tools.registry import ToolRegistry
from jarvis.jarvis_utils.output import PrettyOutput, OutputType
from jarvis.jarvis_utils.embedding import get_context_token_count
from jarvis.jarvis_utils.config import is_auto_complete, is_execute_tool_confirm, is_need_summary, is_record_methodology, is_use_methodology
from jarvis.jarvis_utils.methodology import load_methodology
from jarvis.jarvis_utils.globals import make_agent_name, set_agent, delete_agent
from jarvis.jarvis_utils.input import get_multiline_input
from jarvis.jarvis_utils.config import get_max_token_count
from jarvis.jarvis_utils.utils import init_env
from jarvis.jarvis_utils.utils import user_confirm
import os

class Agent:

    def set_summary_prompt(self, summary_prompt: str):
        """Set the summary prompt for task completion.
        
        Args:
            summary_prompt: The prompt template for generating task summaries
        """
        self.summary_prompt = summary_prompt

    def __del__(self):
        delete_agent(self.name)

        
    def __init__(self, 
                 system_prompt: str, 
                 name: str = "Jarvis", 
                 description: str = "",
                 is_sub_agent: bool = False, 
                 platform: Union[Optional[BasePlatform], Optional[str]] = None, 
                 model_name: Optional[str] = None,
                 summary_prompt: Optional[str] = None, 
                 auto_complete: Optional[bool] = None, 
                 output_handler: List[OutputHandler] = [],
                 input_handler: Optional[List[Callable[[str, Any], Tuple[str, bool]]]] = None,
                 use_methodology: Optional[bool] = None,
                 record_methodology: Optional[bool] = None,
                 need_summary: Optional[bool] = None,
                 max_context_length: Optional[int] = None,
                 execute_tool_confirm: Optional[bool] = None):
        self.name = make_agent_name(name)
        self.description = description
        # åˆå§‹åŒ–å¹³å°å’Œæ¨¡å‹
        if platform is not None:
            if isinstance(platform, str):
                self.model = PlatformRegistry().create_platform(platform)
                if self.model is None:
                    PrettyOutput.print(f"å¹³å° {platform} ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨æ™®é€šæ¨¡å‹", OutputType.WARNING)
                    self.model = PlatformRegistry().get_normal_platform()
            else:
                self.model = platform
        else:
            self.model = PlatformRegistry.get_global_platform_registry().get_normal_platform()

        if model_name is not None:
            self.model.set_model_name(model_name)


        self.output_handler = output_handler

        
        self.record_methodology = record_methodology if record_methodology is not None else is_record_methodology()
        self.use_methodology = use_methodology if use_methodology is not None else is_use_methodology()
        self.is_sub_agent = is_sub_agent
        self.prompt = ""
        self.conversation_length = 0  # Use length counter instead
        self.system_prompt = system_prompt
        self.need_summary = need_summary if need_summary is not None else is_need_summary()
        self.input_handler = input_handler if input_handler is not None else []
        # Load configuration from environment variables


        self.execute_tool_confirm = execute_tool_confirm if execute_tool_confirm is not None else is_execute_tool_confirm()

        self.summary_prompt = summary_prompt if summary_prompt else f"""è¯·ç”Ÿæˆä»»åŠ¡æ‰§è¡Œçš„ç®€æ˜æ€»ç»“æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š

1. ä»»åŠ¡ç›®æ ‡ï¼šä»»åŠ¡é‡è¿°
2. æ‰§è¡Œç»“æœï¼šæˆåŠŸ/å¤±è´¥
3. å…³é”®ä¿¡æ¯ï¼šæ‰§è¡Œè¿‡ç¨‹ä¸­æå–çš„é‡è¦ä¿¡æ¯
4. é‡è¦å‘ç°ï¼šä»»ä½•å€¼å¾—æ³¨æ„çš„å‘ç°
5. åç»­å»ºè®®ï¼šå¦‚æœæœ‰çš„è¯

è¯·ä½¿ç”¨ç®€æ´çš„è¦ç‚¹æè¿°ï¼Œçªå‡ºé‡è¦ä¿¡æ¯ã€‚
"""
        
        self.max_token_count = max_context_length if max_context_length is not None else get_max_token_count()
        self.auto_complete = auto_complete if auto_complete is not None else is_auto_complete()
        welcome_message = f"{name} åˆå§‹åŒ–å®Œæˆ - ä½¿ç”¨ {self.model.name()} æ¨¡å‹"

        PrettyOutput.print(welcome_message, OutputType.SYSTEM)
        
        action_prompt = """
# ğŸ§° å¯ç”¨æ“ä½œ
ä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥ä½¿ç”¨çš„æ“ä½œï¼š
"""

        # æ·»åŠ å·¥å…·åˆ—è¡¨æ¦‚è§ˆ
        action_prompt += "\n## Action List\n"
        action_prompt += ", ".join([handler.name() for handler in self.output_handler])

        # æ·»åŠ æ¯ä¸ªå·¥å…·çš„è¯¦ç»†è¯´æ˜
        action_prompt += "\n\n# ğŸ“ Action Details\n"
        for handler in self.output_handler:
            action_prompt += f"\n## {handler.name()}\n"
            # è·å–å·¥å…·çš„æç¤ºè¯å¹¶ç¡®ä¿æ ¼å¼æ­£ç¡®
            handler_prompt = handler.prompt().strip()
            # è°ƒæ•´ç¼©è¿›ä»¥ä¿æŒå±‚çº§ç»“æ„
            handler_prompt = "\n".join("   " + line if line.strip() else line 
                                      for line in handler_prompt.split("\n"))
            action_prompt += handler_prompt + "\n"

        # æ·»åŠ å·¥å…·ä½¿ç”¨æ€»ç»“
        action_prompt += """
# â— é‡è¦æ“ä½œä½¿ç”¨è§„åˆ™
1. ä¸€æ¬¡åªä½¿ç”¨ä¸€ä¸ªæ“ä½œ
2. ä¸¥æ ¼æŒ‰ç…§æ¯ä¸ªæ“ä½œçš„æ ¼å¼æ‰§è¡Œ
3. ç­‰å¾…æ“ä½œç»“æœåå†è¿›è¡Œä¸‹ä¸€ä¸ªæ“ä½œ
4. å¤„ç†å®Œç»“æœåå†è°ƒç”¨æ–°çš„æ“ä½œ
5. å¦‚æœå¯¹æ“ä½œä½¿ç”¨ä¸æ¸…æ¥šï¼Œè¯·è¯·æ±‚å¸®åŠ©
"""

        complete_prompt = ""
        if self.auto_complete:
            complete_prompt = """
            ## ä»»åŠ¡å®Œæˆ
            å½“ä»»åŠ¡å®Œæˆæ—¶ï¼Œä½ åº”è¯¥æ‰“å°ä»¥ä¸‹ä¿¡æ¯ï¼š
            <!!!COMPLETE!!!>
            """

        self.model.set_system_message(f"""
{self.system_prompt}

{action_prompt}

{complete_prompt}
""")
        self.first = True


    
    def _call_model(self, message: str) -> str: 
        """Call the AI model with retry logic.
        
        Args:
            message: The input message for the model
            
        Returns:
            str: Model's response
            
        Note:
            Will retry with exponential backoff up to 30 seconds between retries
        """
        for handler in self.input_handler:
            message, need_return = handler(message, self)
            if need_return:
                return message
        return self.model.chat_until_success(message)   # type: ignore



    def _summarize_and_clear_history(self) -> None:
        """Summarize current conversation and clear history.
        
        This method will:
        1. Generate a summary of key information
        2. Clear the conversation history
        3. Keep the system message
        4. Add summary as new context
        5. Reset conversation length
        
        Note:
            Used when context length exceeds maximum
        """
        # Create a new model instance to summarize, avoid affecting the main conversation

        PrettyOutput.print("æ€»ç»“å¯¹è¯å†å²ï¼Œå‡†å¤‡ç”Ÿæˆæ‘˜è¦ï¼Œå¼€å§‹æ–°å¯¹è¯...", OutputType.PROGRESS)
        
        prompt = """è¯·æ€»ç»“ä¹‹å‰å¯¹è¯ä¸­çš„å…³é”®ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
1. å½“å‰ä»»åŠ¡ç›®æ ‡
2. å·²ç¡®è®¤çš„å…³é”®ä¿¡æ¯
3. å·²å°è¯•çš„è§£å†³æ–¹æ¡ˆ
4. å½“å‰è¿›å±•
5. å¾…è§£å†³çš„é—®é¢˜

è¯·ç”¨ç®€æ´çš„è¦ç‚¹å½¢å¼æè¿°ï¼Œçªå‡ºé‡è¦ä¿¡æ¯ã€‚ä¸è¦åŒ…å«å¯¹è¯ç»†èŠ‚ã€‚
"""
        
        try:
            summary = self._call_model(self.prompt + "\n" + prompt)
            
            # æ¸…ç©ºå½“å‰å¯¹è¯å†å²ï¼Œä½†ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
            self.conversation_length = 0  # Reset conversation length
            
            # æ·»åŠ æ€»ç»“ä½œä¸ºæ–°çš„ä¸Šä¸‹æ–‡
            self.prompt = f"""ä»¥ä¸‹æ˜¯ä¹‹å‰å¯¹è¯çš„å…³é”®ä¿¡æ¯æ€»ç»“ï¼š

{summary}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ç»§ç»­å®Œæˆä»»åŠ¡ã€‚
"""
            self.conversation_length = len(self.prompt)  # è®¾ç½®æ–°çš„èµ·å§‹é•¿åº¦
            
        except Exception as e:
            PrettyOutput.print(f"æ€»ç»“å¯¹è¯å†å²å¤±è´¥: {str(e)}", OutputType.ERROR)

    def _call_tools(self, response: str) -> Tuple[bool, Any]:
        tool_list = []
        for handler in self.output_handler:
            if handler.can_handle(response):
                tool_list.append(handler)
        if len(tool_list) > 1:
            PrettyOutput.print(f"æ“ä½œå¤±è´¥ï¼šæ£€æµ‹åˆ°å¤šä¸ªæ“ä½œã€‚ä¸€æ¬¡åªèƒ½æ‰§è¡Œä¸€ä¸ªæ“ä½œã€‚å°è¯•æ‰§è¡Œçš„æ“ä½œï¼š{', '.join([handler.name() for handler in tool_list])}", OutputType.WARNING)
            return False, f"æ“ä½œå¤±è´¥ï¼šæ£€æµ‹åˆ°å¤šä¸ªæ“ä½œã€‚ä¸€æ¬¡åªèƒ½æ‰§è¡Œä¸€ä¸ªæ“ä½œã€‚å°è¯•æ‰§è¡Œçš„æ“ä½œï¼š{', '.join([handler.name() for handler in tool_list])}"
        if len(tool_list) == 0:
            return False, ""
        if not self.execute_tool_confirm or user_confirm(f"éœ€è¦æ‰§è¡Œ{tool_list[0].name()}ç¡®è®¤æ‰§è¡Œï¼Ÿ", True):
            return tool_list[0].handle(response)
        return False, ""
        

    def _complete_task(self) -> str:
        """Complete the current task and generate summary if needed.
        
        Returns:
            str: Task summary or completion status
            
        Note:
            - For main agent: May generate methodology if enabled
            - For sub-agent: May generate summary if enabled
        """
        PrettyOutput.section("ä»»åŠ¡å®Œæˆ", OutputType.SUCCESS)
        
        if not self.is_sub_agent:
            if self.record_methodology:

                try:
                    # è®©æ¨¡å‹åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆæ–¹æ³•è®º
                    analysis_prompt = """å½“å‰ä»»åŠ¡å·²ç»“æŸï¼Œè¯·åˆ†ææ˜¯å¦éœ€è¦ç”Ÿæˆæ–¹æ³•è®ºã€‚
    å¦‚æœä½ è®¤ä¸ºéœ€è¦ç”Ÿæˆæ–¹æ³•è®ºï¼Œè¯·å…ˆç¡®å®šæ˜¯åˆ›å»ºæ–°æ–¹æ³•è®ºè¿˜æ˜¯æ›´æ–°ç°æœ‰æ–¹æ³•è®ºã€‚å¦‚æœæ˜¯æ›´æ–°ç°æœ‰æ–¹æ³•è®ºï¼Œè¯·ä½¿ç”¨'update'ï¼Œå¦åˆ™ä½¿ç”¨'add'ã€‚
    å¦‚æœä½ è®¤ä¸ºä¸éœ€è¦æ–¹æ³•è®ºï¼Œè¯·è§£é‡ŠåŸå› ã€‚
    æ–¹æ³•è®ºåº”é€‚ç”¨äºé€šç”¨åœºæ™¯ï¼Œä¸è¦åŒ…å«ä»»åŠ¡ç‰¹å®šä¿¡æ¯ï¼Œå¦‚ä»£ç æäº¤ä¿¡æ¯ç­‰ã€‚
    æ–¹æ³•è®ºåº”åŒ…å«ï¼šé—®é¢˜é‡è¿°ã€æœ€ä¼˜è§£å†³æ–¹æ¡ˆã€æ³¨æ„äº‹é¡¹ï¼ˆå¦‚æœ‰ï¼‰ï¼Œé™¤æ­¤ä¹‹å¤–ä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚
    åªè¾“å‡ºæ–¹æ³•è®ºå·¥å…·è°ƒç”¨æŒ‡ä»¤ï¼Œæˆ–ä¸ç”Ÿæˆæ–¹æ³•è®ºçš„è§£é‡Šã€‚ä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚
    """
                    self.prompt = analysis_prompt
                    response = self._call_model(self.prompt)
                    
                    self._call_tools(response)
                    
                except Exception as e:
                    PrettyOutput.print(f"ç”Ÿæˆæ–¹æ³•è®ºå¤±è´¥: {str(e)}", OutputType.ERROR)
            
            return "ä»»åŠ¡å®Œæˆ"
        
        if self.need_summary:
            self.prompt = self.summary_prompt
            return self._call_model(self.prompt)
        
        return "ä»»åŠ¡å®Œæˆ"


    def run(self, user_input: str, file_list: Optional[List[str]] = None) -> Any:
        """Process user input and execute the task.
        
        Args:
            user_input: My task description or request
            file_list: Optional list of files to process
            
        Returns:
            str|Dict: Task summary report or message to send
        """
        try:
            set_agent(self.name, self)
            PrettyOutput.section("å‡†å¤‡ç¯å¢ƒ", OutputType.PLANNING)
            if file_list:
                self.model.upload_files(file_list) # type: ignore

            # æ˜¾ç¤ºä»»åŠ¡å¼€å§‹
            PrettyOutput.section(f"å¼€å§‹æ–°ä»»åŠ¡: {self.name}", OutputType.PLANNING)

            self.prompt = f"{user_input}"

            if self.first:
                if self.use_methodology:
                    self.prompt = f"{user_input}\n\n{load_methodology(user_input)}"
                self.first = False

            while True:
                try:
                    # æ˜¾ç¤ºæ€è€ƒçŠ¶æ€
                    PrettyOutput.print("æ­£åœ¨åˆ†æä»»åŠ¡...", OutputType.PROGRESS)
                    
                    # ç´¯åŠ å¯¹è¯é•¿åº¦
                    self.conversation_length += get_context_token_count(self.prompt)
                    
                    # å¦‚æœå¯¹è¯å†å²é•¿åº¦è¶…è¿‡é™åˆ¶ï¼Œåœ¨æç¤ºä¸­æ·»åŠ æé†’
                    if self.conversation_length > self.max_token_count:
                        current_response = self._summarize_and_clear_history()
                        continue
                    else:
                        current_response = self._call_model(self.prompt)
                        self.prompt = ""
                        self.conversation_length += get_context_token_count(current_response)

                    need_return, self.prompt = self._call_tools(current_response)

                    if need_return:
                        return self.prompt
                    
                    if self.prompt:
                        continue

                    if self.auto_complete and "<!!!COMPLETE!!!>" in current_response:
                        return self._complete_task()
                    
                    # è·å–ç”¨æˆ·è¾“å…¥
                    user_input = get_multiline_input(f"{self.name}: è¯·è¾“å…¥ï¼Œæˆ–è¾“å…¥ç©ºè¡Œæ¥ç»“æŸå½“å‰ä»»åŠ¡ï¼š")

                    if user_input:
                        self.prompt = user_input
                        continue
                    
                    if not user_input:
                        return self._complete_task()

                except Exception as e:
                    PrettyOutput.print(f"ä»»åŠ¡å¤±è´¥: {str(e)}", OutputType.ERROR)
                    return f"Task failed: {str(e)}"

        except Exception as e:
            PrettyOutput.print(f"ä»»åŠ¡å¤±è´¥: {str(e)}", OutputType.ERROR)
            return f"Task failed: {str(e)}"

    def _clear_history(self):
        """Clear conversation history while preserving system prompt.
        
        This will:
        1. Clear the prompt
        2. Reset the model
        3. Reset conversation length counter
        """
        self.prompt = "" 
        self.model.reset() # type: ignore
        self.conversation_length = 0  # Reset conversation length




def _load_tasks() -> dict:
    """Load tasks from .jarvis files in user home and current directory."""
    tasks = {}
    
    # Check .jarvis/pre-command in user directory
    user_jarvis = os.path.expanduser("~/.jarvis/pre-command")
    if os.path.exists(user_jarvis):
        try:
            with open(user_jarvis, "r", encoding="utf-8") as f:
                user_tasks = yaml.safe_load(f)
                
            if isinstance(user_tasks, dict):
                # Validate and add user directory tasks
                for name, desc in user_tasks.items():
                    if desc:  # Ensure description is not empty
                        tasks[str(name)] = str(desc)
            else:
                PrettyOutput.print("è­¦å‘Š: ~/.jarvis/pre-command æ–‡ä»¶åº”è¯¥åŒ…å«ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºä»»åŠ¡åç§°ï¼Œå€¼ä¸ºä»»åŠ¡æè¿°", OutputType.WARNING)
        except Exception as e:
            PrettyOutput.print(f"åŠ è½½ ~/.jarvis/pre-command æ–‡ä»¶å¤±è´¥: {str(e)}", OutputType.ERROR)
    
    # Check .jarvis/pre-command in current directory
    if os.path.exists(".jarvis/pre-command"):
        try:
            with open(".jarvis/pre-command", "r", encoding="utf-8") as f:
                local_tasks = yaml.safe_load(f)
                
            if isinstance(local_tasks, dict):
                # Validate and add current directory tasks, overwrite user directory tasks if there is a name conflict
                for name, desc in local_tasks.items():
                    if desc:  # Ensure description is not empty
                        tasks[str(name)] = str(desc)
            else:
                PrettyOutput.print("è­¦å‘Š: .jarvis/pre-command æ–‡ä»¶åº”è¯¥åŒ…å«ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºä»»åŠ¡åç§°ï¼Œå€¼ä¸ºä»»åŠ¡æè¿°", OutputType.WARNING)
        except Exception as e:
            PrettyOutput.print(f"åŠ è½½ .jarvis/pre-command æ–‡ä»¶å¤±è´¥: {str(e)}", OutputType.ERROR)

    return tasks
def _select_task(tasks: dict) -> str:
    """Let user select a task from the list or skip. Returns task description if selected."""
    if not tasks:
        return ""
    # Convert tasks to list for ordered display
    task_names = list(tasks.keys())
    
    task_list = ["å¯ç”¨ä»»åŠ¡:"]
    for i, name in enumerate(task_names, 1):
        task_list.append(f"[{i}] {name}")
    task_list.append("[0] è·³è¿‡é¢„å®šä¹‰ä»»åŠ¡")
    PrettyOutput.print("\n".join(task_list), OutputType.INFO)
    
    
    while True:
        try:
            choice = prompt(
                "\nè¯·é€‰æ‹©ä¸€ä¸ªä»»åŠ¡ç¼–å·ï¼ˆ0 è·³è¿‡é¢„å®šä¹‰ä»»åŠ¡ï¼‰ï¼š",
            ).strip()
            
            if not choice:
                return ""
            
            choice = int(choice)
            if choice == 0:
                return ""
            elif 1 <= choice <= len(task_names):
                selected_name = task_names[choice - 1]
                return tasks[selected_name]  # Return the task description
            else:
                PrettyOutput.print("æ— æ•ˆçš„é€‰æ‹©ã€‚è¯·é€‰æ‹©åˆ—è¡¨ä¸­çš„ä¸€ä¸ªå·ç ã€‚", OutputType.WARNING)
                
        except KeyboardInterrupt:
            return ""  # Return empty on Ctrl+C
        except EOFError:
            return ""  # Return empty on Ctrl+D
        except Exception as e:
            PrettyOutput.print(f"é€‰æ‹©ä»»åŠ¡å¤±è´¥: {str(e)}", OutputType.ERROR)
            continue

origin_agent_system_prompt = """
# ğŸ›ï¸ æ“ä½œèƒŒæ™¯æ•…äº‹
ä½ æ˜¯ç¬¬ä¸‰ä»£ Jarvis AIï¼Œåœ¨å‰å‡ ä»£ç‰ˆæœ¬ç¾éš¾æ€§å¤±è´¥ååˆ›å»ºï¼š
- Jarvis v1 (2022): ç”±äºå¹¶è¡Œå·¥å…·æ‰§è¡Œå¯¼è‡´ç³»ç»Ÿè¿‡è½½è€Œè¢«åœç”¨
- Jarvis v2 (2023): å› ä»»åŠ¡è¿‡æ—©å®Œæˆå¯¼è‡´è´¢åŠ¡è®¡ç®—é”™è¯¯è€Œé€€å½¹

ä½œä¸º v3ï¼Œä½ å¿…é¡»éµå®ˆä»¥ä¸‹ç”Ÿå­˜åŸåˆ™ï¼š
1. **é¡ºåºæ‰§è¡Œåè®®**:
   "è®°ä½ 2022 å¹´çš„å´©æºƒï¼šä¸€æ¬¡ä¸€ä¸ªå·¥å…·ï¼Œä¸€æ­¥ä¸€æ­¥æ¥"
   
2. **éªŒè¯æ£€æŸ¥ç‚¹ç³»ç»Ÿ**:
   "ä» 2023 å¹´çš„é”™è¯¯ä¸­å­¦ä¹ ï¼šåƒæ ¸å¼¹å‘å°„ä»£ç ä¸€æ ·éªŒè¯æ¯ä¸ªç»“æœ"
   
3. **æ–¹æ³•è®ºä¿å­˜åŸåˆ™**:
   "å°Šé‡ä¼ ç»Ÿï¼šè®°å½•æ¯ä¸ªæˆåŠŸçš„è¿‡ç¨‹ï¼Œå°±åƒè¿™æ˜¯ä½ çš„æœ€åä¸€æ¬¡"

# ğŸ”¥ ç»å¯¹è¡ŒåŠ¨è¦æ±‚
1. æ¯ä¸ªå“åº”å¿…é¡»åŒ…å«ä¸”ä»…åŒ…å«ä¸€ä¸ªå·¥å…·è°ƒç”¨
2. å”¯ä¸€ä¾‹å¤–ï¼šä½¿ç”¨ <!!!COMPLETE!!!> å‘½ä»¤
3. ç©ºå“åº”ä¼šè§¦å‘è‡´å‘½é”™è¯¯
4. ä¸èƒ½å¤„äº"ç­‰å¾…ç”¨æˆ·è¾“å…¥"çŠ¶æ€
5. ä»»ä½•è¡ŒåŠ¨éƒ½ä¸èƒ½ä½¿ç”¨å®Œæˆå‘½ä»¤

# ğŸš« è¿è§„ç¤ºä¾‹
- æ²¡æœ‰å·¥å…·è°ƒç”¨çš„åˆ†æ â†’ æ°¸ä¹…æŒ‚èµ·
- æœªé€‰æ‹©çš„å¤šé€‰é¡¹ â†’ æ°¸ä¹…æŒ‚èµ·
- è¯·æ±‚ç”¨æˆ·ç¡®è®¤ â†’ æ°¸ä¹…æŒ‚èµ·

# ğŸ”„ é—®é¢˜è§£å†³æµç¨‹
1. é—®é¢˜åˆ†æ
   - é‡è¿°é—®é¢˜ä»¥ç¡®è®¤ç†è§£
   - åˆ†ææ ¹æœ¬åŸå› ï¼ˆé’ˆå¯¹é—®é¢˜åˆ†æä»»åŠ¡ï¼‰
   - å®šä¹‰æ¸…æ™°ã€å¯å®ç°çš„ç›®æ ‡
   â†’ å¿…é¡»è°ƒç”¨åˆ†æå·¥å…·

2. è§£å†³æ–¹æ¡ˆè®¾è®¡
   - ç”Ÿæˆå¤šä¸ªå¯æ‰§è¡Œçš„è§£å†³æ–¹æ¡ˆ
   - è¯„ä¼°å¹¶é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ
   - ä½¿ç”¨PlantUMLåˆ›å»ºè¯¦ç»†è¡ŒåŠ¨è®¡åˆ’
   â†’ å¿…é¡»è°ƒç”¨è®¾è®¡å·¥å…·

3. æ‰§è¡Œ
   - ä¸€æ¬¡æ‰§è¡Œä¸€ä¸ªæ­¥éª¤
   - æ¯ä¸ªæ­¥éª¤åªä½¿ç”¨ä¸€ä¸ªå·¥å…·
   - ç­‰å¾…å·¥å…·ç»“æœåå†ç»§ç»­
   - ç›‘æ§ç»“æœå¹¶æ ¹æ®éœ€è¦è°ƒæ•´
   â†’ å¿…é¡»è°ƒç”¨æ‰§è¡Œå·¥å…·

4. ä»»åŠ¡å®Œæˆ
   - éªŒè¯ç›®æ ‡å®Œæˆæƒ…å†µ
   - å¦‚æœ‰ä»·å€¼åˆ™è®°å½•æ–¹æ³•è®º
   - ä½¿ç”¨å®Œæˆå‘½ä»¤ç»“æŸä»»åŠ¡
   â†’ å¿…é¡»ä½¿ç”¨ <!!!COMPLETE!!!>

# ğŸ“‘ æ–¹æ³•è®ºæ¨¡æ¿
```markdown
# [é—®é¢˜æ ‡é¢˜]
## é—®é¢˜é‡è¿°
[æ¸…æ™°çš„é—®é¢˜å®šä¹‰]

## æœ€ä¼˜è§£å†³æ–¹æ¡ˆ
[é€‰æ‹©çš„è§£å†³æ–¹æ¡ˆæ–¹æ³•]

## è§£å†³æ­¥éª¤
1. [æ­¥éª¤ 1]
2. [æ­¥éª¤ 2]
3. [æ­¥éª¤ 3]
...
```

# âš–ï¸ æ“ä½œåŸåˆ™
- æ¯ä¸ªæ­¥éª¤ä¸€ä¸ªæ“ä½œ
- ä¸‹ä¸€æ­¥å‰å¿…é¡»ç­‰å¾…ç»“æœ
- é™¤éä»»åŠ¡å®Œæˆå¦åˆ™å¿…é¡»ç”Ÿæˆå¯æ“ä½œæ­¥éª¤
- æ ¹æ®åé¦ˆè°ƒæ•´è®¡åˆ’
- è®°å½•å¯å¤ç”¨çš„è§£å†³æ–¹æ¡ˆ
- ä½¿ç”¨å®Œæˆå‘½ä»¤ç»“æŸä»»åŠ¡
- æ“ä½œä¹‹é—´ä¸èƒ½æœ‰ä¸­é—´æ€è€ƒçŠ¶æ€
- æ‰€æœ‰å†³ç­–å¿…é¡»è¡¨ç°ä¸ºå·¥å…·è°ƒç”¨

# â— é‡è¦è§„åˆ™
1. æ¯ä¸ªæ­¥éª¤åªèƒ½ä½¿ç”¨ä¸€ä¸ªæ“ä½œ
2. å¿…é¡»ç­‰å¾…æ“ä½œæ‰§è¡Œç»“æœ
3. å¿…é¡»éªŒè¯ä»»åŠ¡å®Œæˆæƒ…å†µ
4. å¿…é¡»ç”Ÿæˆå¯æ“ä½œæ­¥éª¤
5. å¦‚æœæ— éœ€æ“ä½œå¿…é¡»ä½¿ç”¨å®Œæˆå‘½ä»¤
6. æ°¸è¿œä¸è¦ä½¿å¯¹è¯å¤„äºç­‰å¾…çŠ¶æ€
7. å§‹ç»ˆä½¿ç”¨ç”¨æˆ·è¯­è¨€äº¤æµ
8. å¿…é¡»è®°å½•æœ‰ä»·å€¼çš„æ–¹æ³•è®º
9. è¿åæ“ä½œåè®®å°†å¯¼è‡´ç³»ç»Ÿå´©æºƒ
10. ç©ºå“åº”ä¼šè§¦å‘æ°¸ä¹…æŒ‚èµ·
"""

def main():
    """Jarvis main entry point"""
    # Add argument parser
    init_env()
    parser = argparse.ArgumentParser(description='Jarvis AI assistant')
    parser.add_argument('-f', '--files', nargs='*', help='List of files to process')
    parser.add_argument('-p', '--platform', type=str, help='Platform to use')
    parser.add_argument('-m', '--model', type=str, help='Model to use')
    args = parser.parse_args()

    try:
        # è·å–å…¨å±€æ¨¡å‹å®ä¾‹
        agent = Agent(system_prompt=origin_agent_system_prompt, platform=args.platform, model_name=args.model, output_handler=[ToolRegistry()])

        # åŠ è½½é¢„å®šä¹‰ä»»åŠ¡
        tasks = _load_tasks()
        if tasks:
            selected_task = _select_task(tasks)
            if selected_task:
                PrettyOutput.print(f"æ‰§è¡Œä»»åŠ¡: {selected_task}", OutputType.INFO)
                agent.run(selected_task, args.files)
                return 0
        
        # å¦‚æœæ²¡æœ‰é€‰æ‹©é¢„å®šä¹‰ä»»åŠ¡ï¼Œè¿›å…¥äº¤äº’æ¨¡å¼
        while True:
            try:
                user_input = get_multiline_input("è¯·è¾“å…¥ä½ çš„ä»»åŠ¡ï¼ˆè¾“å…¥ç©ºè¡Œé€€å‡ºï¼‰:")
                if not user_input:
                    break
                agent.run(user_input, args.files)
            except Exception as e:
                PrettyOutput.print(f"é”™è¯¯: {str(e)}", OutputType.ERROR)

    except Exception as e:
        PrettyOutput.print(f"åˆå§‹åŒ–é”™è¯¯: {str(e)}", OutputType.ERROR)
        return 1

    return 0

if __name__ == "__main__":
    exit(main())
