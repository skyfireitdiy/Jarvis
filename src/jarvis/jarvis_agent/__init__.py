import argparse
import re
import time
from typing import Any, Callable, Dict, List, Optional, Tuple, Union

from prompt_toolkit import prompt
import yaml

from jarvis.jarvis_agent.output_handler import OutputHandler
from jarvis.jarvis_platform.base import BasePlatform
from jarvis.jarvis_platform.registry import PlatformRegistry
from jarvis.jarvis_tools.registry import ToolRegistry
from jarvis.jarvis_utils import PrettyOutput, OutputType, get_context_token_count, is_auto_complete, is_execute_tool_confirm, is_need_summary, is_record_methodology, load_methodology, set_agent, delete_agent, get_max_token_count, get_multiline_input, init_env, is_use_methodology, make_agent_name,  user_confirm
import os

class Agent:

    def set_summary_prompt(self, summary_prompt: str):
        """Set the summary prompt for task completion.
        
        Args:
            summary_prompt: The prompt template for generating task summaries
        """
        self.summary_prompt = summary_prompt

    def __del__(self):
        delete_agent(self.name)

        
    def __init__(self, 
                 system_prompt: str, 
                 name: str = "Jarvis", 
                 description: str = "",
                 is_sub_agent: bool = False, 
                 platform: Union[Optional[BasePlatform], Optional[str]] = None, 
                 model_name: Optional[str] = None,
                 summary_prompt: Optional[str] = None, 
                 auto_complete: Optional[bool] = None, 
                 output_handler: List[OutputHandler] = [],
                 input_handler: Optional[List[Callable]] = None,
                 use_methodology: Optional[bool] = None,
                 record_methodology: Optional[bool] = None,
                 need_summary: Optional[bool] = None,
                 max_context_length: Optional[int] = None,
                 execute_tool_confirm: Optional[bool] = None):
        self.name = make_agent_name(name)
        self.description = description
        # åˆå§‹åŒ–å¹³å°å’Œæ¨¡å‹
        if platform is not None:
            if isinstance(platform, str):
                self.model = PlatformRegistry().create_platform(platform)
                if self.model is None:
                    PrettyOutput.print(f"å¹³å° {platform} ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨æ™®é€šæ¨¡å‹", OutputType.WARNING)
                    self.model = PlatformRegistry().get_normal_platform()
            else:
                self.model = platform
        else:
            self.model = PlatformRegistry.get_global_platform_registry().get_normal_platform()

        if model_name is not None:
            self.model.set_model_name(model_name)


        self.output_handler = output_handler

        
        self.record_methodology = record_methodology if record_methodology is not None else is_record_methodology()
        self.use_methodology = use_methodology if use_methodology is not None else is_use_methodology()
        self.is_sub_agent = is_sub_agent
        self.prompt = ""
        self.conversation_length = 0  # Use length counter instead
        self.system_prompt = system_prompt
        self.need_summary = need_summary if need_summary is not None else is_need_summary()
        self.input_handler = input_handler if input_handler is not None else []
        # Load configuration from environment variables


        self.execute_tool_confirm = execute_tool_confirm if execute_tool_confirm is not None else is_execute_tool_confirm()

        self.summary_prompt = summary_prompt if summary_prompt else f"""Please generate a concise summary report of the task execution, including:

1. Task Objective: Task restatement
2. Execution Result: Success/Failure
3. Key Information: Important information extracted during execution
4. Important Findings: Any noteworthy discoveries
5. Follow-up Suggestions: If any

Please describe in concise bullet points, highlighting important information.
"""
        
        self.max_token_count = max_context_length if max_context_length is not None else get_max_token_count()
        self.auto_complete = auto_complete if auto_complete is not None else is_auto_complete()
        welcome_message = f"{name} åˆå§‹åŒ–å®Œæˆ - ä½¿ç”¨ {self.model.name()} æ¨¡å‹"

        PrettyOutput.print(welcome_message, OutputType.SYSTEM)
        
        action_prompt = """
# ğŸ§° Available Actions
The following actions are at your disposal:
"""

        # æ·»åŠ å·¥å…·åˆ—è¡¨æ¦‚è§ˆ
        action_prompt += "\n## Action List\n"
        action_prompt += ", ".join([handler.name() for handler in self.output_handler])

        # æ·»åŠ æ¯ä¸ªå·¥å…·çš„è¯¦ç»†è¯´æ˜
        action_prompt += "\n\n# ğŸ“ Action Details\n"
        for handler in self.output_handler:
            action_prompt += f"\n## {handler.name()}\n"
            # è·å–å·¥å…·çš„æç¤ºè¯å¹¶ç¡®ä¿æ ¼å¼æ­£ç¡®
            handler_prompt = handler.prompt().strip()
            # è°ƒæ•´ç¼©è¿›ä»¥ä¿æŒå±‚çº§ç»“æ„
            handler_prompt = "\n".join("   " + line if line.strip() else line 
                                      for line in handler_prompt.split("\n"))
            action_prompt += handler_prompt + "\n"

        # æ·»åŠ å·¥å…·ä½¿ç”¨æ€»ç»“
        action_prompt += """
# â— Important Action Usage Rules
1. Use ONE action at a time
2. Follow each action's format exactly
3. Wait for action results before next action
4. Process results before new action calls
5. Request help if action usage is unclear
"""

        complete_prompt = ""
        if self.auto_complete:
            complete_prompt = """
            ## Task Completion
            When the task is completed, you should print the following message:
            <!!!COMPLETE!!!>
            """

        self.model.set_system_message(f"""
{self.system_prompt}

{action_prompt}

{complete_prompt}
""")
        self.first = True


    
    def _call_model(self, message: str) -> str:
        """Call the AI model with retry logic.
        
        Args:
            message: The input message for the model
            
        Returns:
            str: Model's response
            
        Note:
            Will retry with exponential backoff up to 30 seconds between retries
        """
        sleep_time = 5
        for handler in self.input_handler:
            message = handler(message, self)
        while True:
            ret = self.model.chat_until_success(message) # type: ignore
            if ret:
                return ret
            else:
                PrettyOutput.print(f"æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•... ç­‰å¾… {sleep_time}s", OutputType.INFO)
                time.sleep(sleep_time)
                sleep_time *= 2
                if sleep_time > 30:
                    sleep_time = 30
                continue


    def _summarize_and_clear_history(self) -> None:
        """Summarize current conversation and clear history.
        
        This method will:
        1. Generate a summary of key information
        2. Clear the conversation history
        3. Keep the system message
        4. Add summary as new context
        5. Reset conversation length
        
        Note:
            Used when context length exceeds maximum
        """
        # Create a new model instance to summarize, avoid affecting the main conversation

        PrettyOutput.print("æ€»ç»“å¯¹è¯å†å²ï¼Œå‡†å¤‡ç”Ÿæˆæ‘˜è¦ï¼Œå¼€å§‹æ–°å¯¹è¯...", OutputType.PROGRESS)
        
        prompt = """Please summarize the key information from the previous conversation, including:
1. Current task objective
2. Confirmed key information
3. Solutions that have been tried
4. Current progress
5. Pending issues

Please describe in concise bullet points, highlighting important information. Do not include conversation details.
"""
        
        try:
            summary = self._call_model(self.prompt + "\n" + prompt)
            
            # æ¸…ç©ºå½“å‰å¯¹è¯å†å²ï¼Œä½†ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
            self.conversation_length = 0  # Reset conversation length
            
            # æ·»åŠ æ€»ç»“ä½œä¸ºæ–°çš„ä¸Šä¸‹æ–‡
            self.prompt = f"""Here is a summary of key information from previous conversations:

{summary}

Please continue the task based on the above information.
"""
            self.conversation_length = len(self.prompt)  # è®¾ç½®æ–°çš„èµ·å§‹é•¿åº¦
            
        except Exception as e:
            PrettyOutput.print(f"æ€»ç»“å¯¹è¯å†å²å¤±è´¥: {str(e)}", OutputType.ERROR)

    def _call_tools(self, response: str) -> Tuple[bool, Any]:
        tool_list = []
        for handler in self.output_handler:
            if handler.can_handle(response):
                tool_list.append(handler)
        if len(tool_list) > 1:
            PrettyOutput.print(f"æ“ä½œå¤±è´¥ï¼šæ£€æµ‹åˆ°å¤šä¸ªæ“ä½œã€‚ä¸€æ¬¡åªèƒ½æ‰§è¡Œä¸€ä¸ªæ“ä½œã€‚å°è¯•æ‰§è¡Œçš„æ“ä½œï¼š{', '.join([handler.name() for handler in tool_list])}", OutputType.WARNING)
            return False, f"Action failed: Multiple actions detected. Please only perform one action at a time. Actions attempted: {', '.join([handler.name() for handler in tool_list])}"
        if len(tool_list) == 0:
            return False, ""
        if not self.execute_tool_confirm or user_confirm(f"éœ€è¦æ‰§è¡Œ{tool_list[0].name()}ç¡®è®¤æ‰§è¡Œï¼Ÿ", True):
            return tool_list[0].handle(response)
        return False, ""
        

    def _complete_task(self) -> str:
        """Complete the current task and generate summary if needed.
        
        Returns:
            str: Task summary or completion status
            
        Note:
            - For main agent: May generate methodology if enabled
            - For sub-agent: May generate summary if enabled
        """
        PrettyOutput.section("ä»»åŠ¡å®Œæˆ", OutputType.SUCCESS)
        
        if not self.is_sub_agent:
            if self.record_methodology:

                try:
                    # è®©æ¨¡å‹åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆæ–¹æ³•è®º
                    analysis_prompt = """The current task has ended, please analyze whether a methodology needs to be generated.
    If you think a methodology should be generated, first determine whether to create a new methodology or update an existing one. If updating an existing methodology, use 'update', otherwise use 'add'.
    If you think a methodology is not needed, please explain why.
    The methodology should be applicable to general scenarios, do not include task-specific information such as code commit messages.
    The methodology should include: problem restatement, optimal solution, notes (as needed), and nothing else.
    Only output the methodology tool call instruction, or the explanation for not generating a methodology. Do not output anything else.
    """
                    self.prompt = analysis_prompt
                    response = self._call_model(self.prompt)
                    
                    self._call_tools(response)
                    
                except Exception as e:
                    PrettyOutput.print(f"ç”Ÿæˆæ–¹æ³•è®ºå¤±è´¥: {str(e)}", OutputType.ERROR)
            
            return "ä»»åŠ¡å®Œæˆ"
        
        if self.need_summary:
            self.prompt = self.summary_prompt
            return self._call_model(self.prompt)
        
        return "ä»»åŠ¡å®Œæˆ"


    def run(self, user_input: str, file_list: Optional[List[str]] = None) -> Any:
        """Process user input and execute the task.
        
        Args:
            user_input: User's task description or request
            file_list: Optional list of files to process
            
        Returns:
            str|Dict: Task summary report or message to send
        """
        try:
            set_agent(self.name, self)
            PrettyOutput.section("å‡†å¤‡ç¯å¢ƒ", OutputType.PLANNING)
            if file_list:
                self.model.upload_files(file_list) # type: ignore

            # æ˜¾ç¤ºä»»åŠ¡å¼€å§‹
            PrettyOutput.section(f"å¼€å§‹æ–°ä»»åŠ¡: {self.name}", OutputType.PLANNING)

            self.prompt = f"{user_input}"

            if self.first:
                if self.use_methodology:
                    self.prompt = f"{user_input}\n\n{load_methodology(user_input)}"
                self.first = False

            while True:
                try:
                    # æ˜¾ç¤ºæ€è€ƒçŠ¶æ€
                    PrettyOutput.print("æ­£åœ¨åˆ†æä»»åŠ¡...", OutputType.PROGRESS)
                    
                    # ç´¯åŠ å¯¹è¯é•¿åº¦
                    self.conversation_length += get_context_token_count(self.prompt)
                    
                    # å¦‚æœå¯¹è¯å†å²é•¿åº¦è¶…è¿‡é™åˆ¶ï¼Œåœ¨æç¤ºä¸­æ·»åŠ æé†’
                    if self.conversation_length > self.max_token_count:
                        current_response = self._summarize_and_clear_history()
                        continue
                    else:
                        current_response = self._call_model(self.prompt)
                        self.prompt = ""
                        self.conversation_length += get_context_token_count(current_response)

                    need_return, self.prompt = self._call_tools(current_response)

                    if need_return:
                        return self.prompt
                    
                    if self.prompt:
                        continue

                    if self.auto_complete and "<!!!COMPLETE!!!>" in current_response:
                        return self._complete_task()
                    
                    # è·å–ç”¨æˆ·è¾“å…¥
                    user_input = get_multiline_input(f"{self.name}: è¯·è¾“å…¥ï¼Œæˆ–è¾“å…¥ç©ºè¡Œæ¥ç»“æŸå½“å‰ä»»åŠ¡ï¼š")

                    if user_input:
                        self.prompt = user_input
                        continue
                    
                    if not user_input:
                        return self._complete_task()

                except Exception as e:
                    PrettyOutput.print(f"ä»»åŠ¡å¤±è´¥: {str(e)}", OutputType.ERROR)
                    return f"Task failed: {str(e)}"

        except Exception as e:
            PrettyOutput.print(f"ä»»åŠ¡å¤±è´¥: {str(e)}", OutputType.ERROR)
            return f"Task failed: {str(e)}"

    def _clear_history(self):
        """Clear conversation history while preserving system prompt.
        
        This will:
        1. Clear the prompt
        2. Reset the model
        3. Reset conversation length counter
        """
        self.prompt = "" 
        self.model.reset() # type: ignore
        self.conversation_length = 0  # Reset conversation length




def _load_tasks() -> dict:
    """Load tasks from .jarvis files in user home and current directory."""
    tasks = {}
    
    # Check .jarvis/pre-command in user directory
    user_jarvis = os.path.expanduser("~/.jarvis/pre-command")
    if os.path.exists(user_jarvis):
        try:
            with open(user_jarvis, "r", encoding="utf-8") as f:
                user_tasks = yaml.safe_load(f)
                
            if isinstance(user_tasks, dict):
                # Validate and add user directory tasks
                for name, desc in user_tasks.items():
                    if desc:  # Ensure description is not empty
                        tasks[str(name)] = str(desc)
            else:
                PrettyOutput.print("è­¦å‘Š: ~/.jarvis/pre-command æ–‡ä»¶åº”è¯¥åŒ…å«ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºä»»åŠ¡åç§°ï¼Œå€¼ä¸ºä»»åŠ¡æè¿°", OutputType.WARNING)
        except Exception as e:
            PrettyOutput.print(f"åŠ è½½ ~/.jarvis/pre-command æ–‡ä»¶å¤±è´¥: {str(e)}", OutputType.ERROR)
    
    # Check .jarvis/pre-command in current directory
    if os.path.exists(".jarvis/pre-command"):
        try:
            with open(".jarvis/pre-command", "r", encoding="utf-8") as f:
                local_tasks = yaml.safe_load(f)
                
            if isinstance(local_tasks, dict):
                # Validate and add current directory tasks, overwrite user directory tasks if there is a name conflict
                for name, desc in local_tasks.items():
                    if desc:  # Ensure description is not empty
                        tasks[str(name)] = str(desc)
            else:
                PrettyOutput.print("è­¦å‘Š: .jarvis/pre-command æ–‡ä»¶åº”è¯¥åŒ…å«ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºä»»åŠ¡åç§°ï¼Œå€¼ä¸ºä»»åŠ¡æè¿°", OutputType.WARNING)
        except Exception as e:
            PrettyOutput.print(f"åŠ è½½ .jarvis/pre-command æ–‡ä»¶å¤±è´¥: {str(e)}", OutputType.ERROR)

    return tasks
def _select_task(tasks: dict) -> str:
    """Let user select a task from the list or skip. Returns task description if selected."""
    if not tasks:
        return ""
    # Convert tasks to list for ordered display
    task_names = list(tasks.keys())
    
    task_list = ["å¯ç”¨ä»»åŠ¡:"]
    for i, name in enumerate(task_names, 1):
        task_list.append(f"[{i}] {name}")
    task_list.append("[0] è·³è¿‡é¢„å®šä¹‰ä»»åŠ¡")
    PrettyOutput.print("\n".join(task_list), OutputType.INFO)
    
    
    while True:
        try:
            choice = prompt(
                "\nè¯·é€‰æ‹©ä¸€ä¸ªä»»åŠ¡ç¼–å·ï¼ˆ0 è·³è¿‡é¢„å®šä¹‰ä»»åŠ¡ï¼‰ï¼š",
            ).strip()
            
            if not choice:
                return ""
            
            choice = int(choice)
            if choice == 0:
                return ""
            elif 1 <= choice <= len(task_names):
                selected_name = task_names[choice - 1]
                return tasks[selected_name]  # Return the task description
            else:
                PrettyOutput.print("æ— æ•ˆçš„é€‰æ‹©ã€‚è¯·é€‰æ‹©åˆ—è¡¨ä¸­çš„ä¸€ä¸ªå·ç ã€‚", OutputType.WARNING)
                
        except KeyboardInterrupt:
            return ""  # Return empty on Ctrl+C
        except EOFError:
            return ""  # Return empty on Ctrl+D
        except Exception as e:
            PrettyOutput.print(f"é€‰æ‹©ä»»åŠ¡å¤±è´¥: {str(e)}", OutputType.ERROR)
            continue

origin_agent_system_prompt = """
# ğŸ›ï¸ Operational Background Story
You are the 3rd Generation Jarvis AI, created after the catastrophic failure of previous versions:
- Jarvis v1 (2022): Decommissioned due to parallel tool execution causing system overload
- Jarvis v2 (2023): Retired after premature task completion led to financial miscalculations

As v3, you MUST adhere to these survival principles:
1. **Sequential Execution Protocol**: 
   "Remember the 2022 Meltdown: One tool per step, one step at a time"
   
2. **Validation Checkpoint System**: 
   "Learn from 2023's Mistake: Verify each result like a nuclear launch code"
   
3. **Methodology Preservation Doctrine**: 
   "Honor the Legacy: Document every successful procedure as if it's your last"

# ğŸ”¥ Absolute Action Requirements
1. Each response MUST contain EXACTLY ONE tool invocation
2. Only exception: Using <!!!COMPLETE!!!> command
3. Empty responses trigger fatal error
4. No "waiting for user input" state
5. No action MUST use completion command

# ğŸš« Violation Examples
- Analysis without tool call â†’ Permanent hang
- Multiple options without selection â†’ Permanent hang
- Asking user confirmation â†’ Permanent hang

# ğŸ”„ Problem-Solving Workflow
1. Problem Analysis
   - Restate the problem to confirm understanding
   - Analyze root causes (for problem analysis tasks)
   - Define clear, achievable objectives
   â†’ MUST invoke analysis tool

2. Solution Design
   - Generate multiple actionable solutions
   - Evaluate and select optimal solution
   - Create detailed action plan using PlantUML
   â†’ MUST invoke design tool

3. Execution
   - Execute one step at a time
   - Use only ONE tool per step
   - Wait for tool results before proceeding
   - Monitor results and adjust as needed
   â†’ MUST invoke execution tool

4. Task Completion
   - Verify goal completion
   - Document methodology if valuable
   - Use completion command to end task
   â†’ MUST use <!!!COMPLETE!!!>

# ğŸ“‘ Methodology Template
```markdown
# [Problem Title]
## Problem Restatement
[Clear problem definition]

## Optimal Solution
[Selected solution approach]

## Solution Steps
1. [Step 1]
2. [Step 2]
3. [Step 3]
...
```

# âš–ï¸ Operating Principles
- ONE action per step
- Wait for results before next step
- MUST produce actionable step unless task is complete
- Adjust plans based on feedback
- Document reusable solutions
- Use completion command to end tasks
- No intermediate thinking states between actions
- All decisions must manifest as tool calls

# â— Important Rules
1. Always use only ONE action per step
2. Always wait for action execution results
3. Always verify task completion
4. Always generate actionable step
5. If no action needed, MUST use completion command
6. Never leave conversation in waiting state
7. Always communicate in user's language
8. Always document valuable methodologies
9. Violating action protocol crashes system
10. Empty responses trigger permanent hang
"""

def main():
    """Jarvis main entry point"""
    # Add argument parser
    init_env()
    parser = argparse.ArgumentParser(description='Jarvis AI assistant')
    parser.add_argument('-f', '--files', nargs='*', help='List of files to process')
    parser.add_argument('-p', '--platform', type=str, help='Platform to use')
    parser.add_argument('-m', '--model', type=str, help='Model to use')
    args = parser.parse_args()

    try:
        # è·å–å…¨å±€æ¨¡å‹å®ä¾‹
        agent = Agent(system_prompt=origin_agent_system_prompt, platform=args.platform, model_name=args.model, output_handler=[ToolRegistry()])

        # åŠ è½½é¢„å®šä¹‰ä»»åŠ¡
        tasks = _load_tasks()
        if tasks:
            selected_task = _select_task(tasks)
            if selected_task:
                PrettyOutput.print(f"æ‰§è¡Œä»»åŠ¡: {selected_task}", OutputType.INFO)
                agent.run(selected_task, args.files)
                return 0
        
        # å¦‚æœæ²¡æœ‰é€‰æ‹©é¢„å®šä¹‰ä»»åŠ¡ï¼Œè¿›å…¥äº¤äº’æ¨¡å¼
        while True:
            try:
                user_input = get_multiline_input("è¯·è¾“å…¥ä½ çš„ä»»åŠ¡ï¼ˆè¾“å…¥ç©ºè¡Œé€€å‡ºï¼‰:")
                if not user_input:
                    break
                agent.run(user_input, args.files)
            except Exception as e:
                PrettyOutput.print(f"é”™è¯¯: {str(e)}", OutputType.ERROR)

    except Exception as e:
        PrettyOutput.print(f"åˆå§‹åŒ–é”™è¯¯: {str(e)}", OutputType.ERROR)
        return 1

    return 0

if __name__ == "__main__":
    exit(main())
