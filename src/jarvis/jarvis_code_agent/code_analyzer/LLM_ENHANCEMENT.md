# LLM实现的上下文推荐功能

## 概述

上下文推荐功能**完全基于LLM实现**，不依赖硬编码规则。相比硬编码的规则匹配，LLM能够：

1. **理解语义**：理解用户意图的真实含义，而不仅仅是关键词匹配
2. **提取实体**：更准确地提取目标文件、符号、概念等
3. **语义搜索**：在代码库中进行语义搜索，找到真正相关的代码
4. **相关性评分**：对推荐结果进行智能评分和排序

## 架构设计

### 纯LLM实现

```
用户输入
    ↓
LLM意图提取
    ↓
基于依赖关系的推荐（代码结构分析）
    ↓
LLM语义搜索
    ↓
LLM相关性评分
    ↓
最终推荐结果
```

**设计特点**：
- **完全基于LLM**：所有语义理解都通过LLM实现
- **代码结构辅助**：结合依赖关系图等代码结构信息
- **智能排序**：使用LLM评分而非简单规则

### 工作流程

```
用户输入
    ↓
LLM意图提取（提取目标文件、符号、意图、关键词）
    ↓
基于依赖关系的推荐（依赖文件、被依赖文件、测试文件）
    ↓
LLM语义搜索（查找更多相关符号和文件）
    ↓
LLM相关性评分（对推荐结果评分和排序）
    ↓
最终推荐结果
```

## LLM增强功能

### 1. 意图提取

使用LLM从用户输入中提取结构化信息：

**输入**：用户任务描述
**输出**：JSON格式的结构化信息
```json
{
    "intent": "fix_bug",
    "target_files": ["src/main.py"],
    "target_symbols": ["process_data", "validate_input"],
    "keywords": ["data processing", "validation", "error handling"],
    "description": "修复数据处理函数中的验证逻辑错误"
}
```

**优势**：
- 理解自然语言描述
- 提取隐含的目标文件和符号
- 识别编辑意图类型

### 2. 语义搜索

使用LLM在代码库中进行语义搜索：

#### 符号语义搜索
- 输入：任务描述 + 关键词 + 符号列表
- LLM分析：哪些符号与任务最相关
- 输出：按相关性排序的符号列表

#### 文件语义搜索
- 输入：任务描述 + 关键词 + 文件列表
- LLM分析：哪些文件与任务最相关
- 输出：按相关性排序的文件列表

**优势**：
- 理解代码的语义含义
- 找到名称不匹配但功能相关的代码
- 考虑上下文和关联性

### 3. 相关性评分

使用LLM对推荐结果进行相关性评分：

#### 文件评分
- 输入：任务描述 + 文件列表
- LLM评分：每个文件与任务的相关性（0-10分）
- 输出：按分数排序的文件列表

#### 符号评分
- 输入：任务描述 + 符号列表
- LLM评分：每个符号与任务的相关性（0-10分）
- 输出：按分数排序的符号列表

**优势**：
- 智能排序，最相关的排在前面
- 过滤低相关性结果
- 提供更精准的推荐

## 实现细节

### LLM调用接口

支持多种LLM接口：
1. `chat_until_success()` - BasePlatform标准接口（优先）
2. `call()` - 通用调用接口
3. `generate()` - 生成接口

### 错误处理

- **LLM调用失败**：自动回退到基础推荐器
- **JSON解析失败**：使用默认值，不影响主流程
- **超时处理**：设置合理的超时时间

### 性能优化

1. **限制输入规模**：
   - 符号列表：最多50个
   - 文件列表：最多30个
   - 评分列表：最多20个

2. **缓存机制**：
   - 利用ContextManager的缓存
   - 避免重复的LLM调用

3. **批量处理**：
   - 一次LLM调用处理多个项目
   - 减少API调用次数

## 使用方式

### 自动集成

LLM推荐器已自动集成到CodeAgent中：

```python
agent = CodeAgent()
agent.run("修复数据处理函数中的空指针异常")
```

系统会自动：
1. 检测Agent是否有LLM模型
2. 如果有，自动启用上下文推荐功能
3. 如果没有，跳过上下文推荐功能（不影响主流程）

### 手动使用

```python
from jarvis.jarvis_code_agent.code_analyzer import (
    ContextManager,
    ContextRecommender
)

# 初始化
context_manager = ContextManager(project_root)
llm_model = agent.model  # 获取LLM模型

# 创建推荐器（需要LLM模型）
recommender = ContextRecommender(
    context_manager,
    llm_model=llm_model
)

# 生成推荐
recommendation = recommender.recommend_context(
    user_input="修复数据处理函数中的bug",
    target_files=["src/main.py"],
)
```

## LLM实现的优势

### 相比硬编码规则

**硬编码规则的局限性**：
- ❌ 只能基于关键词匹配
- ❌ 无法理解语义
- ❌ 可能遗漏语义相关但名称不匹配的代码
- ❌ 无法理解上下文和关联性

**LLM实现的优势**：
- ✅ 理解语义，推荐更准确
- ✅ 能提取隐含的目标
- ✅ 智能排序和过滤
- ✅ 理解代码的语义含义

### 性能考虑

**LLM调用的影响**：
- 需要LLM调用，速度较慢（但通常<5秒）
- 依赖LLM服务可用性
- 可能有API调用成本

**优化措施**：
- 限制输入规模（符号/文件列表）
- 批量处理，减少调用次数
- 错误处理，失败不影响主流程

## 配置选项

### 启用/禁用

上下文推荐功能会自动检测LLM模型是否可用：
- **有LLM模型**：自动启用上下文推荐功能
- **无LLM模型**：跳过上下文推荐功能（不影响主流程）

### 性能调优

可以通过以下方式优化性能：

1. **减少LLM调用**：
   - 只在必要时使用LLM
   - 缓存LLM结果

2. **限制输入规模**：
   - 调整符号/文件列表大小限制
   - 使用更精确的筛选条件

3. **并行处理**：
   - 可以并行调用多个LLM请求（如果支持）

## 示例

### 示例1：语义理解

**用户输入**：
```
"修复用户登录时的验证问题"
```

**基础推荐器**：
- 搜索包含"用户"、"登录"、"验证"关键词的文件
- 可能遗漏：`auth.py`, `session_manager.py` 等语义相关但名称不匹配的文件

**LLM增强推荐器**：
- 理解"用户登录验证"的语义
- 推荐：`auth.py`, `login_handler.py`, `session_manager.py`, `user_validator.py` 等
- 更准确地找到相关代码

### 示例2：意图识别

**用户输入**：
```
"优化数据库查询性能"
```

**基础推荐器**：
- 识别为"modify"意图
- 推荐所有包含"数据库"、"查询"关键词的文件

**LLM增强推荐器**：
- 识别为"optimize"意图
- 推荐：数据库访问层、查询优化相关文件、性能测试文件
- 更精准的推荐策略

### 示例3：相关性评分

**基础推荐器**：
- 所有推荐文件同等重要
- 按文件路径长度排序

**LLM增强推荐器**：
- 对每个文件进行相关性评分
- 最相关的文件排在前面
- 过滤低相关性文件（< 5分）

## 未来改进

1. **向量化搜索**：使用代码嵌入向量进行语义搜索
2. **增量更新**：在文件修改后增量更新推荐
3. **学习用户偏好**：根据历史编辑记录学习推荐偏好
4. **多模型支持**：支持不同的LLM模型和配置
5. **缓存优化**：缓存LLM结果，减少重复调用

## 总结

LLM实现的上下文推荐功能通过完全基于LLM的语义理解，提供了更智能、更准确的上下文推荐。它能够：

- ✅ 理解用户意图的真实含义（而非关键词匹配）
- ✅ 提取隐含的目标文件和符号
- ✅ 进行语义搜索，找到真正相关的代码
- ✅ 智能评分和排序推荐结果
- ✅ 优雅降级，LLM不可用时跳过功能（不影响主流程）

这使得Agent能够获得更好的上下文信息，做出更准确的编辑决策。完全基于LLM的实现确保了推荐的准确性和智能性，避免了硬编码规则无法理解语义的问题。

