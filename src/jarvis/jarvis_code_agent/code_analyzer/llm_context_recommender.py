"""æ™ºèƒ½ä¸Šä¸‹æ–‡æ¨èå™¨ã€‚

ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰ç†è§£ï¼Œæä¾›æ›´å‡†ç¡®çš„ä¸Šä¸‹æ–‡æ¨èã€‚
å®Œå…¨åŸºäºLLMå®ç°ï¼Œä¸ä¾èµ–ç¡¬ç¼–ç è§„åˆ™ã€‚
"""


import os
import re
import yaml
from typing import List, Optional, Dict, Any, Set

from jarvis.jarvis_utils.output import OutputType, PrettyOutput

from .context_recommender import ContextRecommendation
from .context_manager import ContextManager
from .file_ignore import filter_walk_dirs
from .symbol_extractor import Symbol


class ContextRecommender:
    """æ™ºèƒ½ä¸Šä¸‹æ–‡æ¨èå™¨ã€‚
    
    ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰ç†è§£ï¼Œæ ¹æ®ç¼–è¾‘æ„å›¾æ¨èç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
    å®Œå…¨åŸºäºLLMå®ç°ï¼Œæä¾›è¯­ä¹‰çº§åˆ«çš„æ¨èï¼Œè€Œéç®€å•çš„å…³é”®è¯åŒ¹é…ã€‚
    """

    def __init__(self, context_manager: ContextManager, llm_model: Any):
        """åˆå§‹åŒ–ä¸Šä¸‹æ–‡æ¨èå™¨
        
        Args:
            context_manager: ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            llm_model: LLMæ¨¡å‹å®ä¾‹ï¼ˆå¿…éœ€ï¼‰
            
        Raises:
            ValueError: å¦‚æœæœªæä¾›LLMæ¨¡å‹
        """
        self.context_manager = context_manager
        self.llm_model = llm_model
        
        if not llm_model:
            raise ValueError("LLM model is required for context recommendation")

    def recommend_context(
        self,
        user_input: str,
    ) -> ContextRecommendation:
        """æ ¹æ®ç¼–è¾‘æ„å›¾æ¨èä¸Šä¸‹æ–‡
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥/ä»»åŠ¡æè¿°
            
        Returns:
            ContextRecommendation: æ¨èçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        # 1. ä½¿ç”¨LLMæå–å…³é”®è¯ï¼ˆä»…æå–å…³é”®è¯ï¼‰
        keywords = self._extract_keywords_with_llm(user_input)
        
        # 2. åˆå§‹åŒ–æ¨èç»“æœ
        recommended_files: Set[str] = set()
        recommended_symbols: List[Symbol] = []
        related_tests: Set[str] = set()
        reasons: List[str] = []

        # 3. åŸºäºå…³é”®è¯è¿›è¡Œç¬¦å·æŸ¥æ‰¾å’Œæ–‡æœ¬æŸ¥æ‰¾ï¼Œç„¶åä½¿ç”¨LLMæŒ‘é€‰å…³è”åº¦é«˜çš„æ¡ç›®ï¼ˆä¸»è¦æ¨èæ–¹å¼ï¼‰
        if keywords:
            # 3.1 ä½¿ç”¨å…³é”®è¯è¿›è¡Œç¬¦å·æŸ¥æ‰¾å’Œæ–‡æœ¬æŸ¥æ‰¾ï¼Œæ‰¾åˆ°æ‰€æœ‰å€™é€‰ç¬¦å·åŠå…¶ä½ç½®
            candidate_symbols = self._search_symbols_by_keywords(keywords)
            candidate_symbols_from_text = self._search_text_by_keywords(keywords)
            
            # åˆå¹¶å€™é€‰ç¬¦å·ï¼ˆå»é‡ï¼‰
            all_candidates = {}
            for symbol in candidate_symbols + candidate_symbols_from_text:
                # ä½¿ç”¨ (file_path, name, line_start) ä½œä¸ºå”¯ä¸€é”®
                key = (symbol.file_path, symbol.name, symbol.line_start)
                if key not in all_candidates:
                    all_candidates[key] = symbol
            
            candidate_symbols_list = list(all_candidates.values())
            
            # 3.2 ä½¿ç”¨LLMä»å€™é€‰ç¬¦å·ä¸­æŒ‘é€‰å…³è”åº¦é«˜çš„æ¡ç›®
            if candidate_symbols_list:
                selected_symbols = self._select_relevant_symbols_with_llm(
                    user_input, keywords, candidate_symbols_list
                )
                recommended_symbols.extend(selected_symbols)
                
                # ä»é€‰ä¸­çš„ç¬¦å·ä¸­æå–æ–‡ä»¶
                for symbol in selected_symbols:
                    recommended_files.add(symbol.file_path)
                
                if selected_symbols:
                    reasons.append(f"åŸºäºå…³é”®è¯ï¼ˆ{', '.join(keywords[:5])}ï¼‰çš„ç¬¦å·æŸ¥æ‰¾ä¸LLMç­›é€‰")

        # 4. ä½¿ç”¨LLMå¯¹æ¨èç»“æœè¿›è¡Œç›¸å…³æ€§è¯„åˆ†å’Œæ’åº
        file_scores = self._score_files_with_llm(
            user_input,
            list(recommended_files),
        )
        scored_symbols = self._score_symbols_with_llm(
            user_input,
            recommended_symbols,
        )
        
        # 5. è¿‡æ»¤å’Œæ’åº
        # æŒ‰è¯„åˆ†å’Œä¿®æ”¹æ—¶é—´å¯¹æ–‡ä»¶æ’åºï¼Œå¹¶é€‰æ‹©æœ€ç›¸å…³çš„10ä¸ª
        if file_scores:
            final_files = sorted(
                list(recommended_files),
                key=lambda f: (file_scores.get(f, 5.0), os.path.getmtime(f)),
                reverse=True
            )[:10]
        else:
            final_files = sorted(list(recommended_files), key=os.path.getmtime, reverse=True)[:10]
        
        final_symbols = [s for s, _ in sorted(scored_symbols.items(), key=lambda x: x[1], reverse=True)[:10]]
        
        # 6. æ›´æ–°æ¨èåŸå› 
        reason = "ï¼›".join(reasons[:3]) if reasons else "åŸºäºLLMå…³é”®è¯è¯­ä¹‰åˆ†æ"
        if len(reasons) > 3:
            reason += f" ç­‰{len(reasons)}ä¸ªåŸå› "
        if keywords:
            reason = f"åŸºäºå…³é”®è¯ï¼ˆ{', '.join(keywords[:5])}ï¼‰çš„LLMè¯­ä¹‰åˆ†æï¼›{reason}"

        return ContextRecommendation(
            recommended_files=final_files,
            recommended_symbols=final_symbols,
            related_tests=list(related_tests),
            reason=reason,
        )

    def _extract_keywords_with_llm(self, user_input: str) -> List[str]:
        """ä½¿ç”¨LLMæå–å…³é”®è¯ï¼ˆä»…æå–å…³é”®è¯ï¼‰
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        prompt = f"""åˆ†æä»¥ä¸‹ä»£ç ç¼–è¾‘ä»»åŠ¡ï¼Œæå–å…³é”®è¯ã€‚å…³é”®è¯åº”è¯¥æ˜¯ä¸ä»»åŠ¡ç›¸å…³çš„æ ¸å¿ƒæ¦‚å¿µã€æŠ€æœ¯æœ¯è¯­ã€åŠŸèƒ½æ¨¡å—ç­‰ã€‚

ä»»åŠ¡æè¿°ï¼š
{user_input}

è¯·æå–5-10ä¸ªå…³é”®è¯ï¼Œä»¥YAMLæ•°ç»„æ ¼å¼è¿”å›ï¼Œå¹¶ç”¨<KEYWORDS>æ ‡ç­¾åŒ…è£¹ã€‚
åªè¿”å›å…³é”®è¯æ•°ç»„ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚

ç¤ºä¾‹æ ¼å¼ï¼š
<KEYWORDS>
- data processing
- validation
- error handling
- API endpoint
- authentication
</KEYWORDS>
"""

        try:
            response = self._call_llm(prompt)
            # ä»<KEYWORDS>æ ‡ç­¾ä¸­æå–å†…å®¹
            response = response.strip()
            yaml_match = re.search(r'<KEYWORDS>\s*(.*?)\s*</KEYWORDS>', response, re.DOTALL)
            if yaml_match:
                yaml_content = yaml_match.group(1).strip()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾ï¼Œå°è¯•æ¸…ç†markdownä»£ç å—
                if response.startswith("```yaml"):
                    response = response[7:]
                elif response.startswith("```"):
                    response = response[3:]
                if response.endswith("```"):
                    response = response[:-3]
                yaml_content = response.strip()
            
            keywords = yaml.safe_load(yaml_content)
            if not isinstance(keywords, list):
                return []
            
            # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²å’Œè¿‡çŸ­çš„å…³é”®è¯
            keywords = [k.strip() for k in keywords if k and isinstance(k, str) and len(k.strip()) > 1]
            return keywords
        except Exception as e:
            # è§£æå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
            PrettyOutput.print(f"LLMå…³é”®è¯æå–å¤±è´¥: {e}", OutputType.WARNING)
            return []

    def _search_symbols_by_keywords(self, keywords: List[str]) -> List[Symbol]:
        """åŸºäºå…³é”®è¯åœ¨ç¬¦å·è¡¨ä¸­æŸ¥æ‰¾ç›¸å…³ç¬¦å·
        
        Args:
            keywords: å…³é”®è¯åˆ—è¡¨
            
        Returns:
            å€™é€‰ç¬¦å·åˆ—è¡¨
        """
        if not keywords:
            return []
        
        found_symbols: List[Symbol] = []
        keywords_lower = [k.lower() for k in keywords]
        found_symbol_keys = set()  # ç”¨äºå»é‡ï¼Œä½¿ç”¨ (file_path, name, line_start) ä½œä¸ºé”®
        
        # éå†æ‰€æœ‰ç¬¦å·ï¼ŒæŸ¥æ‰¾åç§°æˆ–ç­¾åä¸­åŒ…å«å…³é”®è¯çš„ç¬¦å·
        for symbol_name, symbols in self.context_manager.symbol_table.symbols_by_name.items():
            symbol_name_lower = symbol_name.lower()
            
            # æ£€æŸ¥ç¬¦å·åç§°æ˜¯å¦åŒ…å«ä»»ä½•å…³é”®è¯
            name_matched = False
            for keyword in keywords_lower:
                if keyword in symbol_name_lower:
                    # æ‰¾åˆ°åŒ¹é…çš„ç¬¦å·ï¼Œæ·»åŠ æ‰€æœ‰åŒåç¬¦å·ï¼ˆå¯èƒ½æœ‰é‡è½½ï¼‰
                    for symbol in symbols:
                        key = (symbol.file_path, symbol.name, symbol.line_start)
                        if key not in found_symbol_keys:
                            found_symbols.append(symbol)
                            found_symbol_keys.add(key)
                    name_matched = True
                    break
            
            # å¦‚æœåç§°ä¸åŒ¹é…ï¼Œæ£€æŸ¥ç¬¦å·ç­¾åæ˜¯å¦åŒ…å«å…³é”®è¯
            if not name_matched:
                for symbol in symbols:
                    if symbol.signature:
                        signature_lower = symbol.signature.lower()
                        for keyword in keywords_lower:
                            if keyword in signature_lower:
                                key = (symbol.file_path, symbol.name, symbol.line_start)
                                if key not in found_symbol_keys:
                                    found_symbols.append(symbol)
                                    found_symbol_keys.add(key)
                                break
        
        return found_symbols

    def _search_text_by_keywords(self, keywords: List[str]) -> List[Symbol]:
        """åŸºäºå…³é”®è¯åœ¨æ–‡ä»¶å†…å®¹ä¸­è¿›è¡Œæ–‡æœ¬æŸ¥æ‰¾ï¼Œæ‰¾åˆ°ç›¸å…³ç¬¦å·
        
        Args:
            keywords: å…³é”®è¯åˆ—è¡¨
            
        Returns:
            å€™é€‰ç¬¦å·åˆ—è¡¨ï¼ˆåœ¨åŒ…å«å…³é”®è¯çš„æ–‡ä»¶ä¸­æ‰¾åˆ°çš„ç¬¦å·ï¼‰
        """
        if not keywords:
            return []
        
        found_symbols: List[Symbol] = []
        keywords_lower = [k.lower() for k in keywords]
        
        # è·å–æ‰€æœ‰å·²åˆ†æçš„æ–‡ä»¶
        all_files = set()
        for symbol_name, symbols in self.context_manager.symbol_table.symbols_by_name.items():
            for symbol in symbols:
                all_files.add(symbol.file_path)
        
        # åœ¨æ–‡ä»¶å†…å®¹ä¸­æœç´¢å…³é”®è¯
        for file_path in all_files:
            content = self.context_manager._get_file_content(file_path)
            if not content:
                continue
            
            content_lower = content.lower()
            
            # æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦åŒ…å«ä»»ä½•å…³é”®è¯
            file_matches = False
            for keyword in keywords_lower:
                if keyword in content_lower:
                    file_matches = True
                    break
            
            if file_matches:
                # è·å–è¯¥æ–‡ä»¶ä¸­çš„æ‰€æœ‰ç¬¦å·
                file_symbols = self.context_manager.symbol_table.get_file_symbols(file_path)
                found_symbols.extend(file_symbols)
        
        return found_symbols

    def _select_relevant_symbols_with_llm(
        self, user_input: str, keywords: List[str], candidate_symbols: List[Symbol]
    ) -> List[Symbol]:
        """ä½¿ç”¨LLMä»å€™é€‰ç¬¦å·ä¸­æŒ‘é€‰å…³è”åº¦é«˜çš„æ¡ç›®
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥/ä»»åŠ¡æè¿°
            keywords: å…³é”®è¯åˆ—è¡¨
            candidate_symbols: å€™é€‰ç¬¦å·åˆ—è¡¨ï¼ˆåŒ…å«ä½ç½®ä¿¡æ¯ï¼‰
            
        Returns:
            é€‰ä¸­çš„ç¬¦å·åˆ—è¡¨
        """
        if not candidate_symbols:
            return []
        
        # é™åˆ¶å€™é€‰ç¬¦å·æ•°é‡ï¼Œé¿å…promptè¿‡é•¿
        candidates_to_consider = candidate_symbols[:100]  # æœ€å¤š100ä¸ªå€™é€‰
        
        # æ„å»ºå¸¦ç¼–å·çš„ç¬¦å·ä¿¡æ¯åˆ—è¡¨ï¼ˆåŒ…å«ä½ç½®ä¿¡æ¯ï¼‰
        symbol_info_list = []
        for idx, symbol in enumerate(candidates_to_consider, start=1):
            symbol_info = {
                "åºå·": idx,
                "name": symbol.name,
                "kind": symbol.kind,
                "file": os.path.relpath(symbol.file_path, self.context_manager.project_root),
                "line": symbol.line_start,
                "signature": symbol.signature or "",
            }
            symbol_info_list.append(symbol_info)
        
        prompt = f"""æ ¹æ®ä»¥ä¸‹ä»»åŠ¡æè¿°å’Œå…³é”®è¯ï¼Œä»å€™é€‰ç¬¦å·åˆ—è¡¨ä¸­é€‰æ‹©æœ€ç›¸å…³çš„ç¬¦å·ã€‚

ä»»åŠ¡æè¿°ï¼š{user_input}
å…³é”®è¯ï¼š{', '.join(keywords)}

å€™é€‰ç¬¦å·åˆ—è¡¨ï¼ˆå·²ç¼–å·ï¼ŒåŒ…å«ä½ç½®ä¿¡æ¯ï¼‰ï¼š
{yaml.dump(symbol_info_list, allow_unicode=True, default_flow_style=False)}

è¯·è¿”å›æœ€ç›¸å…³çš„10-20ä¸ªç¬¦å·çš„åºå·ï¼ˆYAMLæ•°ç»„æ ¼å¼ï¼‰ï¼ŒæŒ‰ç›¸å…³æ€§æ’åºï¼Œå¹¶ç”¨<SELECTED_INDICES>æ ‡ç­¾åŒ…è£¹ã€‚

åªè¿”å›åºå·æ•°ç»„ï¼Œä¾‹å¦‚ï¼š
<SELECTED_INDICES>
- 3
- 7
- 12
- 15
- 23
</SELECTED_INDICES>
"""

        try:
            response = self._call_llm(prompt)
            # ä»<SELECTED_INDICES>æ ‡ç­¾ä¸­æå–å†…å®¹
            response = response.strip()
            yaml_match = re.search(r'<SELECTED_INDICES>\s*(.*?)\s*</SELECTED_INDICES>', response, re.DOTALL)
            if yaml_match:
                yaml_content = yaml_match.group(1).strip()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾ï¼Œå°è¯•æ¸…ç†markdownä»£ç å—
                if response.startswith("```yaml"):
                    response = response[7:]
                elif response.startswith("```"):
                    response = response[3:]
                if response.endswith("```"):
                    response = response[:-3]
                yaml_content = response.strip()
            
            selected_indices = yaml.safe_load(yaml_content)
            if not isinstance(selected_indices, list):
                return []
            
            # æ ¹æ®åºå·æŸ¥æ‰¾å¯¹åº”çš„ç¬¦å·å¯¹è±¡
            selected_symbols = []
            for idx in selected_indices:
                # åºå·ä»1å¼€å§‹ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
                if isinstance(idx, int) and 1 <= idx <= len(candidates_to_consider):
                    symbol = candidates_to_consider[idx - 1]
                    selected_symbols.append(symbol)
            
            return selected_symbols
        except Exception as e:
            # è§£æå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
            PrettyOutput.print(f"LLMç¬¦å·ç­›é€‰å¤±è´¥: {e}", OutputType.WARNING)
            return []

    def _semantic_search_files(
        self, user_input: str, keywords: List[str]
    ) -> List[str]:
        """ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰æœç´¢ï¼ŒæŸ¥æ‰¾ç›¸å…³æ–‡ä»¶
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            keywords: å…³é”®è¯åˆ—è¡¨
            
        Returns:
            ç›¸å…³æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        # è·å–é¡¹ç›®ä¸­çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼Œåªè·å–å·²åˆ†æçš„æ–‡ä»¶ï¼‰
        known_files = list(self.context_manager.dependency_graph.dependencies.keys())
        known_files.extend(self.context_manager.dependency_graph.dependents.keys())
        
        if not known_files:
            return []
        
        # é™åˆ¶æ–‡ä»¶æ•°é‡
        files_sample = known_files[:30]  # æœ€å¤š30ä¸ªæ–‡ä»¶
        
        file_info = [
            {
                "path": os.path.relpath(f, self.context_manager.project_root),
                "basename": os.path.basename(f),
            }
            for f in files_sample
        ]
        
        prompt = f"""æ ¹æ®ä»¥ä¸‹ä»»åŠ¡æè¿°å’Œå…³é”®è¯ï¼Œä»æ–‡ä»¶åˆ—è¡¨ä¸­é€‰æ‹©æœ€ç›¸å…³çš„æ–‡ä»¶ã€‚

ä»»åŠ¡æè¿°ï¼š{user_input}
å…³é”®è¯ï¼š{', '.join(keywords)}

æ–‡ä»¶åˆ—è¡¨ï¼š
{yaml.dump(file_info, allow_unicode=True, default_flow_style=False)}

è¯·è¿”å›æœ€ç›¸å…³çš„5-10ä¸ªæ–‡ä»¶è·¯å¾„ï¼ˆYAMLæ•°ç»„æ ¼å¼ï¼‰ï¼ŒæŒ‰ç›¸å…³æ€§æ’åºï¼Œå¹¶ç”¨<FILES>æ ‡ç­¾åŒ…è£¹ã€‚
åªè¿”å›æ–‡ä»¶è·¯å¾„æ•°ç»„ï¼Œä¾‹å¦‚ï¼š
<FILES>
- path/to/file1.py
- path/to/file2.py
</FILES>
"""

        try:
            response = self._call_llm(prompt)
            # ä»<FILES>æ ‡ç­¾ä¸­æå–å†…å®¹
            response = response.strip()
            yaml_match = re.search(r'<FILES>\s*(.*?)\s*</FILES>', response, re.DOTALL)
            if yaml_match:
                yaml_content = yaml_match.group(1).strip()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾ï¼Œå°è¯•æ¸…ç†markdownä»£ç å—
                if response.startswith("```yaml"):
                    response = response[7:]
                elif response.startswith("```"):
                    response = response[3:]
                if response.endswith("```"):
                    response = response[:-3]
                yaml_content = response.strip()
            
            file_paths = yaml.safe_load(yaml_content)
            if not isinstance(file_paths, list):
                return []
            
            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            result = []
            for path in file_paths:
                abs_path = os.path.join(self.context_manager.project_root, path)
                if os.path.exists(abs_path):
                    result.append(abs_path)
            
            return result
        except Exception:
            return []

    def _score_files_with_llm(
        self, user_input: str, files: List[str]
    ) -> Dict[str, float]:
        """ä½¿ç”¨LLMå¯¹æ–‡ä»¶è¿›è¡Œç›¸å…³æ€§è¯„åˆ†
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            files: æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            æ–‡ä»¶è·¯å¾„åˆ°ç›¸å…³æ€§åˆ†æ•°çš„å­—å…¸
        """
        if not files:
            return {}
        
        # é™åˆ¶æ–‡ä»¶æ•°é‡ï¼Œé¿å…promptè¿‡é•¿
        files_to_score = files[:20]
        
        file_info = [
            {
                "path": os.path.relpath(f, self.context_manager.project_root),
                "basename": os.path.basename(f),
            }
            for f in files_to_score
        ]
        
        prompt = f"""æ ¹æ®ä»¥ä¸‹ä»»åŠ¡æè¿°ï¼Œå¯¹æ–‡ä»¶åˆ—è¡¨ä¸­çš„æ¯ä¸ªæ–‡ä»¶è¿›è¡Œç›¸å…³æ€§è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰ã€‚

ä»»åŠ¡æè¿°ï¼š{user_input}

æ–‡ä»¶åˆ—è¡¨ï¼š
{yaml.dump(file_info, allow_unicode=True, default_flow_style=False)}

è¯·è¿”å›YAMLå¯¹è±¡ï¼Œé”®ä¸ºæ–‡ä»¶è·¯å¾„ï¼Œå€¼ä¸ºç›¸å…³æ€§åˆ†æ•°ï¼ˆ0-10çš„æµ®ç‚¹æ•°ï¼‰ï¼Œå¹¶ç”¨<FILE_SCORES>æ ‡ç­¾åŒ…è£¹ã€‚
åªè¿”å›YAMLå¯¹è±¡ï¼Œä¾‹å¦‚ï¼š
<FILE_SCORES>
path/to/file1.py: 8.5
path/to/file2.py: 7.0
path/to/file3.py: 5.5
</FILE_SCORES>
"""

        try:
            response = self._call_llm(prompt)
            # ä»<FILE_SCORES>æ ‡ç­¾ä¸­æå–å†…å®¹
            response = response.strip()
            yaml_match = re.search(r'<FILE_SCORES>\s*(.*?)\s*</FILE_SCORES>', response, re.DOTALL)
            if yaml_match:
                yaml_content = yaml_match.group(1).strip()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾ï¼Œå°è¯•æ¸…ç†markdownä»£ç å—
                if response.startswith("```yaml"):
                    response = response[7:]
                elif response.startswith("```"):
                    response = response[3:]
                if response.endswith("```"):
                    response = response[:-3]
                yaml_content = response.strip()
            
            scores = yaml.safe_load(yaml_content)
            if not isinstance(scores, dict):
                return {}
            
            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„çš„é”®
            result = {}
            for rel_path, score in scores.items():
                abs_path = os.path.join(self.context_manager.project_root, rel_path)
                if abs_path in files_to_score:
                    result[abs_path] = float(score)
            
            # ä¸ºæœªè¯„åˆ†çš„æ–‡ä»¶è®¾ç½®é»˜è®¤åˆ†æ•°
            for f in files_to_score:
                if f not in result:
                    result[f] = 5.0  # é»˜è®¤ä¸­ç­‰ç›¸å…³æ€§
            
            return result
        except Exception:
            # è¯„åˆ†å¤±è´¥ï¼Œè¿”å›é»˜è®¤åˆ†æ•°
            return {f: 5.0 for f in files_to_score}

    def _score_symbols_with_llm(
        self, user_input: str, symbols: List[Symbol]
    ) -> Dict[Symbol, float]:
        """ä½¿ç”¨LLMå¯¹ç¬¦å·è¿›è¡Œç›¸å…³æ€§è¯„åˆ†
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            symbols: ç¬¦å·åˆ—è¡¨
            
        Returns:
            ç¬¦å·åˆ°ç›¸å…³æ€§åˆ†æ•°çš„å­—å…¸
        """
        if not symbols:
            return {}
        
        # é™åˆ¶ç¬¦å·æ•°é‡
        symbols_to_score = symbols[:20]
        
        symbol_info = [
            {
                "name": s.name,
                "kind": s.kind,
                "file": os.path.basename(s.file_path),
                "signature": s.signature or "",
            }
            for s in symbols_to_score
        ]
        
        prompt = f"""æ ¹æ®ä»¥ä¸‹ä»»åŠ¡æè¿°ï¼Œå¯¹ç¬¦å·åˆ—è¡¨ä¸­çš„æ¯ä¸ªç¬¦å·è¿›è¡Œç›¸å…³æ€§è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰ã€‚

ä»»åŠ¡æè¿°ï¼š{user_input}

ç¬¦å·åˆ—è¡¨ï¼š
{yaml.dump(symbol_info, allow_unicode=True, default_flow_style=False)}

è¯·è¿”å›YAMLå¯¹è±¡ï¼Œé”®ä¸ºç¬¦å·åç§°ï¼Œå€¼ä¸ºç›¸å…³æ€§åˆ†æ•°ï¼ˆ0-10çš„æµ®ç‚¹æ•°ï¼‰ï¼Œå¹¶ç”¨<SYMBOL_SCORES>æ ‡ç­¾åŒ…è£¹ã€‚
åªè¿”å›YAMLå¯¹è±¡ï¼Œä¾‹å¦‚ï¼š
<SYMBOL_SCORES>
symbol1: 9.0
symbol2: 7.5
symbol3: 6.0
</SYMBOL_SCORES>
"""

        try:
            response = self._call_llm(prompt)
            # ä»<SYMBOL_SCORES>æ ‡ç­¾ä¸­æå–å†…å®¹
            response = response.strip()
            yaml_match = re.search(r'<SYMBOL_SCORES>\s*(.*?)\s*</SYMBOL_SCORES>', response, re.DOTALL)
            if yaml_match:
                yaml_content = yaml_match.group(1).strip()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾ï¼Œå°è¯•æ¸…ç†markdownä»£ç å—
                if response.startswith("```yaml"):
                    response = response[7:]
                elif response.startswith("```"):
                    response = response[3:]
                if response.endswith("```"):
                    response = response[:-3]
                yaml_content = response.strip()
            
            scores = yaml.safe_load(yaml_content)
            if not isinstance(scores, dict):
                return {}
            
            # åˆ›å»ºç¬¦å·åˆ°åˆ†æ•°çš„æ˜ å°„
            result = {}
            for s in symbols_to_score:
                score = scores.get(s.name, 5.0)  # é»˜è®¤ä¸­ç­‰ç›¸å…³æ€§
                result[s] = float(score)
            
            return result
        except Exception:
            # è¯„åˆ†å¤±è´¥ï¼Œè¿”å›é»˜è®¤åˆ†æ•°
            return {s: 5.0 for s in symbols_to_score}

    def _find_test_files(self, file_path: str) -> List[str]:
        """æŸ¥æ‰¾ä¸æ–‡ä»¶ç›¸å…³çš„æµ‹è¯•æ–‡ä»¶
        
        Args:
            file_path: æºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æµ‹è¯•æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        test_files = []
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        project_root = self.context_manager.project_root

        # å¸¸è§çš„æµ‹è¯•æ–‡ä»¶å‘½åæ¨¡å¼
        test_patterns = [
            f"test_{base_name}.py",
            f"{base_name}_test.py",
            f"test_{base_name}.js",
            f"{base_name}.test.js",
            f"test_{base_name}.ts",
            f"{base_name}.test.ts",
            f"{base_name}_test.rs",
            f"test_{base_name}.go",
        ]

        # åœ¨é¡¹ç›®æ ¹ç›®å½•æœç´¢æµ‹è¯•æ–‡ä»¶
        for root, dirs, files in os.walk(project_root):
            # è·³è¿‡éšè—ç›®å½•å’Œå¸¸è§å¿½ç•¥ç›®å½•
            dirs[:] = filter_walk_dirs(dirs)

            # æ£€æŸ¥æ˜¯å¦æ˜¯æµ‹è¯•ç›®å½•
            if 'test' in root.lower() or 'tests' in root.lower():
                for pattern in test_patterns:
                    if pattern in files:
                        test_file = os.path.join(root, pattern)
                        if os.path.exists(test_file):
                            test_files.append(test_file)

        return test_files[:5]  # é™åˆ¶æ•°é‡

    def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLMç”Ÿæˆå“åº”
        
        Args:
            prompt: æç¤ºè¯
            
        Returns:
            LLMç”Ÿæˆçš„å“åº”æ–‡æœ¬
        """
        if not self.llm_model:
            raise ValueError("LLM model not available")
        
        try:
            # ä½¿ç”¨chat_until_successæ–¹æ³•ï¼ˆBasePlatformçš„æ ‡å‡†æ¥å£ï¼‰
            if hasattr(self.llm_model, 'chat_until_success'):
                response = self.llm_model.chat_until_success(prompt)
                return str(response)
            else:
                # å¦‚æœä¸æ”¯æŒchat_until_successï¼ŒæŠ›å‡ºå¼‚å¸¸
                raise ValueError("LLM model does not support chat_until_success interface")
        except Exception as e:
            PrettyOutput.print(f"LLMè°ƒç”¨å¤±è´¥: {e}", OutputType.WARNING)
            raise

    def format_recommendation(self, recommendation: ContextRecommendation) -> str:
        """æ ¼å¼åŒ–æ¨èç»“æœä¸ºå¯è¯»æ–‡æœ¬
        
        Args:
            recommendation: æ¨èç»“æœ
            
        Returns:
            æ ¼å¼åŒ–çš„æ–‡æœ¬
        """
        lines = ["\nğŸ’¡ æ™ºèƒ½ä¸Šä¸‹æ–‡æ¨è:"]
        lines.append("â”€" * 60)

        if recommendation.reason:
            lines.append(f"ğŸ“Œ æ¨èåŸå› : {recommendation.reason}")

        if recommendation.recommended_files:
            files_str = "\n   ".join(
                f"â€¢ {os.path.relpath(f, self.context_manager.project_root)}"
                for f in recommendation.recommended_files[:5]
            )
            more = len(recommendation.recommended_files) - 5
            if more > 0:
                files_str += f"\n   ... è¿˜æœ‰{more}ä¸ªæ–‡ä»¶"
            lines.append(f"ğŸ“ æ¨èæ–‡ä»¶ ({len(recommendation.recommended_files)}ä¸ª):\n   {files_str}")

        if recommendation.recommended_symbols:
            symbols_str = "\n   ".join(
                f"â€¢ {s.kind} `{s.name}` ({os.path.relpath(s.file_path, self.context_manager.project_root)}:{s.line_start})"
                for s in recommendation.recommended_symbols[:5]
            )
            more = len(recommendation.recommended_symbols) - 5
            if more > 0:
                symbols_str += f"\n   ... è¿˜æœ‰{more}ä¸ªç¬¦å·"
            lines.append(f"ğŸ”— æ¨èç¬¦å· ({len(recommendation.recommended_symbols)}ä¸ª):\n   {symbols_str}")

        if recommendation.related_tests:
            tests_str = "\n   ".join(
                f"â€¢ {os.path.relpath(f, self.context_manager.project_root)}"
                for f in recommendation.related_tests[:3]
            )
            more = len(recommendation.related_tests) - 3
            if more > 0:
                tests_str += f"\n   ... è¿˜æœ‰{more}ä¸ªæµ‹è¯•æ–‡ä»¶"
            lines.append(f"ğŸ§ª ç›¸å…³æµ‹è¯• ({len(recommendation.related_tests)}ä¸ª):\n   {tests_str}")

        lines.append("â”€" * 60)
        lines.append("")  # ç©ºè¡Œ

        return "\n".join(lines) if len(lines) > 2 else ""  # å¦‚æœæ²¡æœ‰æ¨èå†…å®¹ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
