"""ç¼–è¾‘å½±å“èŒƒå›´åˆ†ææ¨¡å—ã€‚

æä¾›ä»£ç ç¼–è¾‘å½±å“èŒƒå›´åˆ†æåŠŸèƒ½ï¼Œè¯†åˆ«å¯èƒ½å—å½±å“çš„æ–‡ä»¶ã€å‡½æ•°ã€æµ‹è¯•ç­‰ã€‚
"""

import ast
import os
import re
import subprocess
from dataclasses import dataclass
from dataclasses import field
from enum import Enum
from typing import Dict
from typing import List
from typing import Optional
from typing import Set

from .context_manager import ContextManager
from .file_ignore import filter_walk_dirs
from .symbol_extractor import Symbol


class ImpactType(Enum):
    """å½±å“ç±»å‹æšä¸¾"""

    REFERENCE = "reference"  # ç¬¦å·å¼•ç”¨
    DEPENDENT = "dependent"  # ä¾èµ–çš„ç¬¦å·
    TEST = "test"  # æµ‹è¯•æ–‡ä»¶
    INTERFACE_CHANGE = "interface_change"  # æ¥å£å˜æ›´
    DEPENDENCY_CHAIN = "dependency_chain"  # ä¾èµ–é“¾


class RiskLevel(Enum):
    """é£é™©ç­‰çº§æšä¸¾"""

    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"


@dataclass
class Impact:
    """è¡¨ç¤ºä¸€ä¸ªå½±å“é¡¹"""

    impact_type: ImpactType
    target: str  # å—å½±å“çš„ç›®æ ‡ï¼ˆæ–‡ä»¶è·¯å¾„ã€ç¬¦å·åç­‰ï¼‰
    description: str = ""
    line: Optional[int] = None
    severity: RiskLevel = RiskLevel.LOW


@dataclass
class InterfaceChange:
    """è¡¨ç¤ºæ¥å£å˜æ›´"""

    symbol_name: str
    change_type: str  # 'signature', 'return_type', 'parameter', 'removed', 'added'
    file_path: str
    line: int
    before: Optional[str] = None
    after: Optional[str] = None
    description: str = ""


@dataclass
class ImpactReport:
    """å½±å“åˆ†ææŠ¥å‘Š"""

    affected_files: List[str] = field(default_factory=list)
    affected_symbols: List[Symbol] = field(default_factory=list)
    affected_tests: List[str] = field(default_factory=list)
    interface_changes: List[InterfaceChange] = field(default_factory=list)
    impacts: List[Impact] = field(default_factory=list)
    risk_level: RiskLevel = RiskLevel.LOW
    recommendations: List[str] = field(default_factory=list)

    def to_string(self, project_root: str = "") -> str:
        """ç”Ÿæˆå¯è¯»çš„å½±å“æŠ¥å‘Šå­—ç¬¦ä¸²"""
        lines = []
        lines.append("=" * 60)
        lines.append("ç¼–è¾‘å½±å“èŒƒå›´åˆ†ææŠ¥å‘Š")
        lines.append("=" * 60)

        # é£é™©ç­‰çº§
        risk_emoji = {RiskLevel.LOW: "ğŸŸ¢", RiskLevel.MEDIUM: "ğŸŸ¡", RiskLevel.HIGH: "ğŸ”´"}
        lines.append(
            f"\né£é™©ç­‰çº§: {risk_emoji.get(self.risk_level, 'âšª')} {self.risk_level.value.upper()}"
        )

        # å—å½±å“æ–‡ä»¶
        if self.affected_files:
            lines.append(f"\nå—å½±å“æ–‡ä»¶ ({len(self.affected_files)}):")
            for file_path in self.affected_files[:10]:
                rel_path = (
                    os.path.relpath(file_path, project_root)
                    if project_root
                    else file_path
                )
                lines.append(f"  - {rel_path}")
            if len(self.affected_files) > 10:
                lines.append(f"  ... è¿˜æœ‰ {len(self.affected_files) - 10} ä¸ªæ–‡ä»¶")

        # å—å½±å“ç¬¦å·
        if self.affected_symbols:
            lines.append(f"\nå—å½±å“ç¬¦å· ({len(self.affected_symbols)}):")
            for symbol in self.affected_symbols[:10]:
                lines.append(
                    f"  - {symbol.kind} {symbol.name} ({os.path.basename(symbol.file_path)}:{symbol.line_start})"
                )
            if len(self.affected_symbols) > 10:
                lines.append(f"  ... è¿˜æœ‰ {len(self.affected_symbols) - 10} ä¸ªç¬¦å·")

        # å—å½±å“æµ‹è¯•
        if self.affected_tests:
            lines.append(f"\nå—å½±å“æµ‹è¯• ({len(self.affected_tests)}):")
            for test_file in self.affected_tests[:10]:
                rel_path = (
                    os.path.relpath(test_file, project_root)
                    if project_root
                    else test_file
                )
                lines.append(f"  - {rel_path}")
            if len(self.affected_tests) > 10:
                lines.append(f"  ... è¿˜æœ‰ {len(self.affected_tests) - 10} ä¸ªæµ‹è¯•æ–‡ä»¶")

        # æ¥å£å˜æ›´
        if self.interface_changes:
            lines.append(f"\næ¥å£å˜æ›´ ({len(self.interface_changes)}):")
            for change in self.interface_changes[:10]:
                lines.append(f"  - {change.symbol_name}: {change.change_type}")
                if change.description:
                    lines.append(f"    {change.description}")
            if len(self.interface_changes) > 10:
                lines.append(
                    f"  ... è¿˜æœ‰ {len(self.interface_changes) - 10} ä¸ªæ¥å£å˜æ›´"
                )

        # å»ºè®®
        if self.recommendations:
            lines.append("\nå»ºè®®:")
            for i, rec in enumerate(self.recommendations, 1):
                lines.append(f"  {i}. {rec}")

        lines.append("\n" + "=" * 60)
        return "\n".join(lines)


@dataclass
class Edit:
    """è¡¨ç¤ºä¸€ä¸ªç¼–è¾‘æ“ä½œ"""

    file_path: str
    line_start: int
    line_end: int
    before: str = ""
    after: str = ""
    edit_type: str = "modify"  # 'modify', 'add', 'delete'


class TestDiscoverer:
    """æµ‹è¯•æ–‡ä»¶å‘ç°å™¨"""

    # æµ‹è¯•æ–‡ä»¶å‘½åæ¨¡å¼
    TEST_PATTERNS = {
        "python": [
            r"test_.*\.py$",
            r".*_test\.py$",
        ],
        "javascript": [
            r".*\.test\.(js|ts|jsx|tsx)$",
            r".*\.spec\.(js|ts|jsx|tsx)$",
        ],
        "rust": [
            r".*_test\.rs$",
        ],
        "java": [
            r".*Test\.java$",
            r".*Tests\.java$",
        ],
        "go": [
            r".*_test\.go$",
        ],
    }

    def __init__(self, project_root: str):
        self.project_root = project_root

    def find_test_files(self, file_path: str) -> List[str]:
        """æŸ¥æ‰¾ä¸æ–‡ä»¶ç›¸å…³çš„æµ‹è¯•æ–‡ä»¶"""
        test_files: List[str] = []

        # æ£€æµ‹è¯­è¨€
        language = self._detect_language(file_path)
        if not language:
            return test_files

        # è·å–æµ‹è¯•æ–‡ä»¶æ¨¡å¼
        patterns = self.TEST_PATTERNS.get(language, [])
        if not patterns:
            return test_files

        # è·å–æ–‡ä»¶çš„åŸºç¡€åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰
        base_name = os.path.splitext(os.path.basename(file_path))[0]

        # åœ¨é¡¹ç›®æ ¹ç›®å½•æœç´¢æµ‹è¯•æ–‡ä»¶
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡éšè—ç›®å½•å’Œå¸¸è§å¿½ç•¥ç›®å½•
            dirs[:] = filter_walk_dirs(dirs)

            for file in files:
                file_path_full = os.path.join(root, file)

                # æ£€æŸ¥æ˜¯å¦åŒ¹é…æµ‹è¯•æ–‡ä»¶æ¨¡å¼
                for pattern in patterns:
                    if re.match(pattern, file, re.IGNORECASE):
                        # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶æ˜¯å¦å¯èƒ½æµ‹è¯•ç›®æ ‡æ–‡ä»¶
                        if self._might_test_file(file_path_full, file_path, base_name):
                            test_files.append(file_path_full)
                        break

        return list(set(test_files))

    def _might_test_file(
        self, test_file: str, target_file: str, base_name: str
    ) -> bool:
        """åˆ¤æ–­æµ‹è¯•æ–‡ä»¶æ˜¯å¦å¯èƒ½æµ‹è¯•ç›®æ ‡æ–‡ä»¶"""
        # è¯»å–æµ‹è¯•æ–‡ä»¶å†…å®¹ï¼ŒæŸ¥æ‰¾ç›®æ ‡æ–‡ä»¶çš„å¼•ç”¨
        try:
            with open(test_file, "r", encoding="utf-8", errors="replace") as f:
                content = f.read()

            # æ£€æŸ¥æ˜¯å¦å¯¼å…¥æˆ–å¼•ç”¨äº†ç›®æ ‡æ–‡ä»¶
            # ç®€å•çš„å¯å‘å¼æ–¹æ³•ï¼šæ£€æŸ¥æ–‡ä»¶åã€æ¨¡å—åç­‰
            target_base = os.path.splitext(os.path.basename(target_file))[0]

            # æ£€æŸ¥å¯¼å…¥è¯­å¥
            import_patterns = [
                rf"import\s+.*{re.escape(target_base)}",
                rf"from\s+.*{re.escape(target_base)}",
                rf"use\s+.*{re.escape(target_base)}",  # Rust
            ]

            for pattern in import_patterns:
                if re.search(pattern, content, re.IGNORECASE):
                    return True

            # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦å‡ºç°åœ¨æµ‹è¯•æ–‡ä»¶ä¸­
            if target_base.lower() in content.lower():
                return True

        except Exception:
            pass

        return False

    def _detect_language(self, file_path: str) -> Optional[str]:
        """æ£€æµ‹æ–‡ä»¶è¯­è¨€"""
        ext = os.path.splitext(file_path)[1].lower()
        ext_map = {
            ".py": "python",
            ".js": "javascript",
            ".ts": "javascript",
            ".jsx": "javascript",
            ".tsx": "javascript",
            ".rs": "rust",
            ".java": "java",
            ".go": "go",
        }
        return ext_map.get(ext)


class ImpactAnalyzer:
    """ç¼–è¾‘å½±å“èŒƒå›´åˆ†æå™¨"""

    def __init__(self, context_manager: ContextManager):
        self.context_manager = context_manager
        self.project_root = context_manager.project_root
        self.test_discoverer = TestDiscoverer(self.project_root)

    def analyze_edit_impact(self, file_path: str, edits: List[Edit]) -> ImpactReport:
        """åˆ†æç¼–è¾‘çš„å½±å“èŒƒå›´

        Args:
            file_path: è¢«ç¼–è¾‘çš„æ–‡ä»¶è·¯å¾„
            edits: ç¼–è¾‘æ“ä½œåˆ—è¡¨

        Returns:
            ImpactReport: å½±å“åˆ†ææŠ¥å‘Š
        """
        impacts: List[Impact] = []
        affected_symbols: Set[Symbol] = set()
        affected_files: Set[str] = {file_path}
        interface_changes: List[InterfaceChange] = []

        # 1. åˆ†ææ¯ä¸ªç¼–è¾‘çš„å½±å“
        for edit in edits:
            # åˆ†æç¬¦å·å½±å“
            symbols_in_edit = self._find_symbols_in_edit(file_path, edit)
            for symbol in symbols_in_edit:
                affected_symbols.add(symbol)
                symbol_impacts = self._analyze_symbol_impact(symbol, edit)
                impacts.extend(symbol_impacts)

                # æ”¶é›†å—å½±å“çš„æ–‡ä»¶
                for impact in symbol_impacts:
                    if impact.impact_type == ImpactType.REFERENCE:
                        affected_files.add(impact.target)
                    elif impact.impact_type == ImpactType.DEPENDENT:
                        affected_files.add(impact.target)

        # 2. åˆ†æä¾èµ–é“¾å½±å“
        dependency_impacts = self._analyze_dependency_chain(file_path)
        impacts.extend(dependency_impacts)
        for impact in dependency_impacts:
            affected_files.add(impact.target)

        # 3. æ£€æµ‹æ¥å£å˜æ›´
        if edits:
            # éœ€è¦è¯»å–æ–‡ä»¶å†…å®¹æ¥æ¯”è¾ƒ
            interface_changes = self._detect_interface_changes(file_path, edits)
            for change in interface_changes:
                affected_files.add(change.file_path)

        # 4. æŸ¥æ‰¾ç›¸å…³æµ‹è¯•
        test_files = self.test_discoverer.find_test_files(file_path)
        for test_file in test_files:
            impacts.append(
                Impact(
                    impact_type=ImpactType.TEST,
                    target=test_file,
                    description=f"å¯èƒ½æµ‹è¯• {os.path.basename(file_path)} çš„æµ‹è¯•æ–‡ä»¶",
                )
            )
            affected_files.add(test_file)

        # 5. è¯„ä¼°é£é™©ç­‰çº§
        risk_level = self._assess_risk(impacts, interface_changes)

        # 6. ç”Ÿæˆå»ºè®®
        recommendations = self._generate_recommendations(
            impacts, interface_changes, affected_files, test_files
        )

        return ImpactReport(
            affected_files=list(affected_files),
            affected_symbols=list(affected_symbols),
            affected_tests=test_files,
            interface_changes=interface_changes,
            impacts=impacts,
            risk_level=risk_level,
            recommendations=recommendations,
        )

    def _find_symbols_in_edit(self, file_path: str, edit: Edit) -> List[Symbol]:
        """æŸ¥æ‰¾ç¼–è¾‘åŒºåŸŸå†…çš„ç¬¦å·"""
        symbols = self.context_manager.symbol_table.get_file_symbols(file_path)

        # æ‰¾å‡ºåœ¨ç¼–è¾‘èŒƒå›´å†…çš„ç¬¦å·
        affected_symbols = []
        for symbol in symbols:
            # æ£€æŸ¥ç¬¦å·æ˜¯å¦ä¸ç¼–è¾‘åŒºåŸŸé‡å 
            if (
                symbol.line_start <= edit.line_end
                and symbol.line_end >= edit.line_start
            ):
                affected_symbols.append(symbol)

        return affected_symbols

    def _analyze_symbol_impact(self, symbol: Symbol, edit: Edit) -> List[Impact]:
        """åˆ†æç¬¦å·ç¼–è¾‘çš„å½±å“"""
        impacts = []

        # 1. æŸ¥æ‰¾æ‰€æœ‰å¼•ç”¨è¯¥ç¬¦å·çš„ä½ç½®
        references = self.context_manager.find_references(symbol.name, symbol.file_path)
        for ref in references:
            impacts.append(
                Impact(
                    impact_type=ImpactType.REFERENCE,
                    target=ref.file_path,
                    description=f"å¼•ç”¨ç¬¦å· {symbol.name}",
                    line=ref.line,
                    severity=RiskLevel.MEDIUM
                    if symbol.kind in ("function", "class")
                    else RiskLevel.LOW,
                )
            )

        # 2. æŸ¥æ‰¾ä¾èµ–è¯¥ç¬¦å·çš„å…¶ä»–ç¬¦å·ï¼ˆåœ¨åŒä¸€æ–‡ä»¶ä¸­ï¼‰
        if symbol.kind in ("function", "class"):
            dependents = self._find_dependent_symbols(symbol)
            for dep in dependents:
                impacts.append(
                    Impact(
                        impact_type=ImpactType.DEPENDENT,
                        target=dep.file_path,
                        description=f"ä¾èµ–ç¬¦å· {symbol.name}",
                        line=dep.line_start,
                        severity=RiskLevel.MEDIUM,
                    )
                )

        return impacts

    def _find_dependent_symbols(self, symbol: Symbol) -> List[Symbol]:
        """æŸ¥æ‰¾ä¾èµ–è¯¥ç¬¦å·çš„å…¶ä»–ç¬¦å·"""
        dependents = []

        # è·å–åŒä¸€æ–‡ä»¶ä¸­çš„æ‰€æœ‰ç¬¦å·
        file_symbols = self.context_manager.symbol_table.get_file_symbols(
            symbol.file_path
        )

        # æŸ¥æ‰¾åœ¨ç¬¦å·å®šä¹‰ä¹‹åçš„ç¬¦å·ï¼ˆå¯èƒ½ä½¿ç”¨è¯¥ç¬¦å·ï¼‰
        for other_symbol in file_symbols:
            if (
                other_symbol.line_start > symbol.line_end
                and other_symbol.name != symbol.name
            ):
                # ç®€å•æ£€æŸ¥ï¼šå¦‚æœç¬¦å·åå‡ºç°åœ¨å…¶ä»–ç¬¦å·çš„èŒƒå›´å†…ï¼Œå¯èƒ½ä¾èµ–
                # è¿™é‡Œä½¿ç”¨ç®€å•çš„å¯å‘å¼æ–¹æ³•
                content = self.context_manager._get_file_content(symbol.file_path)
                if content:
                    # æå–å…¶ä»–ç¬¦å·çš„ä»£ç åŒºåŸŸ
                    lines = content.split("\n")
                    if other_symbol.line_start <= len(
                        lines
                    ) and other_symbol.line_end <= len(lines):
                        region = "\n".join(
                            lines[other_symbol.line_start - 1 : other_symbol.line_end]
                        )
                        if symbol.name in region:
                            dependents.append(other_symbol)

        return dependents

    def _analyze_dependency_chain(self, file_path: str) -> List[Impact]:
        """åˆ†æä¾èµ–é“¾ï¼Œæ‰¾å‡ºæ‰€æœ‰å¯èƒ½å—å½±å“çš„æ–‡ä»¶"""
        impacts = []

        # è·å–ä¾èµ–è¯¥æ–‡ä»¶çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆä¼ é€’é—­åŒ…ï¼‰
        visited = set()
        to_process = [file_path]

        while to_process:
            current = to_process.pop(0)
            if current in visited:
                continue
            visited.add(current)

            dependents = self.context_manager.dependency_graph.get_dependents(current)
            for dependent in dependents:
                if dependent not in visited:
                    impacts.append(
                        Impact(
                            impact_type=ImpactType.DEPENDENCY_CHAIN,
                            target=dependent,
                            description=f"é—´æ¥ä¾èµ– {os.path.basename(file_path)}",
                            severity=RiskLevel.LOW,
                        )
                    )
                    to_process.append(dependent)

        return impacts

    def _detect_interface_changes(
        self, file_path: str, edits: List[Edit]
    ) -> List[InterfaceChange]:
        """æ£€æµ‹æ¥å£å˜æ›´ï¼ˆå‡½æ•°ç­¾åã€ç±»å®šä¹‰ç­‰ï¼‰"""
        changes: List[InterfaceChange] = []

        # è¯»å–æ–‡ä»¶å†…å®¹
        content_before = self._get_file_content_before_edit(file_path, edits)
        content_after = self._get_file_content_after_edit(file_path, edits)

        if not content_before or not content_after:
            return changes

        # è§£æASTå¹¶æ¯”è¾ƒ
        try:
            tree_before = ast.parse(content_before, filename=file_path)
            tree_after = ast.parse(content_after, filename=file_path)

            # æå–å‡½æ•°å’Œç±»å®šä¹‰
            defs_before = self._extract_definitions(tree_before)
            defs_after = self._extract_definitions(tree_after)

            # æ¯”è¾ƒå®šä¹‰
            for name, def_before in defs_before.items():
                if name in defs_after:
                    def_after = defs_after[name]
                    change = self._compare_definition(
                        name, def_before, def_after, file_path
                    )
                    if change:
                        changes.append(change)
                else:
                    # å®šä¹‰è¢«åˆ é™¤
                    changes.append(
                        InterfaceChange(
                            symbol_name=name,
                            change_type="removed",
                            file_path=file_path,
                            line=def_before["line"],
                            description=f"ç¬¦å· {name} è¢«åˆ é™¤",
                        )
                    )

            # æ£€æŸ¥æ–°å¢çš„å®šä¹‰
            for name, def_after in defs_after.items():
                if name not in defs_before:
                    changes.append(
                        InterfaceChange(
                            symbol_name=name,
                            change_type="added",
                            file_path=file_path,
                            line=def_after["line"],
                            description=f"æ–°å¢ç¬¦å· {name}",
                        )
                    )

        except SyntaxError:
            # å¦‚æœè§£æå¤±è´¥ï¼Œè·³è¿‡æ¥å£å˜æ›´æ£€æµ‹
            pass

        return changes

    def _extract_definitions(self, tree: ast.AST) -> Dict[str, Dict]:
        """ä»ASTä¸­æå–å‡½æ•°å’Œç±»å®šä¹‰"""
        definitions = {}

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # æå–å‡½æ•°ç­¾å
                args = [arg.arg for arg in node.args.args]
                signature = f"{node.name}({', '.join(args)})"
                definitions[node.name] = {
                    "type": "function",
                    "line": node.lineno,
                    "signature": signature,
                    "args": args,
                    "node": node,
                }
            elif isinstance(node, ast.ClassDef):
                definitions[node.name] = {
                    "type": "class",
                    "line": node.lineno,
                    "signature": node.name,
                    "node": node,
                }

        return definitions

    def _compare_definition(
        self, name: str, def_before: Dict, def_after: Dict, file_path: str
    ) -> Optional[InterfaceChange]:
        """æ¯”è¾ƒä¸¤ä¸ªå®šä¹‰ï¼Œæ£€æµ‹æ¥å£å˜æ›´"""
        if def_before["type"] != def_after["type"]:
            return InterfaceChange(
                symbol_name=name,
                change_type="signature",
                file_path=file_path,
                line=def_after["line"],
                before=def_before["signature"],
                after=def_after["signature"],
                description=f"ç¬¦å· {name} çš„ç±»å‹ä» {def_before['type']} å˜ä¸º {def_after['type']}",
            )

        if def_before["type"] == "function":
            # æ¯”è¾ƒå‡½æ•°å‚æ•°
            args_before = def_before.get("args", [])
            args_after = def_after.get("args", [])

            if args_before != args_after:
                return InterfaceChange(
                    symbol_name=name,
                    change_type="signature",
                    file_path=file_path,
                    line=def_after["line"],
                    before=def_before["signature"],
                    after=def_after["signature"],
                    description=f"å‡½æ•° {name} çš„å‚æ•°ä» ({', '.join(args_before)}) å˜ä¸º ({', '.join(args_after)})",
                )

        return None

    def _get_file_content_before_edit(
        self, file_path: str, edits: List[Edit]
    ) -> Optional[str]:
        """è·å–ç¼–è¾‘å‰çš„æ–‡ä»¶å†…å®¹"""
        try:
            with open(file_path, "r", encoding="utf-8", errors="replace") as f:
                return f.read()
        except Exception:
            return None

    def _get_file_content_after_edit(
        self, file_path: str, edits: List[Edit]
    ) -> Optional[str]:
        """è·å–ç¼–è¾‘åçš„æ–‡ä»¶å†…å®¹ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # è¿™é‡Œåº”è¯¥æ ¹æ®editsæ¨¡æ‹Ÿç¼–è¾‘åçš„å†…å®¹
        # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ç›´æ¥è¯»å–å½“å‰æ–‡ä»¶å†…å®¹
        # åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œåº”è¯¥æ ¹æ®editsåº”ç”¨å˜æ›´
        try:
            with open(file_path, "r", encoding="utf-8", errors="replace") as f:
                return f.read()
        except Exception:
            return None

    def _assess_risk(
        self, impacts: List[Impact], interface_changes: List[InterfaceChange]
    ) -> RiskLevel:
        """è¯„ä¼°ç¼–è¾‘é£é™©ç­‰çº§"""
        # ç»Ÿè®¡é«˜é£é™©å› ç´ 
        high_risk_count = 0
        medium_risk_count = 0

        # æ¥å£å˜æ›´é€šå¸¸æ˜¯é«˜é£é™©
        if interface_changes:
            high_risk_count += len(interface_changes)

        # ç»Ÿè®¡å½±å“æ•°é‡
        reference_count = sum(
            1 for i in impacts if i.impact_type == ImpactType.REFERENCE
        )
        if reference_count > 10:
            high_risk_count += 1
        elif reference_count > 5:
            medium_risk_count += 1

        # æ£€æŸ¥æ˜¯å¦æœ‰é«˜é£é™©çš„å½±å“
        for impact in impacts:
            if impact.severity == RiskLevel.HIGH:
                high_risk_count += 1
            elif impact.severity == RiskLevel.MEDIUM:
                medium_risk_count += 1

        # è¯„ä¼°é£é™©ç­‰çº§
        if high_risk_count > 0 or medium_risk_count > 3:
            return RiskLevel.HIGH
        elif medium_risk_count > 0 or len(impacts) > 5:
            return RiskLevel.MEDIUM
        else:
            return RiskLevel.LOW

    def _generate_recommendations(
        self,
        impacts: List[Impact],
        interface_changes: List[InterfaceChange],
        affected_files: Set[str],
        test_files: List[str],
    ) -> List[str]:
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        recommendations = []

        # å¦‚æœæœ‰æ¥å£å˜æ›´ï¼Œå»ºè®®æ£€æŸ¥æ‰€æœ‰è°ƒç”¨ç‚¹
        if interface_changes:
            recommendations.append(
                f"æ£€æµ‹åˆ° {len(interface_changes)} ä¸ªæ¥å£å˜æ›´ï¼Œè¯·æ£€æŸ¥æ‰€æœ‰è°ƒç”¨ç‚¹å¹¶æ›´æ–°ç›¸å…³ä»£ç "
            )

        # å¦‚æœæœ‰æµ‹è¯•æ–‡ä»¶ï¼Œå»ºè®®è¿è¡Œæµ‹è¯•
        if test_files:
            recommendations.append(
                f"å‘ç° {len(test_files)} ä¸ªç›¸å…³æµ‹è¯•æ–‡ä»¶ï¼Œå»ºè®®è¿è¡Œæµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£å¸¸"
            )

        # å¦‚æœå½±å“æ–‡ä»¶è¾ƒå¤šï¼Œå»ºè®®å¢é‡æµ‹è¯•
        if len(affected_files) > 5:
            recommendations.append(
                f"ç¼–è¾‘å½±å“äº† {len(affected_files)} ä¸ªæ–‡ä»¶ï¼Œå»ºè®®è¿›è¡Œå¢é‡æµ‹è¯•"
            )

        # å¦‚æœæœ‰å¤§é‡å¼•ç”¨ï¼Œå»ºè®®ä»£ç å®¡æŸ¥
        reference_count = sum(
            1 for i in impacts if i.impact_type == ImpactType.REFERENCE
        )
        if reference_count > 10:
            recommendations.append(
                f"æ£€æµ‹åˆ° {reference_count} ä¸ªç¬¦å·å¼•ç”¨ï¼Œå»ºè®®è¿›è¡Œä»£ç å®¡æŸ¥"
            )

        if not recommendations:
            recommendations.append("ç¼–è¾‘å½±å“èŒƒå›´è¾ƒå°ï¼Œå»ºè®®è¿›è¡ŒåŸºæœ¬æµ‹è¯•")

        return recommendations


def parse_git_diff_to_edits(file_path: str, project_root: str) -> List[Edit]:
    """ä»git diffä¸­è§£æç¼–è¾‘æ“ä½œ

    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        project_root: é¡¹ç›®æ ¹ç›®å½•

    Returns:
        List[Edit]: ç¼–è¾‘æ“ä½œåˆ—è¡¨
    """
    edits: List[Edit] = []

    try:
        # è·å–æ–‡ä»¶çš„git diff
        abs_path = os.path.abspath(file_path)
        if not os.path.exists(abs_path):
            return edits

        # æ£€æŸ¥æ˜¯å¦æœ‰gitä»“åº“
        try:
            subprocess.run(
                ["git", "rev-parse", "--git-dir"],
                cwd=project_root,
                check=True,
                capture_output=True,
                stderr=subprocess.DEVNULL,
            )
        except (subprocess.CalledProcessError, FileNotFoundError):
            # ä¸æ˜¯gitä»“åº“æˆ–gitä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
            return edits

        # è·å–HEADçš„hash
        try:
            result = subprocess.run(
                ["git", "rev-parse", "HEAD"],
                cwd=project_root,
                capture_output=True,
                text=True,
                check=False,
            )
            head_exists = result.returncode == 0 and result.stdout.strip()
        except Exception:
            head_exists = False

        # ä¸´æ—¶æ·»åŠ æ–‡ä»¶åˆ°gitç´¢å¼•ï¼ˆå¦‚æœæ˜¯æ–°æ–‡ä»¶ï¼‰
        subprocess.run(
            ["git", "add", "-N", "--", abs_path],
            cwd=project_root,
            check=False,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
        )

        try:
            # è·å–diff
            cmd = ["git", "diff"] + (["HEAD"] if head_exists else []) + ["--", abs_path]
            result = subprocess.run(
                cmd,
                cwd=project_root,
                capture_output=True,
                text=True,
                encoding="utf-8",
                errors="replace",
                check=False,
            )

            if result.returncode != 0 or not result.stdout:
                return edits

            diff_text = result.stdout

            # è§£ædiffæ–‡æœ¬
            lines = diff_text.split("\n")
            current_hunk_start = None
            current_line_num: Optional[int] = None
            before_lines: List[str] = []
            after_lines: List[str] = []
            in_hunk = False

            for line in lines:
                # è§£æhunk header: @@ -start,count +start,count @@
                if line.startswith("@@"):
                    # ä¿å­˜ä¹‹å‰çš„hunk
                    if in_hunk and current_hunk_start is not None:
                        if before_lines or after_lines:
                            edits.append(
                                Edit(
                                    file_path=abs_path,
                                    line_start=current_hunk_start,
                                    line_end=current_hunk_start + len(after_lines) - 1
                                    if after_lines
                                    else current_hunk_start,
                                    before="\n".join(before_lines),
                                    after="\n".join(after_lines),
                                    edit_type="modify"
                                    if before_lines and after_lines
                                    else ("delete" if before_lines else "add"),
                                )
                            )

                    # è§£ææ–°çš„hunk
                    match = re.search(
                        r"@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@", line
                    )
                    if match:
                        old_start = int(match.group(1))
                        new_start = int(match.group(3))

                        current_hunk_start = new_start
                        current_line_num = old_start
                        before_lines = []
                        after_lines = []
                        in_hunk = True
                    continue

                if not in_hunk:
                    continue

                # è§£ædiffè¡Œ
                if line.startswith("-") and not line.startswith("---"):
                    # åˆ é™¤çš„è¡Œ
                    before_lines.append(line[1:])
                    if current_line_num is not None:
                        current_line_num += 1
                elif line.startswith("+") and not line.startswith("+++"):
                    # æ–°å¢çš„è¡Œ
                    after_lines.append(line[1:])
                elif line.startswith(" "):
                    # æœªæ”¹å˜çš„è¡Œ
                    before_lines.append(line[1:])
                    after_lines.append(line[1:])
                    if current_line_num is not None:
                        current_line_num += 1

            # ä¿å­˜æœ€åä¸€ä¸ªhunk
            if in_hunk and current_hunk_start is not None:
                if before_lines or after_lines:
                    edits.append(
                        Edit(
                            file_path=abs_path,
                            line_start=current_hunk_start,
                            line_end=current_hunk_start + len(after_lines) - 1
                            if after_lines
                            else current_hunk_start,
                            before="\n".join(before_lines),
                            after="\n".join(after_lines),
                            edit_type="modify"
                            if before_lines and after_lines
                            else ("delete" if before_lines else "add"),
                        )
                    )

        finally:
            # æ¸…ç†ä¸´æ—¶æ·»åŠ çš„æ–‡ä»¶
            subprocess.run(
                ["git", "reset", "--", abs_path],
                cwd=project_root,
                check=False,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            )

    except Exception:
        # è§£æå¤±è´¥æ—¶è¿”å›ç©ºåˆ—è¡¨
        pass

    return edits
