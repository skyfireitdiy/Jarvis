# -*- coding: utf-8 -*-
import re
from abc import ABC, abstractmethod
from typing import Generator, List, Tuple

from rich import box  # type: ignore
from rich.live import Live  # type: ignore
from rich.panel import Panel  # type: ignore
from rich.text import Text  # type: ignore

from jarvis.jarvis_utils.config import (
    get_max_input_token_count,
    get_pretty_output,
    is_print_prompt,
)
from jarvis.jarvis_utils.embedding import split_text_into_chunks
from jarvis.jarvis_utils.globals import set_in_chat
from jarvis.jarvis_utils.output import OutputType, PrettyOutput
from jarvis.jarvis_utils.tag import ct, ot
from jarvis.jarvis_utils.utils import get_context_token_count, while_success, while_true


class BasePlatform(ABC):
    """Base class for large language models"""

    def __init__(self):
        """Initialize model"""
        self.suppress_output = True  # æ·»åŠ è¾“å‡ºæ§åˆ¶æ ‡å¿—
        self.web = False  # æ·»åŠ webå±æ€§ï¼Œé»˜è®¤false
        self._saved = False

    def __del__(self):
        """Destroy model"""
        if not self._saved:
            self.delete_chat()

    @abstractmethod
    def set_model_name(self, model_name: str):
        """Set model name"""
        raise NotImplementedError("set_model_name is not implemented")

    def reset(self):
        """Reset model"""
        self.delete_chat()

    @abstractmethod
    def chat(self, message: str) -> Generator[str, None, None]:
        """Execute conversation"""
        raise NotImplementedError("chat is not implemented")

    @abstractmethod
    def upload_files(self, file_list: List[str]) -> bool:
        raise NotImplementedError("upload_files is not implemented")

    @abstractmethod
    def support_upload_files(self) -> bool:
        """Check if platform supports upload files"""
        return False

    def _chat(self, message: str):
        import time

        start_time = time.time()

        input_token_count = get_context_token_count(message)

        if input_token_count > get_max_input_token_count():
            max_chunk_size = get_max_input_token_count() - 1024  # ç•™å‡ºä¸€äº›ä½™é‡
            min_chunk_size = get_max_input_token_count() - 2048
            inputs = split_text_into_chunks(message, max_chunk_size, min_chunk_size)
            print("ğŸ“¤ æ­£åœ¨æäº¤é•¿ä¸Šä¸‹æ–‡...")
            prefix_prompt = f"""
            æˆ‘å°†åˆ†å¤šæ¬¡æä¾›å¤§é‡å†…å®¹ï¼Œåœ¨æˆ‘æ˜ç¡®å‘Šè¯‰ä½ å†…å®¹å·²ç»å…¨éƒ¨æä¾›å®Œæ¯•ä¹‹å‰ï¼Œæ¯æ¬¡ä»…éœ€è¦è¾“å‡º"å·²æ”¶åˆ°"ï¼Œæ˜ç™½è¯·è¾“å‡º"å¼€å§‹æ¥æ”¶è¾“å…¥"ã€‚
            """
            while_true(lambda: while_success(lambda: self.chat(prefix_prompt), 5), 5)
            submit_count = 0
            length = 0
            response = ""
            for input in inputs:
                submit_count += 1
                length += len(input)
                print(
                    f"ğŸ“¤ æ­£åœ¨æäº¤ç¬¬{submit_count}éƒ¨åˆ†ï¼ˆå…±{len(inputs)}éƒ¨åˆ†({length}/{len(message)})ï¼‰"
                )

                response += "\n"
                for trunk in while_true(
                    lambda: while_success(
                        lambda: self.chat(
                            f"<part_content>{input}</part_content>\n\nè¯·è¿”å›<å·²æ”¶åˆ°>ï¼Œä¸éœ€è¦è¿”å›å…¶ä»–ä»»ä½•å†…å®¹"
                        ),
                        5,
                    ),
                    5,
                ):
                    response += trunk

                print(
                    f"ğŸ“¤ æäº¤ç¬¬{submit_count}éƒ¨åˆ†å®Œæˆï¼Œå½“å‰è¿›åº¦ï¼š{length}/{len(message)}"
                )
            print("âœ… æäº¤å®Œæˆ")
            response += "\n" + while_true(
                lambda: while_success(
                    lambda: self._chat("å†…å®¹å·²ç»å…¨éƒ¨æä¾›å®Œæ¯•ï¼Œè¯·æ ¹æ®å†…å®¹ç»§ç»­"), 5
                ),
                5,
            )
        else:
            response = ""

            text_content = Text()
            panel = Panel(
                text_content,
                title=f"[bold cyan]{self.name()}[/bold cyan]",
                subtitle="[dim]æ€è€ƒä¸­...[/dim]",
                border_style="bright_blue",
                box=box.ROUNDED,
            )

            if not self.suppress_output:
                if get_pretty_output():
                    with Live(panel, refresh_per_second=10, transient=False) as live:
                        for s in self.chat(message):
                            response += s
                            text_content.append(s, style="bright_white")
                            panel.subtitle = "[yellow]æ­£åœ¨å›ç­”...[/yellow]"
                            live.update(panel)
                        end_time = time.time()
                        duration = end_time - start_time
                        char_count = len(response)
                        # Calculate token count and tokens per second
                        try:
                            token_count = get_context_token_count(response)
                            tokens_per_second = (
                                token_count / duration if duration > 0 else 0
                            )
                        except Exception as e:
                            PrettyOutput.print(
                                f"Tokenization failed: {str(e)}", OutputType.WARNING
                            )
                            token_count = 0
                            tokens_per_second = 0
                        panel.subtitle = f"[bold green]âœ“ å¯¹è¯å®Œæˆè€—æ—¶: {duration:.2f}ç§’, è¾“å…¥å­—ç¬¦æ•°: {len(message)}, è¾“å…¥Tokenæ•°é‡: {input_token_count}, è¾“å‡ºå­—ç¬¦æ•°: {char_count}, è¾“å‡ºTokenæ•°é‡: {token_count}, æ¯ç§’Tokenæ•°é‡: {tokens_per_second:.2f}[/bold green]"
                        live.update(panel)
                else:
                    for s in self.chat(message):
                        print(s, end="", flush=True)
                        response += s
                    print()
            else:
                for s in self.chat(message):
                    response += s
        # Keep original think tag handling
        response = re.sub(
            ot("think") + r".*?" + ct("think"), "", response, flags=re.DOTALL
        )
        response = re.sub(
            ot("thinking") + r".*?" + ct("thinking"), "", response, flags=re.DOTALL
        )
        return response

    def chat_until_success(self, message: str) -> str:
        """Chat with model until successful response"""
        try:
            set_in_chat(True)
            if not self.suppress_output and is_print_prompt():
                PrettyOutput.print(f"{message}", OutputType.USER)
            result: str = while_true(
                lambda: while_success(lambda: self._chat(message), 5), 5
            )
            from jarvis.jarvis_utils.globals import set_last_message

            set_last_message(result)
            return result
        finally:
            set_in_chat(False)

    @abstractmethod
    def name(self) -> str:
        """Model name"""
        raise NotImplementedError("name is not implemented")

    @classmethod
    @abstractmethod
    def platform_name(cls) -> str:
        """Platform name"""
        raise NotImplementedError("platform_name is not implemented")

    @abstractmethod
    def delete_chat(self) -> bool:
        """Delete chat"""
        raise NotImplementedError("delete_chat is not implemented")

    @abstractmethod
    def save(self, file_path: str) -> bool:
        """Save chat session to a file.

        Note:
            Implementations of this method should set `self._saved = True` upon successful saving
            to prevent the session from being deleted on object destruction.

        Args:
            file_path: The path to save the session file.

        Returns:
            True if saving is successful, False otherwise.
        """
        raise NotImplementedError("save is not implemented")

    @abstractmethod
    def restore(self, file_path: str) -> bool:
        """Restore chat session from a file.

        Args:
            file_path: The path to restore the session file from.

        Returns:
            True if restoring is successful, False otherwise.
        """
        raise NotImplementedError("restore is not implemented")

    @abstractmethod
    def set_system_prompt(self, message: str):
        """Set system message"""
        raise NotImplementedError("set_system_prompt is not implemented")

    @abstractmethod
    def get_model_list(self) -> List[Tuple[str, str]]:
        """Get model list"""
        raise NotImplementedError("get_model_list is not implemented")

    def set_suppress_output(self, suppress: bool):
        """Set whether to suppress output"""
        self.suppress_output = suppress

    def set_web(self, web: bool):
        """Set web flag"""
        self.web = web

    @abstractmethod
    def support_web(self) -> bool:
        """Check if platform supports web functionality"""
        return False
