"""æ™ºèƒ½ä¸Šä¸‹æ–‡æ¨èå™¨ã€‚

ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰ç†è§£ï¼Œæä¾›æ›´å‡†ç¡®çš„ä¸Šä¸‹æ–‡æ¨èã€‚
å®Œå…¨åŸºäºLLMå®ç°ï¼Œä¸ä¾èµ–ç¡¬ç¼–ç è§„åˆ™ã€‚
"""

import json
import os
import re
import yaml
from typing import List, Optional, Dict, Any, Set

from jarvis.jarvis_utils.output import OutputType, PrettyOutput

from .context_recommender import ContextRecommendation
from .context_manager import ContextManager
from .symbol_extractor import Symbol


class ContextRecommender:
    """æ™ºèƒ½ä¸Šä¸‹æ–‡æ¨èå™¨ã€‚
    
    ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰ç†è§£ï¼Œæ ¹æ®ç¼–è¾‘æ„å›¾æ¨èç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
    å®Œå…¨åŸºäºLLMå®ç°ï¼Œæä¾›è¯­ä¹‰çº§åˆ«çš„æ¨èï¼Œè€Œéç®€å•çš„å…³é”®è¯åŒ¹é…ã€‚
    """

    def __init__(self, context_manager: ContextManager, llm_model: Any):
        """åˆå§‹åŒ–ä¸Šä¸‹æ–‡æ¨èå™¨
        
        Args:
            context_manager: ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            llm_model: LLMæ¨¡å‹å®ä¾‹ï¼ˆå¿…éœ€ï¼‰
            
        Raises:
            ValueError: å¦‚æœæœªæä¾›LLMæ¨¡å‹
        """
        self.context_manager = context_manager
        self.llm_model = llm_model
        
        if not llm_model:
            raise ValueError("LLM model is required for context recommendation")

    def recommend_context(
        self,
        user_input: str,
        target_files: Optional[List[str]] = None,
        target_symbols: Optional[List[str]] = None,
    ) -> ContextRecommendation:
        """æ ¹æ®ç¼–è¾‘æ„å›¾æ¨èä¸Šä¸‹æ–‡
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥/ä»»åŠ¡æè¿°
            target_files: ç›®æ ‡æ–‡ä»¶åˆ—è¡¨ï¼ˆå¦‚æœå·²çŸ¥ï¼‰
            target_symbols: ç›®æ ‡ç¬¦å·åˆ—è¡¨ï¼ˆå¦‚æœå·²çŸ¥ï¼‰
            
        Returns:
            ContextRecommendation: æ¨èçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        # 1. ä½¿ç”¨LLMæå–æ„å›¾å’Œå®ä½“
        extracted_info = self._extract_intent_with_llm(user_input)
        
        # 2. åˆå¹¶æå–çš„ä¿¡æ¯
        if extracted_info.get("target_files"):
            target_files = (target_files or []) + extracted_info["target_files"]
        if extracted_info.get("target_symbols"):
            target_symbols = (target_symbols or []) + extracted_info["target_symbols"]
        
        # 3. åŸºäºç›®æ ‡æ–‡ä»¶æ¨èï¼ˆä¾èµ–å…³ç³»ã€æµ‹è¯•æ–‡ä»¶ç­‰ï¼‰
        recommended_files: Set[str] = set()
        recommended_symbols: List[Symbol] = []
        related_tests: Set[str] = set()
        reasons: List[str] = []
        
        if target_files:
            for file_path in target_files:
                # æ¨èä¾èµ–çš„æ–‡ä»¶
                deps = self.context_manager.dependency_graph.get_dependencies(file_path)
                recommended_files.update(deps)
                if deps:
                    reasons.append(f"æ–‡ä»¶ {os.path.basename(file_path)} çš„ä¾èµ–æ–‡ä»¶")

                # æ¨èä¾èµ–è¯¥æ–‡ä»¶çš„æ–‡ä»¶
                dependents = self.context_manager.dependency_graph.get_dependents(file_path)
                recommended_files.update(dependents)
                if dependents:
                    reasons.append(f"ä¾èµ–æ–‡ä»¶ {os.path.basename(file_path)} çš„æ–‡ä»¶")

                # æŸ¥æ‰¾ç›¸å…³æµ‹è¯•æ–‡ä»¶
                tests = self._find_test_files(file_path)
                related_tests.update(tests)
                if tests:
                    reasons.append(f"æ–‡ä»¶ {os.path.basename(file_path)} çš„æµ‹è¯•æ–‡ä»¶")

        # 4. åŸºäºç›®æ ‡ç¬¦å·æ¨è
        if target_symbols:
            for symbol_name in target_symbols:
                # æŸ¥æ‰¾ç¬¦å·å®šä¹‰
                symbol_def = self.context_manager.find_definition(symbol_name)
                if symbol_def:
                    recommended_symbols.append(symbol_def)
                    reasons.append(f"ç¬¦å· {symbol_name} çš„å®šä¹‰")

                # æŸ¥æ‰¾ç¬¦å·å¼•ç”¨
                references = self.context_manager.find_references(symbol_name)
                for ref in references[:5]:  # é™åˆ¶å¼•ç”¨æ•°é‡
                    if ref.file_path not in recommended_files:
                        recommended_files.add(ref.file_path)
                if references:
                    reasons.append(f"ç¬¦å· {symbol_name} çš„å¼•ç”¨ä½ç½®")

        # 5. ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰æœç´¢
        semantic_symbols = self._semantic_search_symbols(
            user_input, extracted_info.get("keywords", [])
        )
        semantic_files = self._semantic_search_files(
            user_input, extracted_info.get("keywords", [])
        )
        
        recommended_files.update(semantic_files)
        recommended_symbols.extend(semantic_symbols)
        if semantic_symbols or semantic_files:
            reasons.append("LLMè¯­ä¹‰æœç´¢")

        # 6. ä½¿ç”¨LLMå¯¹æ¨èç»“æœè¿›è¡Œç›¸å…³æ€§è¯„åˆ†å’Œæ’åº
        scored_files = self._score_files_with_llm(
            user_input,
            list(recommended_files),
        )
        scored_symbols = self._score_symbols_with_llm(
            user_input,
            recommended_symbols,
        )
        
        # 7. è¿‡æ»¤å’Œæ’åº
        final_files = [f for f, _ in sorted(scored_files.items(), key=lambda x: x[1], reverse=True)[:10]]
        final_symbols = [s for s, _ in sorted(scored_symbols.items(), key=lambda x: x[1], reverse=True)[:10]]
        
        # 8. æ›´æ–°æ¨èåŸå› 
        reason = "ï¼›".join(reasons[:3]) if reasons else "åŸºäºLLMè¯­ä¹‰åˆ†æ"
        if len(reasons) > 3:
            reason += f" ç­‰{len(reasons)}ä¸ªåŸå› "
        if extracted_info.get("intent") != "unknown":
            reason = f"åŸºäºLLMè¯­ä¹‰åˆ†æï¼ˆæ„å›¾ï¼š{extracted_info['intent']}ï¼‰ï¼›{reason}"

        return ContextRecommendation(
            recommended_files=final_files,
            recommended_symbols=final_symbols,
            related_tests=list(related_tests),
            reason=reason,
        )

    def _extract_intent_with_llm(self, user_input: str) -> Dict[str, Any]:
        """ä½¿ç”¨LLMæå–ç”¨æˆ·æ„å›¾å’Œå®ä½“
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            
        Returns:
            åŒ…å«æå–ä¿¡æ¯çš„å­—å…¸
        """
        prompt = f"""åˆ†æä»¥ä¸‹ä»£ç ç¼–è¾‘ä»»åŠ¡ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚è¯·ä»¥YAMLæ ¼å¼è¿”å›ç»“æœï¼Œå¹¶ç”¨<INTENT>æ ‡ç­¾åŒ…è£¹ã€‚

ä»»åŠ¡æè¿°ï¼š
{user_input}

è¯·æå–ä»¥ä¸‹ä¿¡æ¯ï¼š
1. intent: ç¼–è¾‘æ„å›¾ï¼ˆadd_feature, fix_bug, refactor, modify, optimize, test, documentç­‰ï¼‰
2. target_files: ç›®æ ‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆä»ä»»åŠ¡æè¿°ä¸­æ¨æ–­ï¼Œå¦‚æœæ˜ç¡®æåˆ°æ–‡ä»¶ï¼‰
3. target_symbols: ç›®æ ‡ç¬¦å·åç§°åˆ—è¡¨ï¼ˆå‡½æ•°åã€ç±»åã€å˜é‡åç­‰ï¼‰
4. keywords: å…³é”®æ¦‚å¿µåˆ—è¡¨ï¼ˆä¸ä»»åŠ¡ç›¸å…³çš„æŠ€æœ¯æ¦‚å¿µã€åŠŸèƒ½æ¨¡å—ç­‰ï¼‰
5. description: ä»»åŠ¡çš„æ ¸å¿ƒæè¿°ï¼ˆä¸€å¥è¯æ€»ç»“ï¼‰

åªè¿”å›YAMLæ ¼å¼ï¼Œç”¨<INTENT>æ ‡ç­¾åŒ…è£¹ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚å¦‚æœæŸé¡¹ä¿¡æ¯æ— æ³•ç¡®å®šï¼Œä½¿ç”¨ç©ºæ•°ç»„æˆ–ç©ºå­—ç¬¦ä¸²ã€‚

ç¤ºä¾‹æ ¼å¼ï¼š
<INTENT>
intent: fix_bug
target_files:
  - src/main.py
target_symbols:
  - process_data
  - validate_input
keywords:
  - data processing
  - validation
  - error handling
description: ä¿®å¤æ•°æ®å¤„ç†å‡½æ•°ä¸­çš„éªŒè¯é€»è¾‘é”™è¯¯
</INTENT>
"""

        try:
            response = self._call_llm(prompt)
            # å°è¯•è§£æYAMLå“åº”
            # ä»<INTENT>æ ‡ç­¾ä¸­æå–å†…å®¹
            response = response.strip()
            # æå–<INTENT>æ ‡ç­¾å†…çš„å†…å®¹
            # æ”¯æŒä¸¤ç§æ ¼å¼ï¼š<INTENT>...content...</INTENT> æˆ– <INTENT>...content...<INTENT>
            yaml_match = re.search(r'<INTENT>\s*(.*?)\s*(?:</INTENT>|<INTENT>)', response, re.DOTALL)
            if yaml_match:
                yaml_content = yaml_match.group(1).strip()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾ï¼Œå°è¯•æ¸…ç†markdownä»£ç å—
                if response.startswith("```yaml"):
                    response = response[7:]
                elif response.startswith("```"):
                    response = response[3:]
                if response.endswith("```"):
                    response = response[:-3]
                yaml_content = response.strip()
            
            extracted = yaml.safe_load(yaml_content)
            if extracted is None:
                extracted = {}
            return extracted
        except Exception as e:
            # è§£æå¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ
            PrettyOutput.print(f"LLMæ„å›¾æå–å¤±è´¥: {e}", OutputType.WARNING)
            return {
                "intent": "unknown",
                "target_files": [],
                "target_symbols": [],
                "keywords": [],
                "description": "",
            }

    def _semantic_search_symbols(
        self, user_input: str, keywords: List[str]
    ) -> List[Symbol]:
        """ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰æœç´¢ï¼ŒæŸ¥æ‰¾ç›¸å…³ç¬¦å·
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            keywords: å…³é”®è¯åˆ—è¡¨
            
        Returns:
            ç›¸å…³ç¬¦å·åˆ—è¡¨
        """
        if not keywords:
            return []
        
        # è·å–æ‰€æœ‰ç¬¦å·çš„æ‘˜è¦ä¿¡æ¯
        all_symbols = []
        for symbol_name, symbols in self.context_manager.symbol_table.symbols_by_name.items():
            for symbol in symbols[:1]:  # æ¯ä¸ªåç§°åªå–ç¬¬ä¸€ä¸ª
                all_symbols.append({
                    "name": symbol.name,
                    "kind": symbol.kind,
                    "file": os.path.basename(symbol.file_path),
                    "signature": symbol.signature or "",
                })
        
        if not all_symbols:
            return []
        
        # é™åˆ¶ç¬¦å·æ•°é‡ï¼Œé¿å…promptè¿‡é•¿
        symbols_sample = all_symbols[:50]  # æœ€å¤š50ä¸ªç¬¦å·
        
        prompt = f"""æ ¹æ®ä»¥ä¸‹ä»»åŠ¡æè¿°å’Œå…³é”®è¯ï¼Œä»ç¬¦å·åˆ—è¡¨ä¸­é€‰æ‹©æœ€ç›¸å…³çš„ç¬¦å·ã€‚

ä»»åŠ¡æè¿°ï¼š{user_input}
å…³é”®è¯ï¼š{', '.join(keywords)}

ç¬¦å·åˆ—è¡¨ï¼š
{yaml.dump(symbols_sample, allow_unicode=True, default_flow_style=False)}

è¯·è¿”å›æœ€ç›¸å…³çš„5-10ä¸ªç¬¦å·åç§°ï¼ˆYAMLæ•°ç»„æ ¼å¼ï¼‰ï¼ŒæŒ‰ç›¸å…³æ€§æ’åºï¼Œå¹¶ç”¨<SYMBOLS>æ ‡ç­¾åŒ…è£¹ã€‚
åªè¿”å›ç¬¦å·åç§°æ•°ç»„ï¼Œä¾‹å¦‚ï¼š
<SYMBOLS>
- symbol1
- symbol2
- symbol3
</SYMBOLS>
"""

        try:
            response = self._call_llm(prompt)
            # ä»<SYMBOLS>æ ‡ç­¾ä¸­æå–å†…å®¹
            response = response.strip()
            yaml_match = re.search(r'<SYMBOLS>\s*(.*?)\s*(?:</SYMBOLS>|<SYMBOLS>)', response, re.DOTALL)
            if yaml_match:
                yaml_content = yaml_match.group(1).strip()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾ï¼Œå°è¯•æ¸…ç†markdownä»£ç å—
                if response.startswith("```yaml"):
                    response = response[7:]
                elif response.startswith("```"):
                    response = response[3:]
                if response.endswith("```"):
                    response = response[:-3]
                yaml_content = response.strip()
            
            symbol_names = yaml.safe_load(yaml_content)
            if not isinstance(symbol_names, list):
                return []
            
            # æŸ¥æ‰¾å¯¹åº”çš„ç¬¦å·å¯¹è±¡
            found_symbols = []
            for name in symbol_names:
                symbols = self.context_manager.symbol_table.find_symbol(name)
                if symbols:
                    found_symbols.extend(symbols[:1])  # æ¯ä¸ªåç§°åªå–ç¬¬ä¸€ä¸ª
            
            return found_symbols
        except Exception:
            return []

    def _semantic_search_files(
        self, user_input: str, keywords: List[str]
    ) -> List[str]:
        """ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰æœç´¢ï¼ŒæŸ¥æ‰¾ç›¸å…³æ–‡ä»¶
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            keywords: å…³é”®è¯åˆ—è¡¨
            
        Returns:
            ç›¸å…³æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        # è·å–é¡¹ç›®ä¸­çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼Œåªè·å–å·²åˆ†æçš„æ–‡ä»¶ï¼‰
        known_files = list(self.context_manager.dependency_graph.dependencies.keys())
        known_files.extend(self.context_manager.dependency_graph.dependents.keys())
        
        if not known_files:
            return []
        
        # é™åˆ¶æ–‡ä»¶æ•°é‡
        files_sample = known_files[:30]  # æœ€å¤š30ä¸ªæ–‡ä»¶
        
        file_info = [
            {
                "path": os.path.relpath(f, self.context_manager.project_root),
                "basename": os.path.basename(f),
            }
            for f in files_sample
        ]
        
        prompt = f"""æ ¹æ®ä»¥ä¸‹ä»»åŠ¡æè¿°å’Œå…³é”®è¯ï¼Œä»æ–‡ä»¶åˆ—è¡¨ä¸­é€‰æ‹©æœ€ç›¸å…³çš„æ–‡ä»¶ã€‚

ä»»åŠ¡æè¿°ï¼š{user_input}
å…³é”®è¯ï¼š{', '.join(keywords)}

æ–‡ä»¶åˆ—è¡¨ï¼š
{yaml.dump(file_info, allow_unicode=True, default_flow_style=False)}

è¯·è¿”å›æœ€ç›¸å…³çš„5-10ä¸ªæ–‡ä»¶è·¯å¾„ï¼ˆYAMLæ•°ç»„æ ¼å¼ï¼‰ï¼ŒæŒ‰ç›¸å…³æ€§æ’åºï¼Œå¹¶ç”¨<FILES>æ ‡ç­¾åŒ…è£¹ã€‚
åªè¿”å›æ–‡ä»¶è·¯å¾„æ•°ç»„ï¼Œä¾‹å¦‚ï¼š
<FILES>
- path/to/file1.py
- path/to/file2.py
</FILES>
"""

        try:
            response = self._call_llm(prompt)
            # ä»<FILES>æ ‡ç­¾ä¸­æå–å†…å®¹
            response = response.strip()
            yaml_match = re.search(r'<FILES>\s*(.*?)\s*(?:</FILES>|<FILES>)', response, re.DOTALL)
            if yaml_match:
                yaml_content = yaml_match.group(1).strip()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾ï¼Œå°è¯•æ¸…ç†markdownä»£ç å—
                if response.startswith("```yaml"):
                    response = response[7:]
                elif response.startswith("```"):
                    response = response[3:]
                if response.endswith("```"):
                    response = response[:-3]
                yaml_content = response.strip()
            
            file_paths = yaml.safe_load(yaml_content)
            if not isinstance(file_paths, list):
                return []
            
            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            result = []
            for path in file_paths:
                abs_path = os.path.join(self.context_manager.project_root, path)
                if os.path.exists(abs_path):
                    result.append(abs_path)
            
            return result
        except Exception:
            return []

    def _score_files_with_llm(
        self, user_input: str, files: List[str]
    ) -> Dict[str, float]:
        """ä½¿ç”¨LLMå¯¹æ–‡ä»¶è¿›è¡Œç›¸å…³æ€§è¯„åˆ†
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            files: æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            æ–‡ä»¶è·¯å¾„åˆ°ç›¸å…³æ€§åˆ†æ•°çš„å­—å…¸
        """
        if not files:
            return {}
        
        # é™åˆ¶æ–‡ä»¶æ•°é‡ï¼Œé¿å…promptè¿‡é•¿
        files_to_score = files[:20]
        
        file_info = [
            {
                "path": os.path.relpath(f, self.context_manager.project_root),
                "basename": os.path.basename(f),
            }
            for f in files_to_score
        ]
        
        prompt = f"""æ ¹æ®ä»¥ä¸‹ä»»åŠ¡æè¿°ï¼Œå¯¹æ–‡ä»¶åˆ—è¡¨ä¸­çš„æ¯ä¸ªæ–‡ä»¶è¿›è¡Œç›¸å…³æ€§è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰ã€‚

ä»»åŠ¡æè¿°ï¼š{user_input}

æ–‡ä»¶åˆ—è¡¨ï¼š
{yaml.dump(file_info, allow_unicode=True, default_flow_style=False)}

è¯·è¿”å›YAMLå¯¹è±¡ï¼Œé”®ä¸ºæ–‡ä»¶è·¯å¾„ï¼Œå€¼ä¸ºç›¸å…³æ€§åˆ†æ•°ï¼ˆ0-10çš„æµ®ç‚¹æ•°ï¼‰ï¼Œå¹¶ç”¨<FILE_SCORES>æ ‡ç­¾åŒ…è£¹ã€‚
åªè¿”å›YAMLå¯¹è±¡ï¼Œä¾‹å¦‚ï¼š
<FILE_SCORES>
path/to/file1.py: 8.5
path/to/file2.py: 7.0
path/to/file3.py: 5.5
</FILE_SCORES>
"""

        try:
            response = self._call_llm(prompt)
            # ä»<FILE_SCORES>æ ‡ç­¾ä¸­æå–å†…å®¹
            response = response.strip()
            yaml_match = re.search(r'<FILE_SCORES>\s*(.*?)\s*(?:</FILE_SCORES>|<FILE_SCORES>)', response, re.DOTALL)
            if yaml_match:
                yaml_content = yaml_match.group(1).strip()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾ï¼Œå°è¯•æ¸…ç†markdownä»£ç å—
                if response.startswith("```yaml"):
                    response = response[7:]
                elif response.startswith("```"):
                    response = response[3:]
                if response.endswith("```"):
                    response = response[:-3]
                yaml_content = response.strip()
            
            scores = yaml.safe_load(yaml_content)
            if not isinstance(scores, dict):
                return {}
            
            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„çš„é”®
            result = {}
            for rel_path, score in scores.items():
                abs_path = os.path.join(self.context_manager.project_root, rel_path)
                if abs_path in files_to_score:
                    result[abs_path] = float(score)
            
            # ä¸ºæœªè¯„åˆ†çš„æ–‡ä»¶è®¾ç½®é»˜è®¤åˆ†æ•°
            for f in files_to_score:
                if f not in result:
                    result[f] = 5.0  # é»˜è®¤ä¸­ç­‰ç›¸å…³æ€§
            
            return result
        except Exception:
            # è¯„åˆ†å¤±è´¥ï¼Œè¿”å›é»˜è®¤åˆ†æ•°
            return {f: 5.0 for f in files_to_score}

    def _score_symbols_with_llm(
        self, user_input: str, symbols: List[Symbol]
    ) -> Dict[Symbol, float]:
        """ä½¿ç”¨LLMå¯¹ç¬¦å·è¿›è¡Œç›¸å…³æ€§è¯„åˆ†
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            symbols: ç¬¦å·åˆ—è¡¨
            
        Returns:
            ç¬¦å·åˆ°ç›¸å…³æ€§åˆ†æ•°çš„å­—å…¸
        """
        if not symbols:
            return {}
        
        # é™åˆ¶ç¬¦å·æ•°é‡
        symbols_to_score = symbols[:20]
        
        symbol_info = [
            {
                "name": s.name,
                "kind": s.kind,
                "file": os.path.basename(s.file_path),
                "signature": s.signature or "",
            }
            for s in symbols_to_score
        ]
        
        prompt = f"""æ ¹æ®ä»¥ä¸‹ä»»åŠ¡æè¿°ï¼Œå¯¹ç¬¦å·åˆ—è¡¨ä¸­çš„æ¯ä¸ªç¬¦å·è¿›è¡Œç›¸å…³æ€§è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰ã€‚

ä»»åŠ¡æè¿°ï¼š{user_input}

ç¬¦å·åˆ—è¡¨ï¼š
{yaml.dump(symbol_info, allow_unicode=True, default_flow_style=False)}

è¯·è¿”å›YAMLå¯¹è±¡ï¼Œé”®ä¸ºç¬¦å·åç§°ï¼Œå€¼ä¸ºç›¸å…³æ€§åˆ†æ•°ï¼ˆ0-10çš„æµ®ç‚¹æ•°ï¼‰ï¼Œå¹¶ç”¨<SYMBOL_SCORES>æ ‡ç­¾åŒ…è£¹ã€‚
åªè¿”å›YAMLå¯¹è±¡ï¼Œä¾‹å¦‚ï¼š
<SYMBOL_SCORES>
symbol1: 9.0
symbol2: 7.5
symbol3: 6.0
</SYMBOL_SCORES>
"""

        try:
            response = self._call_llm(prompt)
            # ä»<SYMBOL_SCORES>æ ‡ç­¾ä¸­æå–å†…å®¹
            response = response.strip()
            yaml_match = re.search(r'<SYMBOL_SCORES>\s*(.*?)\s*(?:</SYMBOL_SCORES>|<SYMBOL_SCORES>)', response, re.DOTALL)
            if yaml_match:
                yaml_content = yaml_match.group(1).strip()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾ï¼Œå°è¯•æ¸…ç†markdownä»£ç å—
                if response.startswith("```yaml"):
                    response = response[7:]
                elif response.startswith("```"):
                    response = response[3:]
                if response.endswith("```"):
                    response = response[:-3]
                yaml_content = response.strip()
            
            scores = yaml.safe_load(yaml_content)
            if not isinstance(scores, dict):
                return {}
            
            # åˆ›å»ºç¬¦å·åˆ°åˆ†æ•°çš„æ˜ å°„
            result = {}
            for s in symbols_to_score:
                score = scores.get(s.name, 5.0)  # é»˜è®¤ä¸­ç­‰ç›¸å…³æ€§
                result[s] = float(score)
            
            return result
        except Exception:
            # è¯„åˆ†å¤±è´¥ï¼Œè¿”å›é»˜è®¤åˆ†æ•°
            return {s: 5.0 for s in symbols_to_score}

    def _find_test_files(self, file_path: str) -> List[str]:
        """æŸ¥æ‰¾ä¸æ–‡ä»¶ç›¸å…³çš„æµ‹è¯•æ–‡ä»¶
        
        Args:
            file_path: æºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æµ‹è¯•æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        test_files = []
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        project_root = self.context_manager.project_root

        # å¸¸è§çš„æµ‹è¯•æ–‡ä»¶å‘½åæ¨¡å¼
        test_patterns = [
            f"test_{base_name}.py",
            f"{base_name}_test.py",
            f"test_{base_name}.js",
            f"{base_name}.test.js",
            f"test_{base_name}.ts",
            f"{base_name}.test.ts",
            f"{base_name}_test.rs",
            f"test_{base_name}.go",
        ]

        # åœ¨é¡¹ç›®æ ¹ç›®å½•æœç´¢æµ‹è¯•æ–‡ä»¶
        for root, dirs, files in os.walk(project_root):
            # è·³è¿‡éšè—ç›®å½•å’Œå¸¸è§å¿½ç•¥ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'target']]

            # æ£€æŸ¥æ˜¯å¦æ˜¯æµ‹è¯•ç›®å½•
            if 'test' in root.lower() or 'tests' in root.lower():
                for pattern in test_patterns:
                    if pattern in files:
                        test_file = os.path.join(root, pattern)
                        if os.path.exists(test_file):
                            test_files.append(test_file)

        return test_files[:5]  # é™åˆ¶æ•°é‡

    def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLMç”Ÿæˆå“åº”
        
        Args:
            prompt: æç¤ºè¯
            
        Returns:
            LLMç”Ÿæˆçš„å“åº”æ–‡æœ¬
        """
        if not self.llm_model:
            raise ValueError("LLM model not available")
        
        try:
            # ä½¿ç”¨chat_until_successæ–¹æ³•ï¼ˆBasePlatformçš„æ ‡å‡†æ¥å£ï¼‰
            if hasattr(self.llm_model, 'chat_until_success'):
                response = self.llm_model.chat_until_success(prompt)
                return response
            else:
                # å¦‚æœä¸æ”¯æŒchat_until_successï¼ŒæŠ›å‡ºå¼‚å¸¸
                raise ValueError("LLM model does not support chat_until_success interface")
        except Exception as e:
            PrettyOutput.print(f"LLMè°ƒç”¨å¤±è´¥: {e}", OutputType.WARNING)
            raise

    def format_recommendation(self, recommendation: ContextRecommendation) -> str:
        """æ ¼å¼åŒ–æ¨èç»“æœä¸ºå¯è¯»æ–‡æœ¬
        
        Args:
            recommendation: æ¨èç»“æœ
            
        Returns:
            æ ¼å¼åŒ–çš„æ–‡æœ¬
        """
        lines = ["\nğŸ’¡ æ™ºèƒ½ä¸Šä¸‹æ–‡æ¨è:"]
        lines.append("â”€" * 60)

        if recommendation.reason:
            lines.append(f"ğŸ“Œ æ¨èåŸå› : {recommendation.reason}")

        if recommendation.recommended_files:
            files_str = "\n   ".join(
                f"â€¢ {os.path.relpath(f, self.context_manager.project_root)}"
                for f in recommendation.recommended_files[:5]
            )
            more = len(recommendation.recommended_files) - 5
            if more > 0:
                files_str += f"\n   ... è¿˜æœ‰{more}ä¸ªæ–‡ä»¶"
            lines.append(f"ğŸ“ æ¨èæ–‡ä»¶ ({len(recommendation.recommended_files)}ä¸ª):\n   {files_str}")

        if recommendation.recommended_symbols:
            symbols_str = "\n   ".join(
                f"â€¢ {s.kind} `{s.name}` ({os.path.relpath(s.file_path, self.context_manager.project_root)}:{s.line_start})"
                for s in recommendation.recommended_symbols[:5]
            )
            more = len(recommendation.recommended_symbols) - 5
            if more > 0:
                symbols_str += f"\n   ... è¿˜æœ‰{more}ä¸ªç¬¦å·"
            lines.append(f"ğŸ”— æ¨èç¬¦å· ({len(recommendation.recommended_symbols)}ä¸ª):\n   {symbols_str}")

        if recommendation.related_tests:
            tests_str = "\n   ".join(
                f"â€¢ {os.path.relpath(f, self.context_manager.project_root)}"
                for f in recommendation.related_tests[:3]
            )
            more = len(recommendation.related_tests) - 3
            if more > 0:
                tests_str += f"\n   ... è¿˜æœ‰{more}ä¸ªæµ‹è¯•æ–‡ä»¶"
            lines.append(f"ğŸ§ª ç›¸å…³æµ‹è¯• ({len(recommendation.related_tests)}ä¸ª):\n   {tests_str}")

        lines.append("â”€" * 60)
        lines.append("")  # ç©ºè¡Œ

        return "\n".join(lines) if len(lines) > 2 else ""  # å¦‚æœæ²¡æœ‰æ¨èå†…å®¹ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
