# -*- coding: utf-8 -*-
"""
Jarvis å®‰å…¨åˆ†æå¥—ä»¶ â€”â€” Workflowï¼ˆå«å¯å¤ç°ç›´æ‰«åŸºçº¿ï¼‰

ç›®æ ‡ï¼š
- è¯†åˆ«æŒ‡å®šæ¨¡å—çš„å®‰å…¨é—®é¢˜ï¼ˆå†…å­˜ç®¡ç†ã€ç¼“å†²åŒºæ“ä½œã€é”™è¯¯å¤„ç†ç­‰ï¼‰ï¼Œæ£€å‡ºç‡â‰¥60% ä¸ºç›®æ ‡ã€‚
- åœ¨ä¸ä¾èµ–å¤–éƒ¨æœåŠ¡çš„å‰æä¸‹ï¼Œæä¾›ä¸€ä¸ªâ€œå¯å¤ç°ã€å¯ç¦»çº¿â€çš„ç›´æ‰«åŸºçº¿ï¼ˆdirect scanï¼‰ã€‚
- å½“å‰é‡‡ç”¨â€œå…ˆç›´æ‰«æ‹†åˆ†å­ä»»åŠ¡ï¼Œå†ç”±å•Agenté€æ¡åˆ†æâ€çš„æ¨¡å¼ï¼›ä¿ç•™æ¥å£ä¾¿äºåç»­åˆ‡æ¢ã€‚

æœ¬æ¨¡å—æä¾›ï¼š
- direct_scan(entry_path, languages=None, exclude_dirs=None) -> Dictï¼šçº¯Python+æ­£åˆ™/å‘½ä»¤è¡Œè¾…åŠ©æ‰«æï¼Œç”Ÿæˆç»“æ„åŒ–ç»“æœ
- format_markdown_report(result_json: Dict) -> strï¼šå°†ç»“æ„åŒ–ç»“æœè½¬ä¸ºå¯è¯»çš„ Markdown

- run_with_agent(entry_path, languages=None) -> strï¼šä½¿ç”¨å•Agenté€æ¡å­ä»»åŠ¡åˆ†ææ¨¡å¼ï¼ˆå¤ç”¨ jarvis.jarvis_sec.__init__ çš„å®ç°ï¼‰
"""

from dataclasses import asdict
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, cast

from jarvis.jarvis_utils.output import PrettyOutput
from jarvis.jarvis_sec.checkers import analyze_c_files
from jarvis.jarvis_sec.checkers import analyze_rust_files
from jarvis.jarvis_sec.types import Issue

# ---------------------------
# æ•°æ®ç»“æ„
# ---------------------------

# Issue dataclass is provided by jarvis.jarvis_sec.types to avoid circular imports


# ---------------------------
# å·¥å…·å‡½æ•°
# ---------------------------


def _iter_source_files(
    entry_path: str,
    languages: Optional[List[str]] = None,
    exclude_dirs: Optional[List[str]] = None,
) -> Iterable[Path]:
    """
    é€’å½’æšä¸¾æºæ–‡ä»¶ï¼Œæ”¯æŒæŒ‰æ‰©å±•åè¿‡æ»¤ä¸ç›®å½•æ’é™¤ã€‚
    é»˜è®¤è¯­è¨€æ‰©å±•ï¼šc, cpp, h, hpp, rs
    """
    entry = Path(entry_path)
    if not entry.exists():
        return

    exts = set((languages or ["c", "cpp", "h", "hpp", "rs"]))
    excludes = set(
        exclude_dirs
        or [
            ".git",
            "build",
            "out",
            "target",
            "dist",
            "bin",
            "obj",
            "third_party",
            "vendor",
            "deps",
            "dependencies",
            "libs",
            "libraries",
            "external",
            "node_modules",
            "test",
            "tests",
            "__tests__",
            "spec",
            "testsuite",
            "testdata",
            "benchmark",
            "benchmarks",
            "perf",
            "performance",
            "bench",
            "benches",
            "profiling",
            "profiler",
            "example",
            "examples",
            "tmp",
            "temp",
            "cache",
            ".cache",
            "docs",
            "doc",
            "documentation",
            "generated",
            "gen",
            "mocks",
            "fixtures",
            "samples",
            "sample",
            "playground",
            "sandbox",
        ]
    )

    for p in entry.rglob("*"):
        if not p.is_file():
            continue
        # ç›®å½•æ’é™¤ï¼ˆä»»æ„ç¥–å…ˆåŒ…å«å³æ’é™¤ï¼‰
        skip = False
        for parent in p.parents:
            if parent.name in excludes:
                skip = True
                break
        if skip:
            continue

        suf = p.suffix.lstrip(".").lower()
        if suf in exts:
            yield p.relative_to(entry)


# ---------------------------
# æ±‡æ€»ä¸æŠ¥å‘Š
# ---------------------------


def direct_scan(
    entry_path: str,
    languages: Optional[List[str]] = None,
    exclude_dirs: Optional[List[str]] = None,
) -> Dict[str, Any]:
    """
    ç›´æ‰«åŸºçº¿ï¼šå¯¹ C/C++/Rust è¿›è¡Œå¯å‘å¼æ‰«æï¼Œè¾“å‡ºç»“æ„åŒ– JSONã€‚
    - æ”¹è¿›ï¼šå§”æ´¾è‡³æ¨¡å—åŒ–æ£€æŸ¥å™¨ï¼ˆoh_sec.checkersï¼‰ï¼Œç»Ÿä¸€è§„åˆ™ä¸ç½®ä¿¡åº¦æ¨¡å‹ã€‚
    """
    base = Path(entry_path).resolve()
    # è®¡ç®—å®é™…ä½¿ç”¨çš„æ’é™¤ç›®å½•åˆ—è¡¨
    default_excludes = [
        ".git",
        "build",
        "out",
        "target",
        "dist",
        "bin",
        "obj",
        "third_party",
        "vendor",
        "deps",
        "dependencies",
        "libs",
        "libraries",
        "external",
        "node_modules",
        "test",
        "tests",
        "__tests__",
        "spec",
        "testsuite",
        "testdata",
        "benchmark",
        "benchmarks",
        "perf",
        "performance",
        "bench",
        "benches",
        "profiling",
        "profiler",
        "example",
        "examples",
        "tmp",
        "temp",
        "cache",
        ".cache",
        "docs",
        "doc",
        "documentation",
        "generated",
        "gen",
        "mocks",
        "fixtures",
        "samples",
        "sample",
        "playground",
        "sandbox",
    ]
    actual_excludes = exclude_dirs if exclude_dirs is not None else default_excludes

    # æ£€æŸ¥ä»£ç åº“ä¸­å®é™…å­˜åœ¨çš„æ’é™¤ç›®å½•
    excludes_set = set(actual_excludes)
    actual_excluded_dirs = []
    for item in base.rglob("*"):
        if item.is_dir() and item.name in excludes_set:
            rel_path = item.relative_to(base)
            if str(rel_path) not in actual_excluded_dirs:
                actual_excluded_dirs.append(str(rel_path))

    if actual_excluded_dirs:
        PrettyOutput.auto_print("[jarvis-sec] å®é™…æ’é™¤çš„ç›®å½•:")
        for dir_path in sorted(actual_excluded_dirs):
            PrettyOutput.auto_print(f"  - {dir_path}")
    else:
        PrettyOutput.auto_print(
            f"[jarvis-sec] æœªå‘ç°éœ€è¦æ’é™¤çš„ç›®å½•ï¼ˆé…ç½®çš„æ’é™¤ç›®å½•: {', '.join(sorted(actual_excludes))}ï¼‰"
        )

    files = list(_iter_source_files(entry_path, languages, exclude_dirs))

    # æŒ‰è¯­è¨€åˆ†ç»„
    c_like_exts = {".c", ".cpp", ".h", ".hpp"}
    rust_exts = {".rs"}
    c_files: List[Path] = [p for p in files if p.suffix.lower() in c_like_exts]
    r_files: List[Path] = [p for p in files if p.suffix.lower() in rust_exts]

    # è°ƒç”¨æ£€æŸ¥å™¨ï¼ˆä¿æŒç›¸å¯¹è·¯å¾„ï¼ŒåŸºäº base_path è§£æï¼‰
    issues_c = analyze_c_files(str(base), [str(p) for p in c_files]) if c_files else []
    issues_r = (
        analyze_rust_files(str(base), [str(p) for p in r_files]) if r_files else []
    )
    issues: List[Issue] = issues_c + issues_r

    summary: Dict[str, Any] = {
        "total": len(issues),
        "by_language": {"c/cpp": 0, "rust": 0},
        "by_category": {},
        "top_risk_files": [],
        "scanned_files": len(files),
        "scanned_root": str(base),
    }
    file_score: Dict[str, int] = {}
    # Safely update language/category counts with explicit typing
    lang_counts = cast(Dict[str, int], summary["by_language"])
    cat_counts = cast(Dict[str, int], summary["by_category"])
    for it in issues:
        lang_counts[it.language] = lang_counts.get(it.language, 0) + 1
        cat_counts[it.category] = cat_counts.get(it.category, 0) + 1
        file_score[it.file] = file_score.get(it.file, 0) + 1
    # Top é£é™©æ–‡ä»¶
    summary["top_risk_files"] = [
        f for f, _ in sorted(file_score.items(), key=lambda x: x[1], reverse=True)[:10]
    ]

    result = {
        "summary": summary,
        "issues": [asdict(i) for i in issues],
    }
    return result


def format_markdown_report(result_json: Dict[str, Any]) -> str:
    """
    å°†ç»“æ„åŒ– JSON è½¬ä¸º Markdown å¯è¯»æŠ¥å‘Šã€‚
    """
    s = result_json.get("summary", {})
    issues: List[Dict[str, Any]] = result_json.get("issues", [])
    md: List[str] = []
    md.append("# Jarvis å®‰å…¨é—®é¢˜åˆ†ææŠ¥å‘Šï¼ˆç›´æ‰«åŸºçº¿ï¼‰")
    md.append("")
    md.append(f"- æ‰«ææ ¹ç›®å½•: {s.get('scanned_root', '')}")
    md.append(f"- æ‰«ææ–‡ä»¶æ•°: {s.get('scanned_files', 0)}")
    md.append(f"- æ£€å‡ºé—®é¢˜æ€»æ•°: {s.get('total', 0)}")
    md.append("")
    md.append("## ç»Ÿè®¡æ¦‚è§ˆ")
    by_lang = s.get("by_language", {})
    md.append(
        f"- æŒ‰è¯­è¨€: c/cpp={by_lang.get('c/cpp', 0)}, rust={by_lang.get('rust', 0)}"
    )
    md.append("- æŒ‰ç±»åˆ«:")
    for k, v in s.get("by_category", {}).items():
        md.append(f"  - {k}: {v}")
    if s.get("top_risk_files"):
        md.append("- Top é£é™©æ–‡ä»¶:")
        for f in s["top_risk_files"]:
            md.append(f"  - {f}")
    md.append("")
    md.append("## è¯¦ç»†é—®é¢˜")
    for i, it in enumerate(issues, start=1):
        md.append(
            f"### [{i}] {it.get('file')}:{it.get('line')} ({it.get('language')}, {it.get('category')})"
        )
        md.append(f"- æ¨¡å¼: {it.get('pattern')}")
        md.append(f"- è¯æ®: `{it.get('evidence')}`")
        md.append(f"- æè¿°: {it.get('description')}")
        md.append(f"- å»ºè®®: {it.get('suggestion')}")
        md.append(f"- ç½®ä¿¡åº¦: {it.get('confidence')}, ä¸¥é‡æ€§: {it.get('severity')}")
        md.append("")
    return "\n".join(md)


def run_with_agent(
    entry_path: str,
    languages: Optional[List[str]] = None,
    report_file: Optional[str] = None,
    cluster_limit: int = 50,
    exclude_dirs: Optional[List[str]] = None,
    enable_verification: bool = True,
    force_save_memory: bool = False,
    output_file: Optional[str] = None,
) -> str:
    """
    ä½¿ç”¨å•Agenté€æ¡å­ä»»åŠ¡åˆ†ææ¨¡å¼è¿è¡Œï¼ˆä¸ jarvis.jarvis_sec.__init__ ä¸­ä¿æŒä¸€è‡´ï¼‰ã€‚
    - å…ˆæ‰§è¡Œæœ¬åœ°ç›´æ‰«ï¼Œç”Ÿæˆå€™é€‰é—®é¢˜
    - ä¸ºæ¯æ¡å€™é€‰åˆ›å»ºä¸€æ¬¡æ™®é€šAgentä»»åŠ¡è¿›è¡Œåˆ†æä¸éªŒè¯
    - èšåˆä¸ºæœ€ç»ˆæŠ¥å‘Šï¼ˆJSON + Markdownï¼‰è¿”å›

    å…¶ä»–ï¼š
    - report_file: JSONL æŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé€ä¼ ï¼‰
    - cluster_limit: èšç±»æ—¶æ¯æ‰¹æ¬¡æœ€å¤šå¤„ç†çš„å‘Šè­¦æ•°ï¼ˆé»˜è®¤ 50ï¼‰ï¼Œå½“å•ä¸ªæ–‡ä»¶å‘Šè­¦è¿‡å¤šæ—¶æŒ‰æ‰¹æ¬¡è¿›è¡Œèšç±»
    - exclude_dirs: è¦æ’é™¤çš„ç›®å½•åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ï¼Œé»˜è®¤å·²åŒ…å«æ„å»ºäº§ç‰©ï¼ˆbuild, out, target, dist, bin, objï¼‰ã€ä¾èµ–ç›®å½•ï¼ˆthird_party, vendor, deps, dependencies, libs, libraries, external, node_modulesï¼‰ã€æµ‹è¯•ç›®å½•ï¼ˆtest, tests, __tests__, spec, testsuite, testdataï¼‰ã€æ€§èƒ½æµ‹è¯•ç›®å½•ï¼ˆbenchmark, benchmarks, perf, performance, bench, benches, profiling, profilerï¼‰ã€ç¤ºä¾‹ç›®å½•ï¼ˆexample, examplesï¼‰ã€ä¸´æ—¶/ç¼“å­˜ï¼ˆtmp, temp, cache, .cacheï¼‰ã€æ–‡æ¡£ï¼ˆdocs, doc, documentationï¼‰ã€ç”Ÿæˆä»£ç ï¼ˆgenerated, genï¼‰å’Œå…¶ä»–ï¼ˆmocks, fixtures, samples, sample, playground, sandboxï¼‰
    - enable_verification: æ˜¯å¦å¯ç”¨äºŒæ¬¡éªŒè¯ï¼ˆé»˜è®¤ Trueï¼‰ï¼Œå…³é—­ååˆ†æAgentç¡®è®¤çš„é—®é¢˜å°†ç›´æ¥å†™å…¥æŠ¥å‘Š
    """
    from jarvis.jarvis_sec import run_security_analysis  # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯

    return run_security_analysis(
        entry_path,
        languages=languages,
        report_file=report_file,
        cluster_limit=cluster_limit,
        exclude_dirs=exclude_dirs,
        enable_verification=enable_verification,
        force_save_memory=force_save_memory,
        output_file=output_file,
    )


# ---------------------------
# å¤–éƒ¨æ ¼å¼åˆ†ææ”¯æŒ
# ---------------------------


def _validate_format(data: Any) -> bool:
    """
    éªŒè¯å¤–éƒ¨æ•°æ®æ˜¯å¦ç¬¦åˆæ ‡å‡† Issue æ ¼å¼ã€‚

    æ ‡å‡†æ ¼å¼ï¼š
    {
        "issues": [
            {
                "language": "c",
                "category": "memory",
                "pattern": "strcpy",
                "file": "src/main.c",
                "line": 42,
                "evidence": "strcpy(dest, src)",
                "description": "Unsafe string copy",
                "suggestion": "Use strncpy instead",
                "confidence": 0.8,
                "severity": "high"
            }
        ]
    }

    æˆ–è€…ç›´æ¥æ˜¯ä¸€ä¸ªæ•°ç»„ï¼š[Issue, ...]
    """
    if isinstance(data, list):
        # ç›´æ¥æ˜¯æ•°ç»„æ ¼å¼
        if not data:
            return False
        item = data[0]
        return isinstance(item, dict) and all(
            k in item
            for k in [
                "language",
                "category",
                "pattern",
                "file",
                "line",
                "evidence",
                "description",
                "suggestion",
                "confidence",
            ]
        )
    elif isinstance(data, dict):
        # å¯¹è±¡æ ¼å¼ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ "issues" å­—æ®µ
        if "issues" not in data:
            return False
        issues = data["issues"]
        if not isinstance(issues, list) or not issues:
            return False
        item = issues[0]
        return isinstance(item, dict) and all(
            k in item
            for k in [
                "language",
                "category",
                "pattern",
                "file",
                "line",
                "evidence",
                "description",
                "suggestion",
                "confidence",
            ]
        )
    return False


def _create_conversion_agent(
    input_file: str,
    output_file: str,
) -> Any:
    """
    åˆ›å»ºè½¬æ¢ Agentï¼Œå­¦ä¹ å¤–éƒ¨æ–‡ä»¶æ ¼å¼å¹¶ç”Ÿæˆè½¬æ¢è„šæœ¬ã€‚

    å‚æ•°ï¼š
    - input_file: å¤–éƒ¨ JSON æ–‡ä»¶è·¯å¾„
    - output_file: è¾“å‡ºæ ‡å‡†æ ¼å¼ JSON æ–‡ä»¶è·¯å¾„

    è¿”å›ï¼š
    - è½¬æ¢åçš„æ ‡å‡†æ ¼å¼æ•°æ®ï¼ˆå­—å…¸ï¼‰

    å¼‚å¸¸ï¼š
    - è½¬æ¢å¤±è´¥æ—¶æŠ›å‡º RuntimeError
    """
    import json
    import tempfile

    from jarvis.jarvis_agent import Agent
    from jarvis.jarvis_utils.output import PrettyOutput

    # è¯»å–å¤–éƒ¨æ–‡ä»¶æ ·æœ¬
    input_path = Path(input_file)
    if not input_path.exists():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")

    with input_path.open("r", encoding="utf-8") as f:
        external_data = json.load(f)

    # æ„å»ºè½¬æ¢æç¤ºè¯
    conversion_prompt = f"""# ä»»åŠ¡ï¼šæ ¼å¼è½¬æ¢è„šæœ¬ç”Ÿæˆ

## ç›®æ ‡
ä½ éœ€è¦åˆ†æå¤–éƒ¨æ‰«æå·¥å…·çš„ JSON æ ¼å¼ï¼Œå¹¶ç¼–å†™ä¸€ä¸ª Python è„šæœ¬å°†å…¶è½¬æ¢ä¸ºæ ‡å‡†çš„å®‰å…¨é—®é¢˜æ ¼å¼ã€‚

## å¤–éƒ¨æ•°æ®æ ·æœ¬
```json
{json.dumps(external_data, indent=2, ensure_ascii=False)[:5000]}
```

## æ ‡å‡†æ ¼å¼
```json
{{
    "issues": [
        {{
            "language": "c",
            "category": "memory",
            "pattern": "strcpy",
            "file": "src/main.c",
            "line": 42,
            "evidence": "strcpy(dest, src)",
            "description": "Unsafe string copy",
            "suggestion": "Use strncpy instead",
            "confidence": 0.8,
            "severity": "high"
        }}
    ]
}}
```

## å­—æ®µæ˜ å°„è¯´æ˜
- language: ç¼–ç¨‹è¯­è¨€ï¼ˆc/cpp/rust ç­‰ï¼‰
- category: é—®é¢˜ç±»åˆ«ï¼ˆmemory/buffer/error_handling ç­‰ï¼‰
- pattern: æ£€æµ‹æ¨¡å¼ï¼ˆå‡½æ•°åã€APIè°ƒç”¨ç­‰ï¼‰
- file: æºä»£ç æ–‡ä»¶è·¯å¾„
- line: ä»£ç è¡Œå·ï¼ˆæ•´æ•°ï¼‰
- evidence: é—®é¢˜è¯æ®ï¼ˆä»£ç ç‰‡æ®µï¼‰
- description: é—®é¢˜æè¿°
- suggestion: ä¿®å¤å»ºè®®
- confidence: ç½®ä¿¡åº¦ï¼ˆ0-1 çš„æµ®ç‚¹æ•°ï¼‰
- severity: ä¸¥é‡ç¨‹åº¦ï¼ˆlow/medium/high/criticalï¼Œå¯é€‰ï¼Œé»˜è®¤ mediumï¼‰

## è¦æ±‚
1. ç¼–å†™ä¸€ä¸ª Python è„šæœ¬ï¼Œè¯»å– `{input_file}`ï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œè¾“å‡ºåˆ° `{output_file}`
2. è„šæœ¬å¿…é¡»ä½¿ç”¨ json åº“å¤„ç† JSON æ–‡ä»¶
3. å¦‚æœå¤–éƒ¨æ•°æ®ä¸­ç¼ºå°‘æŸäº›å­—æ®µï¼Œä½¿ç”¨åˆç†çš„é»˜è®¤å€¼ï¼š
   - severity: "medium"
   - confidence: 0.5
   - language: ä»æ–‡ä»¶æ‰©å±•åæ¨æ–­ï¼ˆ.c/.h -> c, .cpp/.hpp -> cpp, .rs -> rustï¼‰
4. è„šæœ¬å¿…é¡»æœ‰é”™è¯¯å¤„ç†ï¼ˆtry-exceptï¼‰
5. è¾“å‡ºå®Œæ•´çš„å¯æ‰§è¡Œ Python è„šæœ¬ä»£ç ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ–‡å­—

## è¾“å‡ºæ ¼å¼
åªè¾“å‡º Python è„šæœ¬ä»£ç ï¼Œä¸è¦åŒ…å« markdown æ ‡è®°æˆ–å…¶ä»–è¯´æ˜ã€‚
"""

    PrettyOutput.auto_print("ğŸ“ [jarvis-sec] æ­£åœ¨å­¦ä¹ å¤–éƒ¨æ–‡ä»¶æ ¼å¼å¹¶ç”Ÿæˆè½¬æ¢è„šæœ¬...")

    # åˆ›å»º Agent
    agent = Agent(
        system_prompt="""ä½ æ˜¯ä¸€ä¸ªå®‰å…¨æ‰«ææ ¼å¼è½¬æ¢ä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯åˆ†æå¤–éƒ¨æ‰«æå·¥å…·çš„JSONæ ¼å¼ï¼Œå¹¶ç”ŸæˆPythonè½¬æ¢è„šæœ¬ï¼Œå°†å…¶è½¬æ¢ä¸ºæ ‡å‡†çš„å®‰å…¨é—®é¢˜æ ¼å¼ã€‚
""",
        name="format_converter",
        description="å®‰å…¨æ‰«ææ ¼å¼è½¬æ¢ä¸“å®¶",
        use_tools=["read_code", "execute_script"],
    )

    # æ‰§è¡Œè½¬æ¢
    try:
        response = agent.run(conversion_prompt)

        # æå–è„šæœ¬ä»£ç ï¼ˆç§»é™¤å¯èƒ½çš„ markdown æ ‡è®°ï¼‰
        script = response.strip()
        if script.startswith("```python"):
            script = script[9:]
        if script.startswith("```"):
            script = script[3:]
        if script.endswith("```"):
            script = script[:-3]
        script = script.strip()

        # ä¿å­˜è½¬æ¢è„šæœ¬åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".py", delete=False, encoding="utf-8"
        ) as f:
            script_file = f.name
            f.write(script)

        PrettyOutput.auto_print(f"ğŸ”§ [jarvis-sec] è½¬æ¢è„šæœ¬å·²ç”Ÿæˆ: {script_file}")

        # æ‰§è¡Œè½¬æ¢è„šæœ¬
        import subprocess

        result = subprocess.run(
            ["python3", script_file],
            capture_output=True,
            text=True,
            timeout=60,
        )

        # æ¸…ç†ä¸´æ—¶è„šæœ¬æ–‡ä»¶
        try:
            Path(script_file).unlink()
        except Exception:
            pass

        if result.returncode != 0:
            raise RuntimeError(f"è½¬æ¢è„šæœ¬æ‰§è¡Œå¤±è´¥: {result.stderr}")

        PrettyOutput.auto_print(f"âœ… [jarvis-sec] æ ¼å¼è½¬æ¢æˆåŠŸ: {output_file}")

        # è¯»å–è½¬æ¢åçš„æ•°æ®
        output_path = Path(output_file)
        with output_path.open("r", encoding="utf-8") as f:
            converted_data = json.load(f)

        return converted_data

    except Exception as e:
        raise RuntimeError(f"æ ¼å¼è½¬æ¢å¤±è´¥: {e}") from e


def analyze_from_json(
    input_file: str,
    cluster_limit: int = 50,
    enable_verification: bool = True,
    force_save_memory: bool = False,
    output_file: Optional[str] = None,
) -> str:
    """
    ä»å¤–éƒ¨ JSON æ–‡ä»¶åˆ†æå®‰å…¨é—®é¢˜ã€‚

    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. æ ‡å‡†æ ¼å¼ï¼šç›´æ¥åˆ†æ
    2. éæ ‡å‡†æ ¼å¼ï¼šè‡ªåŠ¨åˆ›å»º Agent å­¦ä¹ æ ¼å¼å¹¶è½¬æ¢

    å‚æ•°ï¼š
    - input_file: å¤–éƒ¨ JSON æ–‡ä»¶è·¯å¾„
    - cluster_limit: èšç±»æ—¶æ¯æ‰¹æ¬¡æœ€å¤šå¤„ç†çš„å‘Šè­¦æ•°ï¼ˆé»˜è®¤ 50ï¼‰
    - enable_verification: æ˜¯å¦å¯ç”¨äºŒæ¬¡éªŒè¯ï¼ˆé»˜è®¤ Trueï¼‰
    - force_save_memory: æ˜¯å¦å¼ºåˆ¶ä¿å­˜è®°å¿†ï¼ˆé»˜è®¤ Falseï¼‰
    - output_file: è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    - max_retries: æ ¼å¼è½¬æ¢æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ 3ï¼‰

    è¿”å›ï¼š
    - æœ€ç»ˆæŠ¥å‘Šï¼ˆå­—ç¬¦ä¸²ï¼‰

    å¼‚å¸¸ï¼š
    - è½¬æ¢å¤±è´¥è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°æ—¶æŠ›å‡º RuntimeError
    """
    import json
    import tempfile

    from jarvis.jarvis_utils.output import PrettyOutput

    input_path = Path(input_file)
    if not input_path.exists():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")

    # è¯»å–å¤–éƒ¨æ•°æ®
    with input_path.open("r", encoding="utf-8") as f:
        external_data = json.load(f)

    # æ£€æŸ¥æ ¼å¼
    if _validate_format(external_data):
        PrettyOutput.auto_print("âœ… [jarvis-sec] æ£€æµ‹åˆ°æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥åˆ†æ")
        candidates = (
            external_data
            if isinstance(external_data, list)
            else external_data["issues"]
        )
    else:
        PrettyOutput.auto_print("âš ï¸  [jarvis-sec] æ£€æµ‹åˆ°éæ ‡å‡†æ ¼å¼ï¼Œå¯åŠ¨æ™ºèƒ½è½¬æ¢")

        # å°è¯•æ ¼å¼è½¬æ¢ï¼ˆæ— é™é‡è¯•ç›´åˆ°ç”¨æˆ·å–æ¶ˆï¼‰
        retries = 0
        converted_data = None

        while True:
            try:
                # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
                temp_output = ""
                with tempfile.NamedTemporaryFile(  # type: ignore[arg-type]
                    mode="w", suffix=".json", delete=False, encoding="utf-8"
                ) as f:
                    temp_output = f.name

                # æ‰§è¡Œè½¬æ¢
                converted_data = _create_conversion_agent(str(input_path), temp_output)

                # éªŒè¯è½¬æ¢ç»“æœ
                if not _validate_format(converted_data):
                    raise RuntimeError("è½¬æ¢åçš„æ ¼å¼ä»ç„¶ä¸ç¬¦åˆæ ‡å‡†")

                # æå– candidates åˆ—è¡¨
                if isinstance(converted_data, list):
                    candidates = converted_data
                else:
                    candidates = converted_data.get("issues", [])

                # ä¿å­˜è½¬æ¢åçš„æ–‡ä»¶ç”¨äºåç»­ä½¿ç”¨
                converted_output = (
                    input_path.parent / f"{input_path.stem}_converted.json"
                )
                with Path(converted_output).open("w", encoding="utf-8") as f:
                    json.dump(converted_data, f, indent=2, ensure_ascii=False)
                PrettyOutput.auto_print(
                    f"ğŸ’¾ [jarvis-sec] è½¬æ¢ç»“æœå·²ä¿å­˜: {converted_output}"
                )

                break

            except Exception as e:
                retries += 1
                PrettyOutput.auto_print(
                    f"âŒ [jarvis-sec] æ ¼å¼è½¬æ¢å¤±è´¥ (ç¬¬ {retries} æ¬¡å°è¯•): {e}"
                )

                # è¯¢é—®ç”¨æˆ·æ˜¯å¦é‡è¯•
                PrettyOutput.auto_print(
                    "\nğŸ¤” [jarvis-sec] æ ¼å¼è½¬æ¢å¤±è´¥ï¼Œæ˜¯å¦ç»§ç»­é‡è¯•ï¼Ÿ"
                )
                user_input = input("è¯·è¾“å…¥ 'y' ç»§ç»­é‡è¯•ï¼Œæˆ–å…¶ä»–é”®å–æ¶ˆ: ")

                if user_input.lower() != "y":
                    PrettyOutput.auto_print("âŒ [jarvis-sec] ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                    raise RuntimeError("ç”¨æˆ·å–æ¶ˆæ ¼å¼è½¬æ¢") from e

                PrettyOutput.auto_print("ğŸ”„ [jarvis-sec] æ­£åœ¨é‡è¯•...")

    # å¯¼å…¥å¿…è¦çš„æ¨¡å—
    from jarvis.jarvis_sec.utils import prepare_candidates as _prepare_candidates
    from jarvis.jarvis_sec.clustering import (
        process_clustering_phase as _process_clustering_phase,
    )
    from jarvis.jarvis_sec.verification import (
        process_verification_phase as _process_verification_phase,
    )
    from jarvis.jarvis_sec.file_manager import save_candidates
    from jarvis.jarvis_sec.report import build_json_and_markdown

    # åˆ›å»ºä¸´æ—¶åˆ†æç›®å½•
    with tempfile.TemporaryDirectory() as temp_dir:
        sec_dir = Path(temp_dir)

        # ä¿å­˜å€™é€‰åˆ° candidates.jsonl
        compact_candidates = _prepare_candidates(candidates)
        save_candidates(sec_dir, compact_candidates)

        PrettyOutput.auto_print(
            f"ğŸ“Š [jarvis-sec] å·²åŠ è½½ {len(compact_candidates)} ä¸ªå®‰å…¨é—®é¢˜"
        )

        # åˆ›å»ºçŠ¶æ€ç®¡ç†å™¨ï¼ˆç©ºå®ç°ï¼‰
        class DummyStatusManager:
            def update_clustering(self, **kwargs):
                pass

            def update_verification(self, **kwargs):
                pass

        status_mgr = DummyStatusManager()

        # è¿›åº¦å›è°ƒï¼ˆç©ºå®ç°ï¼‰
        def _progress_append(event):
            pass

        # åˆ›å»ºæŠ¥å‘Šå†™å…¥å‡½æ•°
        def _append_report(record):
            pass

        # èšç±»é˜¶æ®µ
        cluster_batches, invalid_clusters = _process_clustering_phase(
            compact_candidates,
            ".",  # entry_pathï¼ˆå¯ä»¥ä¸æ˜¯çœŸå®è·¯å¾„ï¼‰
            [],  # languages
            cluster_limit,
            sec_dir,
            status_mgr,
            _progress_append,
            force_save_memory=force_save_memory,
        )

        # éªŒè¯é˜¶æ®µ
        all_issues = _process_verification_phase(
            cluster_batches,
            ".",
            [],
            sec_dir,
            status_mgr,
            _progress_append,
            _append_report,
            enable_verification=enable_verification,
            force_save_memory=force_save_memory,
        )

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        result = build_json_and_markdown(all_issues, sec_dir)

        # ä¿å­˜åˆ°è¾“å‡ºæ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with output_path.open("w", encoding="utf-8") as f:
                f.write(result)
            PrettyOutput.auto_print(f"ğŸ“„ [jarvis-sec] æŠ¥å‘Šå·²ä¿å­˜: {output_file}")

        return result


__all__ = [
    "Issue",
    "direct_scan",
    "format_markdown_report",
    "run_with_agent",
    "analyze_from_json",
]
