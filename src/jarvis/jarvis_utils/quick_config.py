# -*- coding: utf-8 -*-
"""
Quick Config CLI å·¥å…·
ç”¨äºå¿«é€Ÿé…ç½® LLM å¹³å°ä¿¡æ¯ï¼ˆClaude/OpenAIï¼‰åˆ° Jarvis é…ç½®æ–‡ä»¶çš„ llms éƒ¨åˆ†
"""

import json
import yaml
from pathlib import Path
from typing import Optional
import typer
from rich.console import Console
from rich.prompt import Prompt, Confirm
import requests  # type: ignore

from .output import PrettyOutput

app = typer.Typer(help="å¿«é€Ÿé…ç½® LLM å¹³å°ä¿¡æ¯åˆ° Jarvis é…ç½®æ–‡ä»¶")
console = Console()


@app.command()
def quick_config(
    platform: Optional[str] = typer.Option(
        None, "--platform", "-p", help="LLMå¹³å°ç±»å‹ (claude/openai)"
    ),
    base_url: Optional[str] = typer.Option(None, "--url", "-u", help="APIåŸºç¡€URL"),
    api_key: Optional[str] = typer.Option(None, "--key", "-k", help="APIå¯†é’¥"),
    config_name: Optional[str] = typer.Option(
        None, "--name", "-n", help="é…ç½®åç§°ï¼Œå¦‚æœæœªæŒ‡å®šå°†ä½¿ç”¨å¹³å°åç§°"
    ),
    output_file: Optional[Path] = typer.Option(
        None, "--output", "-o", help="è¾“å‡ºé…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º~/.jarvis/config.yaml"
    ),
):
    """å¿«é€Ÿé…ç½® LLM å¹³å°ä¿¡æ¯åˆ° Jarvis é…ç½®æ–‡ä»¶çš„ llms éƒ¨åˆ†"""

    # æç¤ºç”¨æˆ·è¾“å…¥ç¼ºå¤±çš„å‚æ•°
    if platform is None:
        platform = Prompt.ask("è¯·è¾“å…¥LLMå¹³å°ç±»å‹ (claude/openai)")
    if base_url is None:
        base_url = Prompt.ask("è¯·è¾“å…¥APIåŸºç¡€URL")
    if api_key is None:
        api_key = Prompt.ask("è¯·è¾“å…¥APIå¯†é’¥")

    # éªŒè¯å¹³å°ç±»å‹
    platform = platform.lower().strip()
    if platform not in ["claude", "openai"]:
        PrettyOutput.auto_print(
            f"âŒ ä¸æ”¯æŒçš„å¹³å°ç±»å‹: {platform}ï¼Œä»…æ”¯æŒ claude å’Œ openai"
        )
        raise typer.Exit(code=1)

    # å¦‚æœæœªæŒ‡å®šé…ç½®åç§°ï¼Œä½¿ç”¨å¹³å°åç§°
    if not config_name:
        config_name = platform

    PrettyOutput.auto_print(
        f"ğŸš€ å¼€å§‹é…ç½® {platform.upper()} å¹³å°ï¼Œé…ç½®åç§°: {config_name}"
    )

    # æµ‹è¯•APIè¿æ¥å¹¶è·å–æ¨¡å‹åˆ—è¡¨
    models = get_models(platform, base_url, api_key)
    if not models:
        PrettyOutput.auto_print("âš ï¸  è­¦å‘Šï¼šæ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡å‹åç§°")
        if platform == "claude":
            models = ["claude-3-5-sonnet-latest"]
        else:  # openai
            models = ["gpt-4o"]

    PrettyOutput.auto_print(
        f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {', '.join(models[:10])}{'...' if len(models) > 10 else ''}"
    )

    # è¯¢é—®ç”¨æˆ·æ˜¯å¦é…ç½®æ‰€æœ‰æ¨¡å‹
    if len(models) > 1:
        console.print("[bold]å¯ç”¨æ¨¡å‹åˆ—è¡¨:[/]")
        for i, model in enumerate(models, 1):
            console.print(f"  {i}. {model}")

        configure_all = Confirm.ask("æ˜¯å¦é…ç½®æ‰€æœ‰æ¨¡å‹ï¼Ÿ", default=False)

        if configure_all:
            selected_models = models
        else:
            model_choices = Prompt.ask("è¯·è¾“å…¥è¦é…ç½®çš„æ¨¡å‹åºå·ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰")
            try:
                indices = [int(x.strip()) - 1 for x in model_choices.split(",")]
                selected_models = []
                for idx in indices:
                    if 0 <= idx < len(models):
                        selected_models.append(models[idx])
                    else:
                        PrettyOutput.auto_print(f"âŒ æ— æ•ˆçš„æ¨¡å‹åºå·: {idx + 1}")
                        raise typer.Exit(code=1)
                if not selected_models:
                    PrettyOutput.auto_print("âŒ æ²¡æœ‰é€‰æ‹©ä»»ä½•æœ‰æ•ˆæ¨¡å‹")
                    raise typer.Exit(code=1)
            except ValueError:
                PrettyOutput.auto_print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—åºå·ï¼Œç”¨é€—å·åˆ†éš”")
                raise typer.Exit(code=1)
    else:
        # å•ä¸ªæ¨¡å‹æƒ…å†µï¼Œç›´æ¥é€‰æ‹©
        selected_models = [models[0]]

    PrettyOutput.auto_print(
        f"âœ… å·²é€‰æ‹© {len(selected_models)} ä¸ªæ¨¡å‹: {', '.join(selected_models)}"
    )

    # é€‰æ‹©é»˜è®¤æ¨¡å‹
    if len(selected_models) == 1:
        default_model = selected_models[0]
        PrettyOutput.auto_print(f"ğŸ¯ é»˜è®¤æ¨¡å‹: {default_model}")
    else:
        console.print("[bold]è¯·é€‰æ‹©é»˜è®¤æ¨¡å‹:[/]")
        for i, model in enumerate(selected_models, 1):
            console.print(f"  {i}. {model}")

        default_choice = Prompt.ask("è¯·è¾“å…¥é»˜è®¤æ¨¡å‹åºå·")
        try:
            default_idx = int(default_choice.strip()) - 1
            if 0 <= default_idx < len(selected_models):
                default_model = selected_models[default_idx]
                PrettyOutput.auto_print(f"ğŸ¯ é»˜è®¤æ¨¡å‹: {default_model}")
            else:
                PrettyOutput.auto_print(f"âŒ æ— æ•ˆçš„æ¨¡å‹åºå·: {default_choice}")
                raise typer.Exit(code=1)
        except ValueError:
            PrettyOutput.auto_print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—åºå·")
            raise typer.Exit(code=1)

    # è®¾ç½®é»˜è®¤è¾“å‡ºæ–‡ä»¶
    if output_file is None:
        jarvis_dir = Path.home() / ".jarvis"
        output_file = jarvis_dir / "config.yaml"

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_file.parent.mkdir(parents=True, exist_ok=True)

    # è¯»å–ç°æœ‰é…ç½®
    config: dict = {}
    if output_file.exists():
        try:
            with open(output_file, "r", encoding="utf-8") as f:
                if output_file.suffix in (".yaml", ".yml"):
                    config = yaml.safe_load(f) or {}
                else:
                    config = json.load(f)
        except Exception as e:
            PrettyOutput.auto_print(f"âš ï¸  æ— æ³•è¯»å–ç°æœ‰é…ç½®æ–‡ä»¶ {output_file}: {e}")
            if not Confirm.ask("æ˜¯å¦ç»§ç»­åˆ›å»ºæ–°é…ç½®ï¼Ÿ", default=True):
                raise typer.Exit(code=0)

    # åˆå§‹åŒ–llmséƒ¨åˆ†
    if "llms" not in config:
        config["llms"] = {}

    # åˆå§‹åŒ–llm_groupséƒ¨åˆ†
    if "llm_groups" not in config:
        config["llm_groups"] = {}

    # ä¸ºæ¯ä¸ªé€‰æ‹©çš„æ¨¡å‹åˆ›å»ºé…ç½®
    for i, model in enumerate(selected_models):
        if len(selected_models) == 1:
            # å•ä¸ªæ¨¡å‹ä½¿ç”¨æŒ‡å®šçš„é…ç½®åç§°
            model_config_name = config_name
        else:
            # å¤šä¸ªæ¨¡å‹ä½¿ç”¨é…ç½®åç§°+æ¨¡å‹åçš„æ–¹å¼é¿å…å†²çª
            model_config_name = (
                f"{config_name}_{model.replace('.', '_').replace('-', '_')}"
            )

        # æ ¹æ®å¹³å°ç±»å‹ç”Ÿæˆæ­£ç¡®çš„é…ç½®é”®å
        if platform == "openai":
            llm_config_dict = {
                "openai_api_key": api_key,
                "openai_api_base": base_url,
            }
        elif platform == "claude":
            llm_config_dict = {
                "anthropic_api_key": api_key,
                "anthropic_base_url": base_url,
            }
        else:
            llm_config_dict = {
                f"{platform}_api_key": api_key,
                f"{platform}_base_url": base_url,
            }

        llm_config = {
            "platform": platform,
            "model": model,
            "max_input_token_count": 128000,
            "llm_config": llm_config_dict,
        }

        # æ·»åŠ æ¨¡å‹é…ç½®
        config["llms"][model_config_name] = llm_config

        # å¦‚æœæ˜¯é»˜è®¤æ¨¡å‹ï¼Œåˆ›å»ºllm_groupsé…ç½®
        if model == default_model:
            # ä½¿ç”¨æ¨¡å‹åç§°ä½œä¸ºç»„åï¼Œæ›¿æ¢ç‰¹æ®Šå­—ç¬¦
            group_name = model.replace(".", "_").replace("-", "_")
            # åˆ›å»ºæ¨¡å‹ç»„é…ç½®
            config["llm_groups"][group_name] = {"normal_llm": model_config_name}
            PrettyOutput.auto_print(
                f"âœ… å·²åˆ›å»ºæ¨¡å‹ç»„ '{group_name}'ï¼Œä½¿ç”¨ {model_config_name} ä½œä¸ºé»˜è®¤æ¨¡å‹"
            )

    PrettyOutput.auto_print(f"âœ… å·²ä¸º {len(selected_models)} ä¸ªæ¨¡å‹åˆ›å»ºé…ç½®")

    # è®¾ç½®é»˜è®¤æ¨¡å‹ç»„
    default_group_name = default_model.replace(".", "_").replace("-", "_")
    config["llm_group"] = default_group_name
    PrettyOutput.auto_print(f"âœ… å·²è®¾ç½®é»˜è®¤æ¨¡å‹ç»„ä¸º '{default_group_name}'")

    # ä¿å­˜é…ç½®æ–‡ä»¶
    try:
        if output_file.suffix in (".yaml", ".yml"):
            with open(output_file, "w", encoding="utf-8") as f:
                yaml.safe_dump(
                    config,
                    f,
                    allow_unicode=True,
                    default_flow_style=False,
                    sort_keys=False,
                )
        else:
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(config, f, indent=2, ensure_ascii=False)

        PrettyOutput.auto_print(f"âœ… é…ç½®å·²ä¿å­˜åˆ° {output_file}")

    except Exception as e:
        PrettyOutput.auto_print(f"âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}")
        raise typer.Exit(code=1)


def get_models(platform: str, base_url: str, api_key: str) -> list:
    """è·å–å¹³å°çš„æ¨¡å‹åˆ—è¡¨"""
    try:
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }

        if platform == "openai":
            url = f"{base_url}/models" if not base_url.endswith("/models") else base_url
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                models = [item["id"] for item in data.get("data", [])]
                return models
        elif platform == "claude":
            # Claude API doesn't have a direct models endpoint, use a common model list
            # For Claude, we'll return a list of known Claude models
            known_claude_models = [
                "claude-3-5-sonnet-latest",
                "claude-3-5-sonnet-20241022",
                "claude-3-5-sonnet-20240620",
                "claude-3-opus-latest",
                "claude-3-opus-20240229",
                "claude-3-sonnet-latest",
                "claude-3-sonnet-20240229",
                "claude-3-haiku-latest",
                "claude-3-haiku-20240307",
            ]
            return known_claude_models
    except Exception as e:
        PrettyOutput.auto_print(f"âš ï¸  è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")

    return []


if __name__ == "__main__":
    app()
