"""ä¸»åŠ¨äº¤äº’åŠ©æ‰‹

æä¾›ä¸»åŠ¨äº¤äº’èƒ½åŠ›ï¼š
- ä¸»åŠ¨æé—®æ¾„æ¸…
- ä¸»åŠ¨æä¾›å»ºè®®
- ä¸»åŠ¨æŠ¥å‘Šè¿›åº¦
"""

from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Optional

from ..intelligence.hybrid_engine import HybridEngine, InferenceMode
from ..intelligence.llm_reasoning import ReasoningContext, ReasoningType

from jarvis.jarvis_utils.output import PrettyOutput


class ActionType(Enum):
    """ä¸»åŠ¨è¡Œä¸ºç±»å‹"""

    CLARIFY = "clarify"  # æ¾„æ¸…
    SUGGEST = "suggest"  # å»ºè®®
    REPORT = "report"  # æŠ¥å‘Š
    WARN = "warn"  # è­¦å‘Š
    REMIND = "remind"  # æé†’
    CONFIRM = "confirm"  # ç¡®è®¤


class ActionPriority(Enum):
    """è¡Œä¸ºä¼˜å…ˆçº§"""

    LOW = 1
    MEDIUM = 2
    HIGH = 3
    URGENT = 4


@dataclass
class ProactiveAction:
    """ä¸»åŠ¨è¡Œä¸º"""

    action_type: ActionType
    content: str
    priority: ActionPriority = ActionPriority.MEDIUM
    trigger_condition: str = ""
    context: dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)
    executed: bool = False


@dataclass
class SuggestionResult:
    """å»ºè®®ç»“æœ"""

    suggestions: list[str] = field(default_factory=list)
    reasoning: str = ""
    confidence: float = 0.0
    source: str = "rule"
    related_context: dict[str, Any] = field(default_factory=dict)


class ProactiveAssistant(HybridEngine):
    """ä¸»åŠ¨äº¤äº’åŠ©æ‰‹"""

    def __init__(
        self,
        llm_client: Any = None,
        mode: InferenceMode = InferenceMode.HYBRID,
    ):
        super().__init__(llm_client=llm_client, mode=mode, enable_learning=True)
        self._pending_actions: list[ProactiveAction] = []
        self._action_history: list[ProactiveAction] = []
        self._suggestion_triggers = {
            "error": ["é”™è¯¯", "å¼‚å¸¸", "å¤±è´¥", "bug", "Error"],
            "performance": ["æ…¢", "å¡é¡¿", "æ€§èƒ½", "ä¼˜åŒ–"],
            "security": ["å®‰å…¨", "æ¼æ´", "é£é™©", "æƒé™"],
            "best_practice": ["æœ€ä½³å®è·µ", "è§„èŒƒ", "æ ‡å‡†", "å»ºè®®"],
        }
        self._clarification_triggers = ["ä¸ç¡®å®š", "å¯èƒ½", "ä¹Ÿè®¸", "å¤§æ¦‚", "æˆ–è€…"]

    def analyze_for_proactive_action(
        self, context: dict[str, Any], user_input: str = ""
    ) -> list[ProactiveAction]:
        """åˆ†æä¸Šä¸‹æ–‡ï¼Œå†³å®šæ˜¯å¦éœ€è¦ä¸»åŠ¨è¡Œä¸º"""
        result = self.infer(input_data=user_input, context=context, mode="analyze")
        actions = []
        if result.success and result.output:
            output: dict[str, Any] = result.output
            if output.get("needs_clarification"):
                actions.append(
                    ProactiveAction(
                        action_type=ActionType.CLARIFY,
                        content=output.get("clarification_question", "è¯·æä¾›æ›´å¤šä¿¡æ¯"),
                        priority=ActionPriority.HIGH,
                    )
                )
            if output.get("has_suggestion"):
                actions.append(
                    ProactiveAction(
                        action_type=ActionType.SUGGEST,
                        content=output.get("suggestion", ""),
                        priority=ActionPriority.MEDIUM,
                    )
                )

        # æ‰“å°ä¸»åŠ¨æœåŠ¡ç»“æœ
        mode_str = "LLM" if result.llm_used else "è§„åˆ™"
        if actions:
            action_types = [a.action_type.value for a in actions]
            PrettyOutput.auto_print(
                f"ğŸ’¡ ä¸»åŠ¨æœåŠ¡: è§¦å‘ {len(actions)} ä¸ªæœåŠ¡ {action_types} (æ¨¡å¼: {mode_str})"
            )

        self._pending_actions.extend(actions)
        return actions

    def generate_suggestions(self, context: dict[str, Any]) -> SuggestionResult:
        """ç”Ÿæˆå»ºè®®"""
        result = self.infer(input_data=str(context), context=context, mode="suggest")
        if result.success and result.output:
            output: dict[str, Any] = result.output
            return SuggestionResult(
                suggestions=output.get("suggestions", []),
                reasoning=output.get("reasoning", ""),
                confidence=output.get("confidence", 0.7),
                source="llm" if result.llm_used else "rule",
            )
        return SuggestionResult()

    def report_progress(self, task_info: dict[str, Any]) -> ProactiveAction:
        """ç”Ÿæˆè¿›åº¦æŠ¥å‘Š"""
        progress = task_info.get("progress", 0)
        status = task_info.get("status", "è¿›è¡Œä¸­")
        content = f"ä»»åŠ¡è¿›åº¦ï¼š{progress}%ï¼ŒçŠ¶æ€ï¼š{status}"
        if task_info.get("blockers"):
            content += f"\né˜»å¡é—®é¢˜ï¼š{task_info['blockers']}"
        action = ProactiveAction(
            action_type=ActionType.REPORT,
            content=content,
            priority=ActionPriority.LOW,
            context=task_info,
        )
        self._pending_actions.append(action)
        return action

    def should_ask_clarification(self, user_input: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ¾„æ¸…"""
        for trigger in self._clarification_triggers:
            if trigger in user_input:
                return True
        return False

    def get_pending_actions(
        self, priority: Optional[ActionPriority] = None
    ) -> list[ProactiveAction]:
        """è·å–å¾…æ‰§è¡Œçš„ä¸»åŠ¨è¡Œä¸º"""
        if priority:
            return [a for a in self._pending_actions if a.priority == priority]
        return self._pending_actions

    def execute_action(self, action: ProactiveAction) -> bool:
        """æ‰§è¡Œä¸»åŠ¨è¡Œä¸º"""
        action.executed = True
        self._action_history.append(action)
        if action in self._pending_actions:
            self._pending_actions.remove(action)
        return True

    def _apply_rule(
        self, rule: Any, input_data: str, **kwargs: Any
    ) -> Optional[dict[str, Any]]:
        """åº”ç”¨å­¦ä¹ åˆ°çš„è§„åˆ™"""
        mode = kwargs.get("mode", "analyze")
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¾„æ¸…
        if mode == "analyze":
            for trigger in self._clarification_triggers:
                if trigger in input_data:
                    return {
                        "needs_clarification": True,
                        "clarification_question": f"æ‚¨æåˆ°'{trigger}'ï¼Œèƒ½å¦æ›´æ˜ç¡®ä¸€äº›ï¼Ÿ",
                    }
            # æ£€æŸ¥æ˜¯å¦æœ‰å»ºè®®è§¦å‘
            for category, triggers in self._suggestion_triggers.items():
                for trigger in triggers:
                    if trigger in input_data:
                        return {
                            "has_suggestion": True,
                            "suggestion": f"æ£€æµ‹åˆ°{category}ç›¸å…³å†…å®¹ï¼Œå»ºè®®è¿›ä¸€æ­¥åˆ†æ",
                        }
        return None

    def _parse_llm_output(self, output: str) -> Optional[dict[str, Any]]:
        """è§£æLLMè¾“å‡º"""
        import json

        try:
            if "{" in output and "}" in output:
                start = output.index("{")
                end = output.rindex("}") + 1
                parsed: dict[str, Any] = json.loads(output[start:end])
                return parsed
        except (json.JSONDecodeError, ValueError):
            pass
        return {"suggestions": [], "reasoning": output}

    def _build_reasoning_context(
        self, input_data: str, **kwargs: Any
    ) -> ReasoningContext:
        """æ„å»ºæ¨ç†ä¸Šä¸‹æ–‡"""
        context = kwargs.get("context", {})
        mode = kwargs.get("mode", "analyze")
        if mode == "suggest":
            instruction = f"""åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ç”Ÿæˆæœ‰ä»·å€¼çš„å»ºè®®ï¼š

ä¸Šä¸‹æ–‡ï¼š{context}
è¾“å…¥ï¼š{input_data}

è¯·æä¾›å…·ä½“ã€å¯æ“ä½œçš„å»ºè®®ã€‚"""
        else:
            instruction = f"""åˆ†æä»¥ä¸‹å†…å®¹ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦ä¸»åŠ¨äº¤äº’ï¼š

è¾“å…¥ï¼š{input_data}
ä¸Šä¸‹æ–‡ï¼š{context}

åˆ¤æ–­æ˜¯å¦éœ€è¦æ¾„æ¸…æˆ–æä¾›å»ºè®®ã€‚"""
        return ReasoningContext(
            task_type=ReasoningType.ANALYSIS,
            input_data=input_data,
            instruction=instruction,
            output_format='{"needs_clarification": bool, "has_suggestion": bool, "suggestions": []}',
        )
