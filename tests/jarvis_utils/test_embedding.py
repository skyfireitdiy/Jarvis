# -*- coding: utf-8 -*-
"""jarvis_utils.embedding æ¨¡å—å•å…ƒæµ‹è¯•"""


from jarvis.jarvis_utils.embedding import get_context_token_count, split_text_into_chunks


class TestGetContextTokenCount:
    """æµ‹è¯• get_context_token_count å‡½æ•°"""

    def test_empty_string(self):
        """æµ‹è¯•ç©ºå­—ç¬¦ä¸²"""
        assert get_context_token_count("") == 0

    def test_none_input(self):
        """æµ‹è¯• None è¾“å…¥"""
        assert get_context_token_count(None) == 0

    def test_simple_text(self):
        """æµ‹è¯•ç®€å•æ–‡æœ¬"""
        text = "Hello world"
        result = get_context_token_count(text)
        assert isinstance(result, int)
        assert result > 0

    def test_long_text(self):
        """æµ‹è¯•é•¿æ–‡æœ¬"""
        text = "Hello world " * 100
        result = get_context_token_count(text)
        assert isinstance(result, int)
        assert result > 0

    def test_unicode_text(self):
        """æµ‹è¯• Unicode æ–‡æœ¬"""
        text = "ä½ å¥½ä¸–ç•Œ ğŸŒ"
        result = get_context_token_count(text)
        assert isinstance(result, int)
        assert result > 0

    def test_multiline_text(self):
        """æµ‹è¯•å¤šè¡Œæ–‡æœ¬"""
        text = "Line 1\nLine 2\nLine 3"
        result = get_context_token_count(text)
        assert isinstance(result, int)
        assert result > 0


class TestSplitTextIntoChunks:
    """æµ‹è¯• split_text_into_chunks å‡½æ•°"""

    def test_empty_text(self):
        """æµ‹è¯•ç©ºæ–‡æœ¬"""
        assert split_text_into_chunks("") == []

    def test_short_text(self):
        """æµ‹è¯•çŸ­æ–‡æœ¬ï¼ˆå°äºæœ€å°é•¿åº¦ï¼‰"""
        text = "Short text"
        chunks = split_text_into_chunks(text, max_length=512, min_length=50)
        # å³ä½¿æ–‡æœ¬å¾ˆçŸ­ï¼Œä¹Ÿåº”è¯¥è¿”å›è‡³å°‘ä¸€ä¸ªå—
        assert len(chunks) >= 1
        assert chunks[0] == text

    def test_text_within_max_length(self):
        """æµ‹è¯•åœ¨æœ€å¤§é•¿åº¦å†…çš„æ–‡æœ¬"""
        text = "This is a test text that is not too long"
        chunks = split_text_into_chunks(text, max_length=512, min_length=50)
        assert len(chunks) == 1
        assert chunks[0] == text

    def test_long_text_splitting(self):
        """æµ‹è¯•é•¿æ–‡æœ¬åˆ†å‰²"""
        # åˆ›å»ºä¸€ä¸ªè¾ƒé•¿çš„æ–‡æœ¬
        text = "Word " * 200  # çº¦ 1000 ä¸ªå­—ç¬¦
        chunks = split_text_into_chunks(text, max_length=100, min_length=20)
        assert len(chunks) > 1
        # éªŒè¯æ‰€æœ‰å—éƒ½è¢«åŒ…å«
        combined = "".join(chunks)
        assert combined == text

    def test_custom_max_length(self):
        """æµ‹è¯•è‡ªå®šä¹‰æœ€å¤§é•¿åº¦"""
        text = "Word " * 100
        chunks = split_text_into_chunks(text, max_length=50, min_length=10)
        assert len(chunks) > 1
        # æ¯ä¸ªå—ï¼ˆé™¤äº†æœ€åä¸€ä¸ªï¼‰åº”è¯¥æ¥è¿‘æœ€å¤§é•¿åº¦
        for chunk in chunks[:-1]:
            assert len(chunk) > 0

    def test_custom_min_length(self):
        """æµ‹è¯•è‡ªå®šä¹‰æœ€å°é•¿åº¦"""
        text = "Word " * 200
        chunks = split_text_into_chunks(text, max_length=100, min_length=30)
        assert len(chunks) > 1
        # é™¤äº†æœ€åä¸€ä¸ªå—ï¼Œå…¶ä»–å—åº”è¯¥æ»¡è¶³æœ€å°é•¿åº¦è¦æ±‚ï¼ˆåŸºäºtokenä¼°ç®—ï¼‰

    def test_multiline_text(self):
        """æµ‹è¯•å¤šè¡Œæ–‡æœ¬"""
        text = "Line 1\n" * 50
        chunks = split_text_into_chunks(text, max_length=100, min_length=20)
        assert len(chunks) > 0
        combined = "".join(chunks)
        assert combined == text

